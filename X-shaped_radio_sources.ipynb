{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc08d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in packages for pandas, astropy, etc. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Column, MaskedColumn\n",
    "from astropy.io.ascii import masked\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.cosmology import LambdaCDM \n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.sdss import SDSS\n",
    "from astropy.coordinates import match_coordinates_sky\n",
    "import os \n",
    "\n",
    "cosmo = LambdaCDM(H0=70, Om0=0.3, Ode0=0.7) #Creating our choice of cosmology here...\n",
    "\n",
    "pd.set_option('display.max_columns', 300) # Setting max number of rows per df to be the size of the df\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c072d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm rewriting our matching algorithm using the search_around_sky() function\n",
    "# It may not always be the best option, but at least for these double peaked catalogs, I think I'm going to run \n",
    "# with it\n",
    "\n",
    "def match_tables_fib(t1,t2,match_tol):\n",
    "    if 'level_0' in t1.columns:\n",
    "        t1.drop(labels=['level_0'], axis=1, inplace=True)\n",
    "    t1.reset_index(drop=False, inplace=True)\n",
    "    if 'level_0' in t2.columns:\n",
    "        t2.drop(labels=['level_0'], axis=1, inplace=True)\n",
    "    t2.reset_index(inplace=True, drop=False)\n",
    "    t1['Table_flag'] = 'Table1'\n",
    "    t2['Table_flag'] = 'Table2'\n",
    "    # First we begin by matching RA1 and Dec1 of t1 to RA1 and Dec1 of t2\n",
    "    c1 = SkyCoord(ra=t1['RA1_deg']*u.degree, dec=t1['Dec1_deg']*u.degree) # Storing coordinates for table 1\n",
    "    c2 = SkyCoord(ra=t2['RA1_deg']*u.degree, dec=t2['Dec1_deg']*u.degree) # storing coordinates for table 2\n",
    "    # Adding a match tolerance here, with user input for the function\n",
    "    max_sep = match_tol * u.arcsec # The max match tolerance will be 5''\n",
    "    #idx2, d2d2, d3d2 = match_coordinates_sky(c1, c2) # Now matching table 1 to table 2\n",
    "    idx1, idx2, _, _ = c2.search_around_sky(c1, max_sep) \n",
    "    # idx1 and idx2 are the indices in table 1 and table 2 which are the closest matching rows to each other\n",
    "    # Note, we should not need to cross match RA1 vs. RA2, across table because the double peaked sources only have\n",
    "    # a single set of coordinates at this point\n",
    "    # We need to make tables for t1 and t2 that do not include the matched items\n",
    "    t1unique = (t1[~t1['index'].isin(idx1)]).reset_index(drop=True)\n",
    "    t2unique = (t2[~t2['index'].isin(idx2)]).reset_index(drop=True)\n",
    "    # And then we need a table for the matches items where we ensure they are properly matching (SDSS names should \\\n",
    "    # be the same), and then remove the duplicates, store the relevant info from the second table, and concatenate \\\n",
    "    # this with the primary table\n",
    "    tmatches = pd.concat([(t1.iloc[idx1]),(t2.iloc[idx2])]).sort_values(by='Name').reset_index(drop=True)\n",
    "    tunique = pd.concat([t1unique, t2unique]).sort_values(by='Name').reset_index(drop=True)\n",
    "    #\n",
    "    #t1matches.loc[t1matches['index'].isin(c1_dups['idx1']), 'Paper(s)'] += \" ; \" + t2['Paper(s)'][0]\n",
    "    #t1matches.loc[t1matches['index'].isin(c1_dups['idx1']), 'BibCode(s)'] += \" ; \" + t2['BibCode(s)'][0]\n",
    "    #t1matches.loc[t1matches['index'].isin(c1_dups['idx1']), 'DOI(s)'] += \" ; \" + t2['DOI(s)'][0]\n",
    "    return tunique, tmatches, idx1, idx2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4377051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now loading in the catalog(s) from Tytler+2009\n",
    "cheung2007 = (Table.read('Tables/Cheung_2007/table2.dat', readme = 'Tables/Cheung_2007/ReadMe', format='ascii.cds')).to_pandas()\n",
    "\n",
    "cheung2007['System Type'] = \"Recoil Candidate\"\n",
    "cheung2007['Name'] = cheung2007['[C2007]']\n",
    "cheung2007['Name2'] = cheung2007['[C2007]']\n",
    "cheung2007['Selection Method'] = \"X-ray Shaped Radio Source Candidate\"\n",
    "cheung2007['Confirmation Method'] = -99\n",
    "\n",
    "cheung2007['z1'] = cheung2007['z']\n",
    "cheung2007['z1_type'] = -100\n",
    "cheung2007['z2'] = cheung2007['z']\n",
    "cheung2007['z2_type'] = -100\n",
    "\n",
    "# Creating an RA and Dec column for each source (and a duplicate column for each for the 'secondary' in each)\n",
    "cheung2007['RA1'] = cheung2007['RAh'].astype(str) + ':' + cheung2007['RAm'].astype(str) + ':' + cheung2007['RAs'].astype(str)\n",
    "cheung2007['Dec1'] = cheung2007['DE-'].astype(str) + cheung2007['DEd'].astype(str) + ':' + cheung2007['DEm'].astype(str) + ':' + cheung2007['DEs'].astype(str)\n",
    "\n",
    "cheung2007['RA2'] = cheung2007['RA1']\n",
    "cheung2007['Dec2'] = cheung2007['Dec1']\n",
    "\n",
    "# And converting sexagesimal to degrees...\n",
    "coordconvert = SkyCoord(ra = cheung2007['RA1'], dec = cheung2007['Dec1'], frame='icrs', unit = (u.hourangle, u.deg))\n",
    "cheung2007['RA1_deg'] = coordconvert.ra.degree\n",
    "cheung2007['Dec1_deg'] = coordconvert.dec.degree\n",
    "\n",
    "cheung2007['RA2_deg'] = cheung2007['RA1_deg']\n",
    "cheung2007['Dec2_deg'] = cheung2007['Dec1_deg']\n",
    "\n",
    "# Dropping the original 7 columns for RA and Dec\n",
    "cheung2007.drop(labels=['RAh','RAm','RAs','DE-','DEd','DEm','DEs'], axis=1, inplace=True)\n",
    "\n",
    "# Dropping irrelevant columns that (as far as I know) we do not need...\n",
    "cheung2007.drop(labels=['Seq','g-r','f_g-r','f_rmag','ID','S.365','S4.9','r_S4.9','alpha1','alpha2','OCat'], axis=1, inplace=True)\n",
    "#'S1.4',\n",
    "\n",
    "# Adding in columns for information about the coordinates\n",
    "cheung2007['Equinox'] = \"J2000\"\n",
    "cheung2007['Optical'] = 'Optical'\n",
    "cheung2007['Coordinate_waveband'] = cheung2007['Optical'].where(((cheung2007['r_rmag']=='SDSS') | (cheung2007['r_rmag']=='APM') | (cheung2007['r_rmag']=='D89') | (cheung2007['r_rmag']=='USNO')), other='Radio')\n",
    "cheung2007['Coordinate_Source'] = cheung2007['r_rmag'] # I believe this should be Cheung's column 'r_rmag'\n",
    "cheung2007.drop(labels='Optical', axis=1, inplace=True)\n",
    "\n",
    "cheung2007['Brightness1'] = cheung2007['rmag'].where(((cheung2007['rmag']>0) & (cheung2007['r_rmag']=='SDSS')), other=cheung2007['S1.4'])\n",
    "cheung2007['Brightness2'] = cheung2007['Brightness1']\n",
    "cheung2007['r SDSS'] = 'r SDSS'\n",
    "cheung2007['Brightness_band1'] = cheung2007[\"r SDSS\"].where(((cheung2007['r_rmag']=='SDSS') & (cheung2007['rmag']>0)), other='1.4 GHz NVSS')\n",
    "cheung2007['Brightness_band2'] = cheung2007['Brightness2']\n",
    "cheung2007.drop(labels='r SDSS', axis=1, inplace=True)\n",
    "\n",
    "cheung2007['asinh model mag'] = 'asinh model mag'\n",
    "cheung2007['Brightness_type1'] = cheung2007['asinh model mag'].where((cheung2007['r_rmag']=='SDSS'), other='Flux: mJy')\n",
    "cheung2007['Brightness_type2'] = cheung2007['Brightness_type1']\n",
    "cheung2007.drop(labels='asinh model mag', axis=1, inplace=True)\n",
    "\n",
    "cheung2007['Sep'] = 0\n",
    "cheung2007['Sep(kpc)'] = 0\n",
    "cheung2007['delta_z'] = cheung2007['z1']-cheung2007['z2']\n",
    "cheung2007['dV'] = (2.99e+5)*((1+cheung2007['z1'])**2 - (1+cheung2007['z2'])**2)/((1+cheung2007['z1'])**2+(1+cheung2007['z2'])**2)\n",
    "\n",
    "# Adding in the info for Cheung's paper here\n",
    "cheung2007['Paper(s)'] = \"Cheung+2007\"\n",
    "cheung2007['BibCode(s)'] = \"2007AJ....133.2097C\"\n",
    "cheung2007['DOI(s)'] = \"https://doi.org/10.1086/513095\"\n",
    "cheung2007['Notes'] = \" \"\n",
    "\n",
    "# Now dropping any irrelevant columns \n",
    "cheung2007.drop(labels=['[C2007]','rmag','r_rmag','z','r_z'], axis=1, inplace=True)\n",
    "\n",
    "# Now rearranging the columns (and renaming if need be):\n",
    "\n",
    "#cheung2007 = cheung2007[['System Type','Name1','Name2','Selection Method','Confirmation Method','z1', \\\n",
    "#                         'z1_type','z2','z2_type','RA1','Dec1','RA1_deg','Dec1_deg','RA2','Dec2',\\\n",
    "#                         'RA2_deg','Dec2_deg','Equinox','Coordinate_waveband','Coordinate_Source','Brightness1',\\\n",
    "#                         'Brightness_band1','Brightness_type1','Brightness2','Brightness_band2',\\\n",
    "#                         'Brightness_type2','Sep','Sep(kpc)','delta_z','dV','Paper(s)','BibCode(s)','DOI(s)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26b7d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cheung2007.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1295d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheung2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da068e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reading in the information from table 1 of Cheung+2007, which was a literature compilation of X-shaped \\\n",
    "# radio sources\n",
    "\n",
    "cheung2007_t1 = pd.read_csv('Tables/Cheung_2007/Cheung2007_table1.csv', sep=',')\n",
    "\n",
    "cheung2007_t1['Name'] = cheung2007_t1['System Name']\n",
    "cheung2007_t1['Name2'] = cheung2007_t1['System Name']\n",
    "cheung2007_t1['Selection Method'] = \"X-Shaped Radio Source\"\n",
    "cheung2007_t1['Confirmation Method'] = -99\n",
    "cheung2007_t1['z1'] = cheung2007_t1['Redshift']\n",
    "cheung2007_t1['z1_type'] = -100\n",
    "cheung2007_t1['z2'] = cheung2007_t1['Redshift']\n",
    "cheung2007_t1['z2_type'] = -100\n",
    "\n",
    "cheung2007_t1['RA1'] = cheung2007_t1['RA']\n",
    "cheung2007_t1['Dec1']= cheung2007_t1['Dec']\n",
    "\n",
    "cheung2007_t1['RA2'] = cheung2007_t1['RA']\n",
    "cheung2007_t1['Dec2']= cheung2007_t1['Dec']\n",
    "\n",
    "# Converting now the sexagesimal coordinates to degrees...\n",
    "coordconvert = SkyCoord(ra = cheung2007_t1['RA1'], dec = cheung2007_t1['Dec1'], frame='icrs', unit = (u.hourangle, u.deg))\n",
    "cheung2007_t1['RA1_deg'] = coordconvert.ra.degree\n",
    "cheung2007_t1['Dec1_deg'] = coordconvert.dec.degree\n",
    "\n",
    "cheung2007_t1['RA2_deg'] = cheung2007_t1['RA1_deg']\n",
    "cheung2007_t1['Dec2_deg'] = cheung2007_t1['Dec1_deg']\n",
    "\n",
    "cheung2007_t1['Brightness_band1'] = cheung2007_t1['Brightness_band1'].astype(str) + \" (Simbad)\"\n",
    "cheung2007_t1['Brightness_type1'] = cheung2007_t1['Brightness_type1'].astype(str) + \" (Check Simbad)\"\n",
    "\n",
    "cheung2007_t1['Brightness2'] = cheung2007_t1['Brightness1']\n",
    "cheung2007_t1['Brightness_band2'] = cheung2007_t1['Brightness_band1']\n",
    "cheung2007_t1['Brightness_type2'] = cheung2007_t1['Brightness_type1']\n",
    "\n",
    "#cheung2007_t1['delta_z'] = cheung2007_t1['z1']-cheung2007_t1['z2']\n",
    "cheung2007_t1['dV'] = (2.99e+5)*((1+cheung2007_t1['z1'])**2 - (1+cheung2007_t1['z2'])**2)/((1+cheung2007_t1['z1'])**2+(1+cheung2007_t1['z2'])**2)\n",
    "\n",
    "\n",
    "# Dropping unnecessary columns:\n",
    "cheung2007_t1.drop(labels=['Component Name','J2000 Designation', 'System Name', 'Discovery Method', 'Redshift',\\\n",
    "                           'Redshift Type', 'RA', 'Dec'], axis=1, inplace=True)\n",
    "\n",
    "# Tacking on Cheung+2007's paper info, just so I can note that Cheung+2007 lists all of these...\n",
    "cheung2007_t1['Paper(s)'] = (cheung2007_t1['Paper(s)']).astype(str)+\" ; Cheung+2007\"\n",
    "cheung2007_t1['BibCode(s)'] = cheung2007_t1['BibCode(s)'].astype(str)+\" ; 2007AJ....133.2097C\"\n",
    "cheung2007_t1['DOI(s)'] = cheung2007_t1['DOI(s)'].astype(str)+\" ; https://doi.org/10.1086/513095\"\n",
    "cheung2007_t1['Notes'] = \" \"\n",
    "\n",
    "\n",
    "# Now rearranging the columns and renaming (if needed):\n",
    "\n",
    "#cheung2007_t1 = cheung2007_t1[['System Type','Name1','Name2','Selection Method','Confirmation Method','z1',\\\n",
    "#                               'z1_type','z2','z2_type','RA1','Dec1','RA1_deg','Dec1_deg','RA2','Dec2','RA2_deg',\\\n",
    "#                               'Dec2_deg','Equinox','Coordinate Waveband','Coordinate Source','Brightness1',\\\n",
    "#                               'Brightness_band1','Brightness_type1','Brightness2','Brightness_band2',\\\n",
    "#                               'Brightness_type2','Sep(arcsec)','Sep(kpc)','delta_z','dV','Paper(s)',\\\n",
    "#                               'BibCode(s)','DOI(s)', 'Notes']]\n",
    "# \n",
    "#cheung2007_t1.columns=['System Type','Name1','Name2','Selection Method','Confirmation Method','z1',\\\n",
    "#                               'z1_type','z2','z2_type','RA1','Dec1','RA1_deg','Dec1_deg','RA2','Dec2','RA2_deg',\\\n",
    "#                               'Dec2_deg','Equinox','Coordinate_waveband','Coordinate_Source','Brightness1',\\\n",
    "#                               'Brightness_band1','Brightness_type1','Brightness2','Brightness_band2',\\\n",
    "#                               'Brightness_type2','Sep','Sep(kpc)','delta_z','dV','Paper(s)',\\\n",
    "#                               'BibCode(s)','DOI(s)', 'Notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5715c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cheung2007_t1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a4e744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to add 3C 293 (Liu+2004) and for J0116 at RA and Dec 01 16 25.071 -47 22 40.67\n",
    "# --> Liu+04 was added as an individual target.\n",
    "# --> --> Need to come back to th eJ0116 bcause I don't remember what that is\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbf4538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now concatenating the two tables form Cheung+2007\n",
    "frames=[cheung2007_t1,cheung2007]\n",
    "cheung_master = pd.concat(frames).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e2cd0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheung_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a63a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cf0f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're loading in the X-shaped radio sources from Proctor+2011\n",
    "\n",
    "proctor2011 = (Table.read('Tables/Proctor2011/table8.dat', readme = 'Tables/Proctor2011/ReadMe', format='ascii.cds')).to_pandas()\n",
    "\n",
    "# There is some overlap between Proctor+2011 and Cheung+2007. Need to match those!\n",
    "\n",
    "\n",
    "proctor2011['Name'] = proctor2011['FCG']\n",
    "proctor2011['Name2'] = proctor2011['FCG']\n",
    "#proctor2011['z1'] = proctor2011['z']\n",
    "#proctor2011['z2'] = proctor2011['z']\n",
    "#proctor2011['z1_type'] = proctor2011['n_z']\n",
    "#proctor2011['z2_type'] = proctor2011['n_z']\n",
    "\n",
    "# Now converting the naming convention to RA and Dec and adding some informative columns\n",
    "#name_to_coords(yang2019,proctor2011['Designation'])\n",
    "\n",
    "proctor2011['RA1'] = proctor2011['RAh'].astype(str) + ':' + proctor2011['RAm'].astype(str) + ':' + proctor2011['RAs'].astype(str)\n",
    "proctor2011['Dec1'] = proctor2011['DE-'].astype(str) + proctor2011['DEd'].astype(str) + ':' + proctor2011['DEm'].astype(str) + ':' + proctor2011['DEs'].astype(str)\n",
    "\n",
    "# And now converting to get the coordinates in degrees rather than sexagesimal...\n",
    "coordconvert = SkyCoord(ra = proctor2011['RA1'], dec = proctor2011['Dec1'], frame='icrs', unit = (u.hourangle, u.deg))\n",
    "\n",
    "proctor2011['RA1_deg'] = coordconvert.ra.degree\n",
    "proctor2011['Dec1_deg'] = coordconvert.dec.degree\n",
    "\n",
    "#proctor2011['Coordinates'] = proctor2011['SDSSID']#.str.slice(start=1) # Stripping the J\n",
    "#proctor2011['RA_test'] = proctor2011['Coordinates'].str.slice(start=1, stop=10) # Stripping the DEC parts \n",
    "#proctor2011['Dec_test'] = proctor2011['Coordinates'].str.slice(start=10, stop=19) # Stripping the RA parts\n",
    "#proctor2011['RA'] = proctor2011['RA_test'].str.slice(start=0, stop=2)+\":\"+proctor2011['RA_test'].str.slice(start=2, stop=4)+\":\"+proctor2011['RA_test'].str.slice(start=4, stop=9) # Putting together the RA coordinates separated by colons\n",
    "#proctor2011['Dec'] = proctor2011['Dec_test'].str.slice(start=0, stop=3)+\":\"+proctor2011['Dec_test'].str.slice(start=3, stop=5)+\":\"+proctor2011['Dec_test'].str.slice(start=5, stop=10) # Putting together the Dec coodinates separated by colons\n",
    "#yang2019.drop(columns=['Coordinates','RA_test','Dec_test'], inplace=True)\n",
    "\n",
    "# Adding in a second set of coordinates for the 'secondary'\n",
    "proctor2011['RA2'] = proctor2011['RA1']\n",
    "proctor2011['Dec2'] = proctor2011['Dec1']\n",
    "\n",
    "proctor2011['RA2_deg'] = proctor2011['RA1_deg']\n",
    "proctor2011['Dec2_deg'] = proctor2011['Dec1_deg']\n",
    "\n",
    "# Adding details about the coordinates\n",
    "proctor2011['Equinox'] = \"J2000\"\n",
    "proctor2011['Coordinate_waveband'] = \"Radio\"\n",
    "proctor2011['Coordinate_Source'] = \"FIRST\"\n",
    "\n",
    "proctor2011['System Type'] = 'Recoil Candidate'\n",
    "\n",
    "# Adding in some columns that we'll population via a Simbad or Ned search later\n",
    "proctor2011['Brightness1'] = -100\n",
    "proctor2011['Brightness_band1'] = -100\n",
    "proctor2011['Brightness_type1'] = -100\n",
    "\n",
    "proctor2011['Brightness2'] = -100\n",
    "proctor2011['Brightness_band2'] = -100\n",
    "proctor2011['Brightness_type2'] = -100\n",
    "\n",
    "# Adding in a column to denote the system separation as '-1' which I will take in this case to mean that it is \\\n",
    "# of order ~1 kpc or less, but is not currently determined.\n",
    "#proctor2011['Sep'] = 3 # arcseconds\n",
    "# Since these are candidates and we do not have a measure of separation, we'll use the 3'' diameter of the SDSS \\\n",
    "# fiber as an upper limit\n",
    "\n",
    "\n",
    "#proctor2011['Sep(kpc)'] = proctor2011['Sep']*((cosmo.arcsec_per_kpc_proper(proctor2011['z']))**(-1))\n",
    "\n",
    "\n",
    "# For the projected separation, we'll use the upper limit of 3'' to calculate an upper limit in units of kpc\n",
    "#proctor2011['delta_z'] = proctor2011['z1']-proctor2011['z2']\n",
    "#proctor2011['dV'] = (2.99e+5)*((1+proctor2011['z1'])**2 - (1+proctor2011['z2'])**2)/((1+proctor2011['z1'])**2+(1+proctor2011['z2'])**2)\n",
    "# dV will be zero until we include follow-up observations that show separate redshifts\n",
    "\n",
    "# Adding information about the paper and the selection method\n",
    "proctor2011['Selection Method'] = \"X-Shaped Radio Source\" #DPSELs\n",
    "proctor2011['Confirmation Method'] = \"-99\"\n",
    "proctor2011['Paper(s)'] = \"Proctor+2011\"\n",
    "proctor2011['BibCode(s)'] = \"2011ApJS..194...31P\"\n",
    "proctor2011['DOI(s)'] = \"https://doi.org/10.1088/0067-0049/194/2/31\"\n",
    "\n",
    "## And dropping any columns that we don't need....\n",
    "#yang2019.drop(labels=['SDSS','f_SDSS','Vel','logL','Type','Q','zr','zh'],\\\n",
    "#              axis=1, inplace=True)\n",
    "\n",
    "## Rearranging the columns and renaming columns now...\n",
    "#yang2019 = proctor2011[['System Type','Name','Name2','Selection Method','Confirmation Method','z','z1_type','z2',\\\n",
    "#                    'z2_type','RA', 'Dec', 'RA_deg','Dec_deg','RA2','Dec2','RA2_deg','Dec2_deg',\\\n",
    "#                    'Equinox','Coordinate_waveband','Coordinate_Source','Brightness1','Brightness_band1',\\\n",
    "#                    'Brightness_type1','Brightness2','Brightness_band2','Brightness_type2','Sep','Sep(kpc)',\\\n",
    "#                    'delta_z','dV','Paper(s)','BibCode(s)','DOI(s)']]\n",
    "#yang2019.columns=['System Type','Name1','Name2','Selection Method','Confirmation Method','z1','z1_type','z2',\\\n",
    "#                    'z2_type','RA1', 'Dec1', 'RA1_deg','Dec1_deg','RA2','Dec2','RA2_deg','Dec2_deg',\\\n",
    "#                    'Equinox','Coordinate_waveband','Coordinate_Source','Brightness1','Brightness_band1',\\\n",
    "#                    'Brightness_type1','Brightness2','Brightness_band2','Brightness_type2','Sep','Sep(kpc)',\\\n",
    "#                    'delta_z','dV','Paper(s)','BibCode(s)','DOI(s)']\n",
    "#\n",
    "\n",
    "# These two objects are flagged as having double-peaked emission lines\n",
    "#J0818+1508 J1554+3811\n",
    "\n",
    "\n",
    "#proctor2011\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed72248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ead074d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunique, tmatches, idx1, idx2 = match_tables_fib(cheung_master,proctor2011,5)\n",
    "\n",
    "# Adding the DOI, author, and bibcode info to all of the Smith+2010 rows here in the matches table...\n",
    "for index, row in tmatches.iterrows():\n",
    "    if row['Table_flag']!='Table2':\n",
    "        tmatches.at[index, 'Paper(s)'] += ' ; Proctor+2011'\n",
    "        tmatches.at[index, 'BibCode(s)'] += ' ; 2011ApJS..194...31P' \n",
    "        tmatches.at[index, 'DOI(s)'] += ' ; https://doi.org/10.1088/0067-0049/194/2/31'\n",
    "\n",
    "## Now clipping out all Smith+2010 rows from the matches table\n",
    "tmatches = tmatches[tmatches['Table_flag']!='Table2'].reset_index(drop=True)\n",
    "#\n",
    "## Concatenating everything together to generate a master table here\n",
    "profx = pd.concat([tmatches,tunique]).sort_values(by='Name').reset_index(drop=True)\n",
    "profx.drop(labels=['index','Table_flag'], axis=1, inplace=True) #'level_0',\n",
    "\n",
    "# There are 20 matches between these two tables\n",
    "#print(len(tmatches))\n",
    "\n",
    "# Verified that this works properly and proctor+ is attached to the correct number of objects in the final table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0b2c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#profx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e8231e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're adding in the information from Roberts+2018\n",
    "\n",
    "roberts2018 = (Table.read('Tables/Roberts2018/table1.dat', readme = 'Tables/Roberts2018/ReadMe', format='ascii.cds')).to_pandas()\n",
    "#Table 2 contains information on the VLA imaging\n",
    "#Table 4 includes peak intensity information and figure tags\n",
    "\n",
    "roberts_objs = roberts2018['[C2007]'].tolist()\n",
    "\n",
    "for index, row in profx.iterrows():\n",
    "    if row['Name'] in roberts_objs:\n",
    "        #print('True')\n",
    "        profx.at[index, 'Paper(s)'] += ' ; Roberts+2018'\n",
    "        profx.at[index, 'BibCode(s)'] += ' ; 2018ApJ...852...47R' \n",
    "        profx.at[index, 'DOI(s)'] += ' ; https://doi.org/10.3847/1538-4357/aa9c49'\n",
    "\n",
    "# Verified that this matching process works\n",
    "# Just go back and verify that the correct number of objects is actually matched\n",
    "# profx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67919903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2719adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're adding in the information from Saripalli+2018\n",
    "# Table 1 has redshift info, optical classes, XRG classification schemes, and size of radio extent\n",
    "# Table 2 has information on hosts, emission lines, and radio power\n",
    "\n",
    "# Here we're adding in the information from Roberts+2018\n",
    "\n",
    "saripalli2018 = (Table.read('Tables/Saripalli2018/table1.dat', readme = 'Tables/Saripalli2018/ReadMe', format='ascii.cds')).to_pandas()\n",
    "#Table 2 contains information on the VLA imaging\n",
    "#Table 4 includes peak intensity information and figure tags\n",
    "\n",
    "sar_objs = saripalli2018['[C2007]'].tolist()\n",
    "\n",
    "for index, row in profx.iterrows():\n",
    "    if row['Name'] in sar_objs:\n",
    "        #print('True')\n",
    "        profx.at[index, 'Paper(s)'] += ' ; Saripalli+2018'\n",
    "        profx.at[index, 'BibCode(s)'] += ' ; 2018ApJ...852...48S' \n",
    "        profx.at[index, 'DOI(s)'] += ' ; https://doi.org/10.3847/1538-4357/aa9c4b'\n",
    "\n",
    "sarobjs = ['J0033−0149','J0049+0059','J0143−0119','J0821+2922','J1111+4050','J1128+1919','J1201−0703','J1210+1121','J1227+2155','J1330−0206','J1339−0016','J1522+4527','J2226+0125']      \n",
    "for index, row in profx.iterrows():\n",
    "    if row['Name'] in sar_objs:\n",
    "        #print('True')\n",
    "        profx.at[index, 'Paper(s)'] += ' ; Saripalli+2018'\n",
    "        profx.at[index, 'BibCode(s)'] += ' ; 2018ApJ...852...48S' \n",
    "        profx.at[index, 'DOI(s)'] += ' ; https://doi.org/10.3847/1538-4357/aa9c4b'\n",
    "        profx.at[index, 'Notes'] += ' Saripalli+ reject this object for reasons listed in their Table 3.'\n",
    "            \n",
    "# This looks like it's all matched properly\n",
    "# I've also verified that the correct number of objects int he final table are flagged having been examined by \\\n",
    "# Roberts+ and Saripalli+\n",
    "\n",
    "# profx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704fd39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a6a1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now loading in the new X-shaped radio source from Yang+2019\n",
    "\n",
    "# GO INTO YANG+ AND FLAG OBJECTS THEY QUOTE AS BEING DISCOVERED PREVIOUSLY!\n",
    "\n",
    "\n",
    "yang2019t1 = (Table.read('Tables/Yang2019/table2.dat', readme = 'Tables/Yang2019/ReadMe', format='ascii.cds')).to_pandas()\n",
    "yang2019t2 = (Table.read('Tables/Yang2019/table3.dat', readme = 'Tables/Yang2019/ReadMe', format='ascii.cds')).to_pandas()\n",
    "\n",
    "yang2019t1['Name'] = yang2019t1['SName']\n",
    "yang2019t1['Name2'] = yang2019t1['SName']\n",
    "yang2019t1['z1'] = yang2019t1['z']\n",
    "yang2019t1['z2'] = yang2019t1['z']\n",
    "yang2019t1['z1_type'] = yang2019t1['n_z']\n",
    "yang2019t1['z2_type'] = yang2019t1['n_z']\n",
    "\n",
    "# Now converting the naming convention to RA and Dec and adding some informative columns\n",
    "#name_to_coords(yang2019,yang2019t1['Designation'])\n",
    "\n",
    "yang2019t1['RA1'] = yang2019t1['RAh'].astype(str) + ':' + yang2019t1['RAm'].astype(str) + ':' + yang2019t1['RAs'].astype(str)\n",
    "yang2019t1['Dec1'] = yang2019t1['DE-'].astype(str) + yang2019t1['DEd'].astype(str) + ':' + yang2019t1['DEm'].astype(str) + ':' + yang2019t1['DEs'].astype(str)\n",
    "\n",
    "# And now converting to get the coordinates in degrees rather than sexagesimal...\n",
    "coordconvert = SkyCoord(ra = yang2019t1['RA1'], dec = yang2019t1['Dec1'], frame='icrs', unit = (u.hourangle, u.deg))\n",
    "\n",
    "yang2019t1['RA1_deg'] = coordconvert.ra.degree\n",
    "yang2019t1['Dec1_deg'] = coordconvert.dec.degree\n",
    "\n",
    "#yang2019t1['Coordinates'] = yang2019t1['SDSSID']#.str.slice(start=1) # Stripping the J\n",
    "#yang2019t1['RA_test'] = yang2019t1['Coordinates'].str.slice(start=1, stop=10) # Stripping the DEC parts \n",
    "#yang2019t1['Dec_test'] = yang2019t1['Coordinates'].str.slice(start=10, stop=19) # Stripping the RA parts\n",
    "#yang2019t1['RA'] = yang2019t1['RA_test'].str.slice(start=0, stop=2)+\":\"+yang2019t1['RA_test'].str.slice(start=2, stop=4)+\":\"+yang2019t1['RA_test'].str.slice(start=4, stop=9) # Putting together the RA coordinates separated by colons\n",
    "#yang2019t1['Dec'] = yang2019t1['Dec_test'].str.slice(start=0, stop=3)+\":\"+yang2019t1['Dec_test'].str.slice(start=3, stop=5)+\":\"+yang2019t1['Dec_test'].str.slice(start=5, stop=10) # Putting together the Dec coodinates separated by colons\n",
    "#yang2019.drop(columns=['Coordinates','RA_test','Dec_test'], inplace=True)\n",
    "\n",
    "# Adding in a second set of coordinates for the 'secondary'\n",
    "yang2019t1['RA2'] = yang2019t1['RA1']\n",
    "yang2019t1['Dec2'] = yang2019t1['Dec1']\n",
    "\n",
    "yang2019t1['RA2_deg'] = yang2019t1['RA1_deg']\n",
    "yang2019t1['Dec2_deg'] = yang2019t1['Dec1_deg']\n",
    "\n",
    "# Adding details about the coordinates\n",
    "yang2019t1['Equinox'] = \"J2000\"\n",
    "yang2019t1['Coordinate_waveband'] = \"Optical\"\n",
    "yang2019t1['Coordinate_Source'] = \"SDSS\"\n",
    "\n",
    "yang2019t1['System Type'] = 'Binary AGN Candidate'\n",
    "\n",
    "# Adding in some columns that we'll population via a Simbad or Ned search later\n",
    "yang2019t1['Brightness1'] = -100\n",
    "yang2019t1['Brightness_band1'] = -100\n",
    "yang2019t1['Brightness_type1'] = -100\n",
    "\n",
    "yang2019t1['Brightness2'] = -100\n",
    "yang2019t1['Brightness_band2'] = -100\n",
    "yang2019t1['Brightness_type2'] = -100\n",
    "\n",
    "# Adding in a column to denote the system separation as '-1' which I will take in this case to mean that it is \\\n",
    "# of order ~1 kpc or less, but is not currently determined.\n",
    "#yang2019t1['Sep'] = 3 # arcseconds\n",
    "# Since these are candidates and we do not have a measure of separation, we'll use the 3'' diameter of the SDSS \\\n",
    "# fiber as an upper limit\n",
    "\n",
    "\n",
    "#yang2019t1['Sep(kpc)'] = yang2019t1['Sep']*((cosmo.arcsec_per_kpc_proper(yang2019t1['z']))**(-1))\n",
    "\n",
    "\n",
    "# For the projected separation, we'll use the upper limit of 3'' to calculate an upper limit in units of kpc\n",
    "#yang2019t1['delta_z'] = yang2019t1['z1']-yang2019t1['z2']\n",
    "#yang2019t1['dV'] = (2.99e+5)*((1+yang2019t1['z1'])**2 - (1+yang2019t1['z2'])**2)/((1+yang2019t1['z1'])**2+(1+yang2019t1['z2'])**2)\n",
    "# dV will be zero until we include follow-up observations that show separate redshifts\n",
    "\n",
    "# Adding information about the paper and the selection method\n",
    "yang2019t1['Selection Method'] = \"Strong X-Shaped Radio Source\" #DPSELs\n",
    "yang2019t1['Confirmation Method'] = \"-99\"\n",
    "yang2019t1['Paper(s)'] = \"Yang+2019 ; Joshi+2019\"\n",
    "yang2019t1['BibCode(s)'] = \"2019ApJS..245...17Y ; 2019ApJ...887..266J\"\n",
    "yang2019t1['DOI(s)'] = \"https://doi.org/10.3847/1538-4365/ab4811 ; https://doi.org/ 10.3847/1538-4357/ab536f\"\n",
    "yang2019t1['Notes'] = \" \"\n",
    "\n",
    "\n",
    "## And dropping any columns that we don't need....\n",
    "#yang2019.drop(labels=['SDSS','f_SDSS','Vel','logL','Type','Q','zr','zh'],\\\n",
    "#              axis=1, inplace=True)\n",
    "\n",
    "## Rearranging the columns and renaming columns now...\n",
    "#yang2019 = yang2019t1[['System Type','Name','Name2','Selection Method','Confirmation Method','z','z1_type','z2',\\\n",
    "#                    'z2_type','RA', 'Dec', 'RA_deg','Dec_deg','RA2','Dec2','RA2_deg','Dec2_deg',\\\n",
    "#                    'Equinox','Coordinate_waveband','Coordinate_Source','Brightness1','Brightness_band1',\\\n",
    "#                    'Brightness_type1','Brightness2','Brightness_band2','Brightness_type2','Sep','Sep(kpc)',\\\n",
    "#                    'delta_z','dV','Paper(s)','BibCode(s)','DOI(s)']]\n",
    "#yang2019.columns=['System Type','Name1','Name2','Selection Method','Confirmation Method','z1','z1_type','z2',\\\n",
    "#                    'z2_type','RA1', 'Dec1', 'RA1_deg','Dec1_deg','RA2','Dec2','RA2_deg','Dec2_deg',\\\n",
    "#                    'Equinox','Coordinate_waveband','Coordinate_Source','Brightness1','Brightness_band1',\\\n",
    "#                    'Brightness_type1','Brightness2','Brightness_band2','Brightness_type2','Sep','Sep(kpc)',\\\n",
    "#                    'delta_z','dV','Paper(s)','BibCode(s)','DOI(s)']\n",
    "#\n",
    "\n",
    "# These two objects are flagged as having double-peaked emission lines\n",
    "#J0818+1508 J1554+3811\n",
    "\n",
    "#yang2019t1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa8f3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunique, tmatches, idx1, idx2 = match_tables_fib(profx,yang2019t1,5)\n",
    "\n",
    "# There are 12 matches between Yang+ and the main table\n",
    "\n",
    "#tmatches\n",
    "# Adding the DOI, author, and bibcode info to all of the Liu+2010 rows here in the matches table...\n",
    "for index, row in tmatches.iterrows():\n",
    "    if row['Paper(s)']!='Yang+2019 ; Joshi+2019':\n",
    "        tmatches.at[index, 'Paper(s)'] += ' ; Yang+2019 ; Joshi+2019'\n",
    "        tmatches.at[index, 'BibCode(s)'] += ' ; 2019ApJS..245...17Y ; 2019ApJ...887..266J' \n",
    "        tmatches.at[index, 'DOI(s)'] += ' ; https://doi.org/10.3847/1538-4365/ab4811 ; https://doi.org/ 10.3847/1538-4357/ab536f'\n",
    "        #tmatches.at[index, 'Notes'] += ''\n",
    "        \n",
    "# Now clipping out all Comerford+2013 rows from the matches table\n",
    "tmatches = tmatches[tmatches['Paper(s)']!='Yang+2019 ; Joshi+2019'].reset_index(drop=True)\n",
    "\n",
    "# Concatenating everything together to generate a master table here\n",
    "profx = pd.concat([tmatches,tunique]).sort_values(by='Name').reset_index(drop=True)\n",
    "profx.drop(labels=['index'], axis=1, inplace=True)\n",
    "#tunique\n",
    "\n",
    "#profx\n",
    "\n",
    "# This process appears to work properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f129a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now loading in the new X-shaped radio source from Yang+2019\n",
    "yang2019t2['Name'] = yang2019t2['SName']\n",
    "yang2019t2['Name2'] = yang2019t2['SName']\n",
    "yang2019t2['z1'] = yang2019t2['z']\n",
    "yang2019t2['z2'] = yang2019t2['z']\n",
    "yang2019t2['z1_type'] = yang2019t2['n_z']\n",
    "yang2019t2['z2_type'] = yang2019t2['n_z']\n",
    "\n",
    "# Now converting the naming convention to RA and Dec and adding some informative columns\n",
    "#name_to_coords(yang2019,yang2019t2['Designation'])\n",
    "\n",
    "yang2019t2['RA1'] = yang2019t2['RAh'].astype(str) + ':' + yang2019t2['RAm'].astype(str) + ':' + yang2019t2['RAs'].astype(str)\n",
    "yang2019t2['Dec1'] = yang2019t2['DE-'].astype(str) + yang2019t2['DEd'].astype(str) + ':' + yang2019t2['DEm'].astype(str) + ':' + yang2019t2['DEs'].astype(str)\n",
    "\n",
    "# And now converting to get the coordinates in degrees rather than sexagesimal...\n",
    "coordconvert = SkyCoord(ra = yang2019t2['RA1'], dec = yang2019t2['Dec1'], frame='icrs', unit = (u.hourangle, u.deg))\n",
    "\n",
    "yang2019t2['RA1_deg'] = coordconvert.ra.degree\n",
    "yang2019t2['Dec1_deg'] = coordconvert.dec.degree\n",
    "\n",
    "#yang2019t2['Coordinates'] = yang2019t2['SDSSID']#.str.slice(start=1) # Stripping the J\n",
    "#yang2019t2['RA_test'] = yang2019t2['Coordinates'].str.slice(start=1, stop=10) # Stripping the DEC parts \n",
    "#yang2019t2['Dec_test'] = yang2019t2['Coordinates'].str.slice(start=10, stop=19) # Stripping the RA parts\n",
    "#yang2019t2['RA'] = yang2019t2['RA_test'].str.slice(start=0, stop=2)+\":\"+yang2019t2['RA_test'].str.slice(start=2, stop=4)+\":\"+yang2019t2['RA_test'].str.slice(start=4, stop=9) # Putting together the RA coordinates separated by colons\n",
    "#yang2019t2['Dec'] = yang2019t2['Dec_test'].str.slice(start=0, stop=3)+\":\"+yang2019t2['Dec_test'].str.slice(start=3, stop=5)+\":\"+yang2019t2['Dec_test'].str.slice(start=5, stop=10) # Putting together the Dec coodinates separated by colons\n",
    "#yang2019.drop(columns=['Coordinates','RA_test','Dec_test'], inplace=True)\n",
    "\n",
    "# Adding in a second set of coordinates for the 'secondary'\n",
    "yang2019t2['RA2'] = yang2019t2['RA1']\n",
    "yang2019t2['Dec2'] = yang2019t2['Dec1']\n",
    "\n",
    "yang2019t2['RA2_deg'] = yang2019t2['RA1_deg']\n",
    "yang2019t2['Dec2_deg'] = yang2019t2['Dec1_deg']\n",
    "\n",
    "# Adding details about the coordinates\n",
    "yang2019t2['Equinox'] = \"J2000\"\n",
    "yang2019t2['Coordinate_waveband'] = \"Optical\"\n",
    "yang2019t2['Coordinate_Source'] = \"SDSS\"\n",
    "\n",
    "yang2019t2['System Type'] = 'Binary AGN Candidate'\n",
    "\n",
    "# Adding in some columns that we'll population via a Simbad or Ned search later\n",
    "yang2019t2['Brightness1'] = -100\n",
    "yang2019t2['Brightness_band1'] = -100\n",
    "yang2019t2['Brightness_type1'] = -100\n",
    "\n",
    "yang2019t2['Brightness2'] = -100\n",
    "yang2019t2['Brightness_band2'] = -100\n",
    "yang2019t2['Brightness_type2'] = -100\n",
    "\n",
    "# Adding in a column to denote the system separation as '-1' which I will take in this case to mean that it is \\\n",
    "# of order ~1 kpc or less, but is not currently determined.\n",
    "#yang2019t2['Sep'] = 3 # arcseconds\n",
    "# Since these are candidates and we do not have a measure of separation, we'll use the 3'' diameter of the SDSS \\\n",
    "# fiber as an upper limit\n",
    "\n",
    "\n",
    "#yang2019t2['Sep(kpc)'] = yang2019t2['Sep']*((cosmo.arcsec_per_kpc_proper(yang2019t2['z']))**(-1))\n",
    "\n",
    "\n",
    "# For the projected separation, we'll use the upper limit of 3'' to calculate an upper limit in units of kpc\n",
    "#yang2019t2['delta_z'] = yang2019t2['z1']-yang2019t2['z2']\n",
    "#yang2019t2['dV'] = (2.99e+5)*((1+yang2019t2['z1'])**2 - (1+yang2019t2['z2'])**2)/((1+yang2019t2['z1'])**2+(1+yang2019t2['z2'])**2)\n",
    "# dV will be zero until we include follow-up observations that show separate redshifts\n",
    "\n",
    "# Adding information about the paper and the selection method\n",
    "yang2019t2['Selection Method'] = \"Probable X-Shaped Radio Source\" #DPSELs\n",
    "yang2019t2['Confirmation Method'] = \"-99\"\n",
    "yang2019t2['Paper(s)'] = \"Yang+2019\"\n",
    "yang2019t2['BibCode(s)'] = \"2019ApJS..245...17Y\"\n",
    "yang2019t2['DOI(s)'] = \"https://doi.org/10.3847/1538-4365/ab4811\"\n",
    "yang2019t2['Notes'] = \" \"\n",
    "\n",
    "\n",
    "## And dropping any columns that we don't need....\n",
    "#yang2019.drop(labels=['SDSS','f_SDSS','Vel','logL','Type','Q','zr','zh'],\\\n",
    "#              axis=1, inplace=True)\n",
    "\n",
    "## Rearranging the columns and renaming columns now...\n",
    "#yang2019 = yang2019t2[['System Type','Name','Name2','Selection Method','Confirmation Method','z','z1_type','z2',\\\n",
    "#                    'z2_type','RA', 'Dec', 'RA_deg','Dec_deg','RA2','Dec2','RA2_deg','Dec2_deg',\\\n",
    "#                    'Equinox','Coordinate_waveband','Coordinate_Source','Brightness1','Brightness_band1',\\\n",
    "#                    'Brightness_type1','Brightness2','Brightness_band2','Brightness_type2','Sep','Sep(kpc)',\\\n",
    "#                    'delta_z','dV','Paper(s)','BibCode(s)','DOI(s)']]\n",
    "#yang2019.columns=['System Type','Name1','Name2','Selection Method','Confirmation Method','z1','z1_type','z2',\\\n",
    "#                    'z2_type','RA1', 'Dec1', 'RA1_deg','Dec1_deg','RA2','Dec2','RA2_deg','Dec2_deg',\\\n",
    "#                    'Equinox','Coordinate_waveband','Coordinate_Source','Brightness1','Brightness_band1',\\\n",
    "#                    'Brightness_type1','Brightness2','Brightness_band2','Brightness_type2','Sep','Sep(kpc)',\\\n",
    "#                    'delta_z','dV','Paper(s)','BibCode(s)','DOI(s)']\n",
    "#\n",
    "\n",
    "# this is flagged as having double-peaked emission lines:\n",
    "# J1247+1948\n",
    "\n",
    "\n",
    "#yang2019t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05bc878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunique, tmatches, idx1, idx2 = match_tables_fib(profx,yang2019t2,5)\n",
    "\n",
    "# There are 6 matches between the yang2019t2 table and the main table\n",
    "\n",
    "#tmatches\n",
    "# Adding the DOI, author, and bibcode info to all of the Liu+2010 rows here in the matches table...\n",
    "for index, row in tmatches.iterrows():\n",
    "    if row['Paper(s)']!='Yang+2019':\n",
    "        tmatches.at[index, 'Paper(s)'] += ' ; Yang+2019'\n",
    "        tmatches.at[index, 'BibCode(s)'] += ' ; 2019ApJS..245...17Y' \n",
    "        tmatches.at[index, 'DOI(s)'] += ' ; https://doi.org/10.3847/1538-4365/ab4811'\n",
    "        #tmatches.at[index, 'Notes'] += ''\n",
    "\n",
    "# Now clipping out all Comerford+2013 rows from the matches table\n",
    "tmatches = tmatches[tmatches['Paper(s)']!='Yang+2019'].reset_index(drop=True)\n",
    "\n",
    "# Concatenating everything together to generate a master table here\n",
    "profx = pd.concat([tmatches,tunique]).sort_values(by='Name').reset_index(drop=True)\n",
    "profx.drop(labels=['index'], axis=1, inplace=True)\n",
    "#tunique\n",
    "\n",
    "#profx\n",
    "\n",
    "# This process appears to work properly\n",
    "# I have examined the final output table, and we do indeed have 290 sources, as reported by Yang+.\n",
    "# I have also confirmed that 106 objects were correclt flagged as being examined by Joshi+2019 as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72a75dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "621ef21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True J0113+0106\n",
      "True J0115-0000\n",
      "True J0702+5002\n",
      "True J0859-0433\n",
      "True J0914+1715\n",
      "True J0917+0523\n",
      "True J0924+4233\n",
      "True J1055-0707\n",
      "True J1218+1955\n",
      "True J1309-0012\n",
      "True J1339-0016\n",
      "True J1406-0154\n",
      "True J1430+5217\n",
      "True J1600+2058\n",
      "True J1606+0000\n"
     ]
    }
   ],
   "source": [
    "# Adding in the bib information for the Lal+2019 targets, which were drawn from the cheung+07 list\n",
    "\n",
    "lal2019 = ['J0113+0106','J0115-0000','J0702+5002','J0859-0433','J0914+1715','J0917+0523','J0924+4233','J1055-0707','J1130+0058','J1218+1955','J1309-0012','J1339-0016','J1406-0154','J1430+5217','J1600+2058','J1606+0000']\n",
    "\n",
    "for index, row in profx.iterrows():\n",
    "    if row['Name'] in lal2019:\n",
    "        print('True',row['Name'])\n",
    "        profx.at[index, 'Paper(s)'] += ' ; Lal+2019'\n",
    "        profx.at[index, 'BibCode(s)'] += ' ; 2019AJ....157..195L' \n",
    "        profx.at[index, 'DOI(s)'] += ' ; https://doi.org/10.3847/1538-3881/ab1419'\n",
    "        profx.at[index, 'Notes'] += ' Lal+2019 obtained additional radio imaging.'\n",
    "            \n",
    "#profx\n",
    "\n",
    "# Verified that this matching process works and the correct number of objects list Lal+2019 in the final table.\n",
    "\n",
    "# **************************\n",
    "# EXCEPT: J1130+0058 COMES FROM WANG+2003 NOT FROM CHEUNG+2007, SO IT IS NOT IN THE MAIN TABLE PRIOR TO THIS\n",
    "# We will need to manually include Wang+2003\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57372ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58016183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now saving profx as a final table for output\n",
    "\n",
    "profx.to_csv('Xshaped_radio_samples.csv', sep=',', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc818ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8ce21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50672e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
