{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61be427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in packages for pandas, astropy, etc. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Column, MaskedColumn\n",
    "from astropy.io.ascii import masked\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.cosmology import LambdaCDM \n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.sdss import SDSS\n",
    "from astropy.coordinates import match_coordinates_sky\n",
    "import os \n",
    "import json \n",
    "\n",
    "cosmo = LambdaCDM(H0=70, Om0=0.3, Ode0=0.7) #Creating our choice of cosmology here...\n",
    "\n",
    "pd.set_option('display.max_columns', 300) # Setting max number of rows per df to be the size of the df\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "afcbadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting log\n",
    "# 6 Dec. 2023\n",
    "# Going to try to keep better track of changes as I'm doing them so I can add them as remarks to my commit notes\n",
    "#\n",
    "# Reformatting, reordering, and correcting system type labels. This involves removing duplicate entries, fixing \\\n",
    "# errors where a slash was missed during the matching process, system types missing altogether, and slimming down \\\n",
    "# the variations. For example, binary quasars --> dual AGNs or candidates, AGN recoil candidate --> \\\n",
    "# recoil candidate, etc., and we're removing things like 'fast jet realignment' and 'double-peak emitter'\n",
    "# \n",
    "# These classes are going to be alphabetized from now on within the System Type cell. \n",
    "#\n",
    "#\n",
    "# I've noticed I accidently removed the separations for the Hennawi+2010 targets because they were referred to as \\\n",
    "# DelT (and vel diff was DelV). I've added the separations back in. Tytler+2009 is also missing info, but I think \\\n",
    "# I accidently removed it from their table when matching. I also corrected bibcodes --> BibCodes for Tytler+2009 \\\n",
    "# and Kirkman+2008. \n",
    "#\n",
    "# Corrected the missing angular separations for Findlay+2018 (and converted from arcmin to arcsec). Also added \\\n",
    "# in coordinate waveband and source in for (SDSS or ATLAS), equinox, and changed Dual AGN--> Quasar Pair\n",
    "# We'll remove pairs and keep genuine duals as we format here... Also ajusted the selection and confirmation \\\n",
    "# methods columns. \n",
    "#\n",
    "# Added in the missing separations for Hennawi+2006 (removed them by accident). Correcting the selection and \\\n",
    "# confirmation methods of Hennawi+2006. This includes making adjustments to the t2 table. Separations have also \\\n",
    "# now been added back in for Hennawi+2010. These were being read in as delT_1\n",
    "#\n",
    "# In binary quasar notebook, also went back and fixed where I accidently was throwing out the BibCode(s) column\n",
    "#\n",
    "# Note for Hennawi's targets, we still have a problem. I was able to remove duplicates before, but I was not \\\n",
    "# careful about paying attention to whether the coordinates and redshifts referred to the same objects, or at least, \\\n",
    "# I have no record of being that careful. I will eventually need to go through by hand for all of the duplicates and \\\n",
    "# ensure the redshifts and coordinates do indeed refer to the same objects. For now, we will ignore this problem. \n",
    "#\n",
    "# I believe I have now also fixed all of the equinox, coordinate waveband, and cordinate source info that was missing \\\n",
    "# from the binary quasar notebook (added back in where ever possible); made '1' and '2' columns for these entries\n",
    "#\n",
    "# Corrected the missing column in the Koss+2012 and Hainline+ listing\n",
    "#\n",
    "# Modified the selection method for targets from Yang+2019. These are no longer 'strong' and 'probable' X-shaped \\\n",
    "# radio sources; we list them simply as X-shaped radio sources. \n",
    "#\n",
    "# Corrected the equinox, coordinate waveband, and coordinate course listings for X-shaped radio sources. Wrong \\\n",
    "# column names for some, others had wrong info (Yang+2019 for example had coordinates listed as optical and SDSS \\\n",
    "# rather than radio and VLA / FIRST)\n",
    "#\n",
    "# In individual table: (1) changed all 'Recoiling AGN Candidate' tags to 'Recoil Candidate'; (2) since X-shaped \\\n",
    "# radio sources have been claimed to be either recoiling AGNs/SMBHs AND binary AGNs, ALL X-shaped radio sources \\\n",
    "# have a 'recoil candidate' and a 'binary AGN candidate' tag. This is also the case in the actual X-shaped radio \\\n",
    "# source notebook; (3) removed use of 'double-peaked emitter candidate' from system types. no need to include.\n",
    "#\n",
    "# Appended '1' to all equinox, coordinate waveband, and coordinate source columns in varstrometry notebook. Also\n",
    "# added in the z1 column (using the z column) in the Orosz table. No z column in the Hwang table, though. I have\\\n",
    "# now corrected issues with the Orosz+ table; RA1 and Dec1 have been added in, and RA2, Dec2, and Name2 have been \\\n",
    "# marked as -99 since no counterparts are currently known. Name2, RA2, Dec2, and the degree versions for the \\\n",
    "# Hwang+ table has also been flagged as -99. Note, the name flags are string(-99). RA1 and Dec1 added as well.\n",
    "#\n",
    "# Appended '1' to all equinox, coordinate waveband, and coordinate source columns in binary periodicity notebook.\n",
    "# Also now added in a z1 column\n",
    "#\n",
    "# NEED TO ADD SELECTION METHOD INFO FOR THE MAJORITY OF LENS SELECTED SOURCES (ETC INADA 2008)\n",
    "#\n",
    "# In the offset eission line notebook, I've now added in the '1' entries for equinox, waveband, and source\n",
    "#\n",
    "# In the double-peaked notebook: (1) added 'candidate' to the object examined by Nandi+; (2) changed equinox, \\\n",
    "# coordinate waveband, and coordinate source columns to have '1' appended at the end; (3) added back in  the\\\n",
    "# redshift 1 column. All redshift 2s were verified to be identical to z1, and thenm overwritten to '-99' along \\\n",
    "# with the spec type and the dV entries. I also now fixed the issue of missing redshifts and coordinates for \\\n",
    "# a good chunk of the Yuan+2016 targets. The z column had been broken into z_x and z_y for some reason, so \\\n",
    "# =yuan2016['z'] obviously didnt work (I guess I coerced the errors away here by accident). Also added in the \\\n",
    "# sexagesimal format for coordinates under RA and Dec, which are then converted to RA1 and Dec1 at the end like \\\n",
    "# usual.\n",
    "#\n",
    "# In the offset broad line binary notebook: added in '1' and '2' entries for equinox, waveband, and source, and \\\n",
    "# verified that there are z1 columns. Redshift 2s were verified to be identical to z1s and overwritten by '-99'. \\\n",
    "# Spec types and dVs were also overwritte, except for the dVs from Kim+2016, which were based on Halpha.\n",
    "#\n",
    "# In the match all catalogs notebook, I think I fixed the issue where confirmation methods and names were being \\\n",
    "# overwritten by accident for one or two objects. I've also now fixed the issue where a system type flag from one \\\n",
    "# table was beeing added to the MAC without a delimiter.\n",
    "#\n",
    "# The dual quasars from lens searches seems okay for now, but I'll be checking for issues tomorrow (today) when \\\n",
    "# I output the latest version of the DR.\n",
    "#\n",
    "# Corrected the improper system type adding in the match all catalogs notebook. \n",
    "# In binary quasar notebook, changed 'quasar pairs' to quasar pair.\n",
    "# In individual objects table, changed the Lusso+2019 target from dual quasar to dual agn. This will probably \\\n",
    "# get changed back to something else since this object is likely not a merger induced 'dual'\n",
    "#\n",
    "#\n",
    "# In the lens matching notebook: I have now reformatted the redshift columns for Lemon2020 (z1-z2 because they \\\n",
    "# are NIQs). For cases of missing RA and Decs, I made sure to change it from str(-99) to -99. Reformatted Lemon \\\n",
    "# 2019 and 2018 as well, adjusting the redshifts for 1 and 2 (adding in z1, and making sure z1=z2 for NIQs), and \\\n",
    "# adjusted the string vs nonstring for coordinates of 2. Added in Name1 for Agnello and adjusted the 2 coords to \\\n",
    "# non strings. Agnello already has a redshift 1 column. Adjusted coord for 2 for Spiniello. I've made adjustments \\\n",
    "# to the eftek2017 table; I'd only previously adjusted z1 based on if z1<0, but now I adjust both z1 and 2 based \\\n",
    "# on the -1 flag, and I also modify the z type. I've formatted some of the equinox, waveband, and source entries \\\n",
    "# in more2016. See notes below about the Inada tables; I have done some major reformatting of the Inada csv input \\\n",
    "# files as well as adding for loopd top overwrite bad redshift, z type, and coordinate cells. I've finished adding \\\n",
    "# back in the (largely blank) notes column and finalizing changes to the lens notebook.\n",
    "#\n",
    "# It looks like some inconclusive pairs from some of Lemon's works are included (from 2019 I think) while others \\\n",
    "# (like in 2018) are excluded, even those not listed as being possible stars. We will need to come back to this \\\n",
    "# in a later release...\n",
    "#\n",
    "# Discovered a major issue wit the Inada2010t3 table. I had not properly accounted for redshifts that were 0 or \\\n",
    "# negative flags, and I cut on dV. As far as I am aware, this is the only time I did this in that notebook. This \\\n",
    "# threw out a bunch of objects, and several of these DO match with the BQ lists. I have now output that list of \\\n",
    "# 'lost' objects as a separate .csv and I will load it in and match it against the MAC in the matching catalog \\\n",
    "# notebook. Evidently I did the same thing to the 2012 notebook. I've output another .csv file for those 'lost' \\\n",
    "# sources as well. I've double-checked the formatting of the Inada+ cells (and the input files) to make sure the \\\n",
    "# redshift columns are fine and that coordinate columns to not contain strings. I've also added in aseveral for \\\n",
    "# loops to overwrite bad redshift values and bad redshift type entries. \n",
    "#\n",
    "# In the catalog matching notebook, I now have addition cells at the end that match the missing objects from Inada \\\n",
    "# 2010 and 2012 back in, and concatenates the remaining objects with the MAC main tables.\n",
    "#\n",
    "#\n",
    "# found and fixed a bug in the match catalogs. I had indiv instead of indiv_x in a few instances when matching \\\n",
    "# the individual tables against the main table.\n",
    "\n",
    "# In the X-shaped radio source noteook: corrected the seleciton method for one of the cheung2007 tables. I've \\\n",
    "# also just updated the cell that adds Roberts+ info to the Cheung+ targets. It now grabs the redshifts from \\\n",
    "# Roberts+ if there is no redshift from Cheung+.\n",
    "\n",
    "# In the individual table, I've now added a redshift for NGC 1068\n",
    "# Adjusted the matching stuff for the Barrows+2011 target so that a secondary z and name are not adopted\n",
    "# Added 'bulge' and 'red blob' in name1 and name2 for the Markakis+ target\n",
    "\n",
    "# Just realized that I was starting to adjust the RA and Dec entries in my notebooks (like marking duplicate RA \\\n",
    "# and Dec 2 as -99), but I CANNOT do that without messing up the total matching notebook, because then these \\\n",
    "# objects will be placed in the MACnoRA2 table and will be matched differently. \n",
    "\n",
    "#\n",
    "# Just discovered an issue with the varstrometry table from Hwang+; I didn't realize it at the time, but they have \\\n",
    "# duplicate entries, because where objects had two GAIA matches, they placed the second match on a second row \\\n",
    "# instead of using separate columns... \n",
    "#    At this point, it might be easier to just go in and manually correct the secondary coordinates and drop the \\\n",
    "# 'duplicate rows'... we'll have to see...\n",
    "#\n",
    "#\n",
    "# Another issue noticed: Ra and Dec values for gattano are -99 for some reason, but I can see matches with \\\n",
    "#    Inada+2010.... need to look into this issue...\n",
    "#\n",
    "# Corrected the coordinates for the Wang+2010 IRAS target. Also correcting the Pindor coordinates in the \\\n",
    "# individual table (since in the matching script I have it overwrite from the individual table)\n",
    "\n",
    "# WE NEED TO DOUBLE CHECK WHY DV AND SEP IS NOT TAKEN FROM FU2012T3 AND T4!S\n",
    "#\n",
    "\n",
    "# Down below, I've now finished overwriting all of the duplicate Name2 values in the binary/recoil table (there \\\n",
    "# are some dual candidates int hat table that weren't piocked up by the other table, but that's okay)\n",
    "\n",
    "# As of 18 December, I am now adding in a confidence flag column. It will start as -99, and change to our -1-->1 \\\n",
    "# system as we modify the flags for samples and individual targets\n",
    "\n",
    "\n",
    "# pindor+2006 individual target, not overlapping with hennawi, has secondary coordinates relative to first\n",
    "\n",
    "\n",
    "\n",
    "# Changes following 2 Jan 2024\n",
    "\n",
    "# inada 2008 is missing the z types\n",
    "# In Inada2008 table 2, I've fixed the missing z2 listing for SDSSJ100229.46+444942.7 (it is now -99)\n",
    "# Within this notebook, I am going thorugh and by Name1 assigning the missing z type flags for Inada 2008 and other \\\n",
    "# papers where applicable\n",
    "\n",
    "# just corrected the separation int he individual table for the Wong+2008 target. Sep is 1.3' or 78''. It was \\\n",
    "# listed as 1.3''. Still a dual based on our cosmology (~83 kpc)\n",
    "\n",
    "# Corrections made to the lens botebook. Anguita2018 mistaken had inada table names listed in the \\\n",
    "# dV loop. I;ve commented out the selection and confirmation method column creation commands since I've \\\n",
    "# put these into the csv files themselves. For the Eftek2017 , Rusu2019, and Lemon2020 matches, I now have the code \\\n",
    "# take the redshifts from Lemon 2020.\n",
    "\n",
    "# I have now gone through and added selection methods for all of the lens search papers to the actual csv files.\\\n",
    "# These may need to be refined, because pretty much all GAIA multi-peak selection methods are simply marked as \\\n",
    "# 'optical imaging' and nothing more specific, but we really should be more specific. \n",
    "\n",
    "# Confirmation methods have been added to the csv files for a few of these papers but not for all of them. Any \\\n",
    "# work that required looking through the original tables and differentiating between optical and IR imaging \\\n",
    "# typically does not have confirmation strategies listed, for now. (But they will be... next big thing...).\n",
    "#\n",
    "\n",
    "# I've now gone back into the matching notebooks notebook and adjusted the code where Inada gets matched to Gattano\n",
    "# For some reaosn, the match I'm seeing looks correct. Which makes me think what I saw below and in some other cases\n",
    "# was an issue of not resting the index. Looking back through my matching notebook, the index was **not** reset \\\n",
    "# after every concatenation with a new table, meaning we had a hell of a lot of duplicate indexes. I have now gone \\\n",
    "# through and added index reset commands throughout whenever I found a concatenation, and even when loading in \\\n",
    "# new tables that may not have been reset previously.\n",
    "\n",
    "# I stand corrected. I'm not sure what I was seeing before... the match between Gattano and Inada looks fine after \\\n",
    "# all. In any event, I now pull most information over from Inada and really only add the Gattano citation and designation\n",
    "#\n",
    "\n",
    "# corrected the issue of a missing selection method and confirmation method for Rusu (for some reason had redshift listed instead)\n",
    "\n",
    "\n",
    "# figure out why there is overlap on J002729.24+211152.08 between yuan and severgnini liu and serafinelli\n",
    "# --> index was not being reset in the double peaked table just before adding this so it must have been added to \\\n",
    "# the original index as well as the yuan index. I now have added in an index resetting function.\n",
    "\n",
    "# Indeed, once the index resetting was in place, the severgnini issue disappeared, as did the issue with the Kim2020\n",
    "# non-matches and the issues with Smith, Song, and Kim\n",
    "\n",
    "# I have now gone through and standardized (and fixed) the selection techniques in the binary notebook.\n",
    "# Erac2013 was fixed *used to be listed as double-peak selected). I do not differentiate between broad Hbeta and \\\n",
    "# broad Mg II selection. This is something we could consider changing soon. I am also adding in 'Optical Spectroscopy' \\\n",
    "# and 'Fiber Spectroscopy' (or maybe Fiber optical spectroscopy).\n",
    "\n",
    "# I am now debating whether LOS radial velocity and long-slit spec should be listed as a selection technique or \\\n",
    "# an analysis technique\n",
    "\n",
    "# I have gone through and double-checked/correct all of the system types in the offset and Bl binary notebooks, \\\n",
    "# made sure a few columns were strings when they were supposed to be (such as brightness band and source), removed \\\n",
    "# source Name 2 and redshift 2 for a  umber of sources that did not require it, and I have revised the selection \\\n",
    "# techniques I believe not for all of the catalogs in those two notebooks. \n",
    "\n",
    "# In addition, I have now included all of the Mg II-only selected objects from Ju+2013 appropriately matched to \\\n",
    "# the remainder of the Wang+2017 catalog, and this table is now appropriately matched into the MAC at the end of \\\n",
    "# the matching notebook. \n",
    "\n",
    "# In the offset notebook, I now have also included the missing offset AGNs from comerford+2009 and the remainder \\\n",
    "# of Barrows+2016's sample (excluding anything I already tagged in the individual table or other notebooks such as \\\n",
    "# the Liu notebook). These two tables are saved and read directly into the matching notebook and appropriately \\\n",
    "# matched with the full MAC table. \n",
    "\n",
    "# As of now, I believe we have included all missing objects/major works. There are bound to be a few works that \\\n",
    "# we have missed, but I believe we have all of the major works and are probably only missing a few works on \\\n",
    "# binaries\n",
    "\n",
    "# I have added 'radio imaging' to the Fu+2015 selection techniques and 'optical spectroscopy' to the Fu+2018 \\\n",
    "# objects. \n",
    "\n",
    "# Corrected a couplw of typos where we tack on the system types from eracleous+2012 and ju+2013. \n",
    "\n",
    "# Just removed the listing of 'Dual AGN Candidate / Offset AGN Candidate' tag within the double-peaked object ]\n",
    "# notebook (this tag came from Comerford+2015)\n",
    "\n",
    "# Corrected some typos in the Liu and Fu notebook... Fu's notes were being aded to the confirmation method, and the \\\n",
    "# Fu selection methods were overwriting the Liu selection methods\n",
    "\n",
    "# Just a note: there are a few objects getting put into the bad , bad2, and bad3 frames but likely shouldn't be\\\n",
    "# something seems to be goingwrong when their separation in kpc or dV is calculated. need to double check. \n",
    "\n",
    "\n",
    "# as of today (17 Jan 2024), every object within the 'good' tables (as opposed to the ones listed as 'bad')\n",
    "# have selection methodologies. This involved going through and formatting/reformatting a variety of individual \\\n",
    "# targets as well as removing '-99' listings in the selection method in the matching notebook and correcting \\\n",
    "# ahost of typos throughout the other notebooks (a few per notebook in the binary quasr, lens, etc. notebooks).\n",
    "# Most of the work was revising/reformatting/double-checking the individual targets\n",
    "\n",
    "\n",
    "# fixed a redshift issue that was introduced when we matched together Ianda+2008 and Mason+2000. \\\n",
    "#The Mason redshifts camme from simbad, drawn from SDSS but the redshifts likely suffered from fiber spillover \\\n",
    "# (they were very similiar) whereas the redshifts from Ianada 2008 were distinct (3000 km s^-1 difference.). \\\n",
    "# Therefore I have gone back and deferred to Inada for redshifts and coordinates\n",
    "\n",
    "# We will be removing at least one of the gattano targets form the good set of tables\n",
    "\n",
    "# moved wong+08 target to +1 in confidence. may revisit\n",
    "# moved imanishi+2020 target back to a dual AGn candidate. not sure why that was a dual agn but the otherwasn't\n",
    "# moved Woo+2014 down to dual agn candidate in individual table\n",
    "\n",
    "# J048 fixed typo in matching catalog that put the wrong literature name for 1048 (j instead of i was used for \\\n",
    "# the MACnora2 index)\n",
    "\n",
    "# just added A and B designations to the Miller+2004 targets, since previously they were listed as the same thing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ee24c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAC = pd.read_csv('MAC_DR0p5_16Jan2024.csv', sep=',')\n",
    "\n",
    "MAC.fillna(-99, inplace=True)\n",
    "\n",
    "MAC['Confidence Flag'] = -99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f13375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def find_matches(names):\n",
    "#    name_dict = {}\n",
    "#    matches = []\n",
    "#\n",
    "#    for name in names:\n",
    "#        # Remove 'SDSS' or 'SDSS ' from the name\n",
    "#        modified_name = name.replace('SDSS ', '').replace('SDSS', '')\n",
    "#\n",
    "#        first_6_chars = modified_name[:7]\n",
    "#        if first_6_chars in name_dict:\n",
    "#            matches.append((name_dict[first_6_chars], name))\n",
    "#        else:\n",
    "#            name_dict[first_6_chars] = name\n",
    "#\n",
    "#    return matches\n",
    "#\n",
    "#names = MAC['Name1'].to_list()\n",
    "#matched_pairs = find_matches(names)\n",
    "#print(len(matched_pairs))\n",
    "#\n",
    "#for pair in matched_pairs:\n",
    "#    print(f\"Match found: {pair[0]} and {pair[1]}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a5710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecating this list on 24 January 2024; I don't think we need to manually make this adjustment anymore\n",
    "#bqoverlap = ['J115822.77+123518.5','J120727.09+140817.1','J123555.27+683627.0','J132022.54+305622.8',\\\n",
    "#             'J141855.41+244108.9','J142604.32+071930.0','J143002.88+071411.3','J145826.72+544813.1',\\\n",
    "#             'J150747.23+290333.2','J160603.02+290050.8','J163510.30+291116.1','J155330.23+223010.22']\n",
    "\n",
    "for index, row in MAC.iterrows():\n",
    "    # deprecating this hennawi line as of 24 january 2024,; I don't think it is necessary any longer\n",
    "    #if 'Hennawi' in row['Paper(s)']:\n",
    "    #    MAC.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "    if 'J005113.94+002047.2' in row['Name1']:\n",
    "        MAC.at[index, 'Processed System Type'] = 'Dual AGN' # this is from Fu+2015's sample\n",
    "    elif 'J100602.14+071131.0' in row['Name1']:\n",
    "        MAC.at[index, 'Processed System Type'] = 'Dual AGN' # from Rubinur's 2019 sample\n",
    "    elif 'J220634.97+000327.6' in row['Name1']:\n",
    "        MAC.at[index, 'Processed System Type'] = 'Dual AGN' # Fu+2015's sample\n",
    "    elif 'SDSS J1120+6711A' in row['Name1']:\n",
    "        MAC.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "    # deprecated this next line on 24 january 2024; I don't think it is necessary anymore\n",
    "    #elif row['Name1'] in bqoverlap:\n",
    "    #    MAC.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "    elif 'SDSS J171544.05+600835.7' in row['Name1']:\n",
    "        MAC.at[index, 'Processed System Type'] = 'Dual AGN Candidate' \n",
    "        # we're reclassifying Julie's 2011 target from Dual AGN --> Dual AGN Candidate\n",
    "    # this next line and the next line after are deprecated as of 24 Jan 2024 (no longer needed)\n",
    "    #elif row['Processed System Type']=='Dual AGN Candidate / Offset AGN Candidate':\n",
    "    #    MAC.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "    #    # here we're overwriting Julie's offset AGN classification, because in all cases they were also dual candidates\n",
    "    #    # we may need to come back and think about this some more, because Julie's work was selecting dual SMBH candidates \\\n",
    "    #    # within a single host galaxy, but some of the overlap (ex. with Xin Liu's targets) have large separations \\\n",
    "    #    # (ex. 70 kpc), so these targets are technically a dual within a dual.... but I don't think I trust that offset \\\n",
    "    #    # AGNs truly are tracing dual SMBHs. We can always come back and change this later.\n",
    "    #elif row['Processed System Type']=='Dual AGN Candidate / Likely Single AGN':\n",
    "    #    MAC.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "    #    #'Dual AGN Candidate / Likely Single AGN' is both a dual AGN candidate based on Liu+2011 (so resolved spec pair),\\\n",
    "    #    # but ALSO a dual AGN candidate based on double-peak selection (Wang, and the followed up by others). \\\n",
    "    #    # Muller-sanchez followed up with radio and showed that the origin of the double-peak was still ambiguous, but \\\n",
    "    #    # all of the papers seem to point to the double-peaked AGN being a single AGN. Muller-sanchez's imaging did not \\\n",
    "    #    # cover both nuclei that Liu+ consider to be a pair, so the folks doing the double-peaked work did not focus on ]\n",
    "    #    # the companion at ~6'' away. So we'll class this as a dual AGN candidate\n",
    "    #    #\n",
    "    #    # Users will have to be wary of these kinds of cases, because the subjective flag will probably be +0.5 here,\\\n",
    "    #    # but that will reflect the dual candidacy from Liu's work and NOT the candidacy of the double-peaked work\n",
    "    #    #\n",
    "    #J155330.23+223010.22 diff redshifts\n",
    "    #J163510.30+291116.1 diff redshifts?, we'll handle this later\n",
    "    #J150747.23+290333.2 diff redshifts but doesnt meet dV cut; we'll remove this later, put it int he bad table, and relabel as clustered QSOs\n",
    "    #J145826.72+544813.1 diff z\n",
    "    # J143002.88+071411.3 diff z\n",
    "    # J142604.32+071930.0 diff z\n",
    "    # J141855.41+244108.9 diff z?, we'll handle this later\n",
    "    # J123555.27+683627.0 diff z \n",
    "    \n",
    "#pippin = MAC[MAC['Processed System Type']=='Dual AGN / Dual AGN Candidate / Recoil Candidate']\n",
    "\n",
    "# Binary AGN Candidate / Dual AGN --> This is J09527, McGurk+2011's target that was also selected by Liu+2014\n",
    "# Dual AGN Candidate / Recoil Candidate --> overlap between x-shaped radio sources and double peak and a couple individual targets\n",
    "# Binary AGN Candidate / Dual AGN Candidate this is fine\n",
    "# Binary AGN Candidate / Dual AGN Candidate / Recoil Candidate this is fine and is due to X-shaped radio source overlap\n",
    "# Binary SMBH Candidate / Dual AGN Candidate --> just one target, and is fine\n",
    "\n",
    "\n",
    "### Fixed:\n",
    "# 'Dual AGN / Offset AGN Candidate' --> Originally from Liu, followed-up by husemann. Also selected by Barrows as \\\n",
    "# offset AGN, but I think after some reading, it will prob be marked as a dual AGN only.\n",
    "# 'Dual AGN / Dual AGN Candidate' --> a lot of overlap between Hennawi and others, and then some with Liu2011 \\\n",
    "# and others\n",
    "#'Dual AGN / Likely Single AGN' --> This is Julie Comerford's 2011 target, followed up by Liu, Smith, Smith, and others\n",
    "# 'Dual AGN Candidate / Offset AGN Candidate' --> overlap between comerford+ and liu+2011, inada+2010, smith2010, \\\n",
    "# and liu2010\n",
    "# 'Dual AGN Candidate / Likely Single AGN' see notes above\n",
    "# 'Binary AGN Candidate / Binary SMBH Candidate / Dual AGN Candidate' --> This is J1536+0441\n",
    "# Looking at how amyn people grabbed this target and for different reasons, I'm okay keeping this cross class\n",
    "\n",
    "# note: when we add the Fu+ selection method, we overwrite the liu2011 selection method. make sure to fix this in the notebook.\n",
    "# J005113.94+002047.2 --> confirmed binary in radio.\n",
    "# J220634.97+000327.6 --> confirmed binary in radio.\n",
    "# J100602.14+071131.0 --> I believe this is confirmed as a dual in the radio by rubinur but confirm\n",
    "# SDSS J1120+6711A --> likely dual based on Pindor's work\n",
    "# anything with hennawi+ gets pushed to dual agn status. \n",
    "\n",
    "# 2345+007 --> confirmed dual AGN ...\n",
    "# myers+ targets, unless we have redshifts for both, are staying as dual candidates. If we have redshifts for \\\n",
    "# both and there is some dV, we'll consider them as duals with high confidence\n",
    "\n",
    "\n",
    "#pippin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68419b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I'm going to make a legacy column called 'legacy system type'\n",
    "# I'll use this later oon when I want to come back and add in the legacy system types that others have used, like \\\n",
    "# 'binary quasar'\n",
    "\n",
    "MAC['Legacy System Type'] = MAC['System Type'].astype(str)\n",
    "\n",
    "# and now here we're going to replace all 'binary quasar' system types with 'dual AGNs', and simialrly for the \\\n",
    "# candidates...\n",
    "\n",
    "types = MAC['System Type'].dropna().str.split(' / ')\n",
    "\n",
    "# Step 2 and 3: Remove duplicates, alphabetize, and replace 'binary quasar' with 'dual AGN' in any context for each cell\n",
    "def process_cell(cell):\n",
    "    # Replace 'binary quasar' with 'dual AGN' in any context\n",
    "    cell = [x.replace('Binary Quasar Candidate', 'Dual AGN Candidate') for x in cell]\n",
    "    cell = [x.replace('Binary Quasar', 'Dual AGN Candidate') for x in cell]\n",
    "    cell = [x.replace('Quasar Pair', 'Dual AGN Candidate') for x in cell]\n",
    "    cell = [x.replace('Dual AGN Candidate / Likely Single AGN', 'Dual AGN Candidate') for x in cell]\n",
    "    cell = [x.replace('Likely Single AGN', 'Dual AGN Candidate') for x in cell]\n",
    "    cell = [x.replace('Single AGNs', 'Dual AGN Candidate') for x in cell]\n",
    "    cell = [x.replace('Single AGN', 'Dual AGN Candidate') for x in cell]\n",
    "    cell = [x.replace('Dual AGN Candidate / Likely Single AGN', 'Dual AGN Candidate') for x in cell]\n",
    "    # Remove duplicates using set and then convert back to list\n",
    "    unique_labels = list(set(cell))\n",
    "    # Alphabetize the contents\n",
    "    unique_labels.sort()\n",
    "    return unique_labels\n",
    "\n",
    "processed_types = types.apply(process_cell)\n",
    "\n",
    "# Step 4: Join the contents back into a single string\n",
    "MAC['Processed System Type'] = processed_types.apply(' / '.join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc1b1dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dual AGN Candidate' 'Dual AGN / Dual AGN Candidate'\n",
      " 'Dual AGN Candidate / Dual SMBH Candidate'\n",
      " 'Dual AGN Candidate / Recoil Candidate' 'Dual AGN'\n",
      " 'Binary AGN Candidate / Dual AGN Candidate'\n",
      " 'Binary SMBH Candidate / Dual AGN Candidate'\n",
      " 'Binary AGN Candidate / Binary SMBH Candidate / Dual AGN Candidate'\n",
      " 'Binary AGN Candidate / Binary SMBH Candidate' 'Dual SMBH Candidate'\n",
      " 'Binary AGN Candidate / Dual SMBH Candidate / Recoil Candidate'\n",
      " 'Binary AGN Candidate / Dual SMBH Candidate' 'Binary AGN Candidate'\n",
      " 'Binary SMBH Candidate' 'Recoil Candidate'\n",
      " 'Binary AGN Candidate / Recoil Candidate'\n",
      " 'Binary AGN Candidate / Dual AGN Candidate / Recoil Candidate'\n",
      " 'Binary AGN Candidate / Binary SMBH Candidate / Dual AGN Candidate / Recoil Candidate'\n",
      " 'Binary AGN'\n",
      " 'Binary SMBH Candidate / Dual SMBH Candidate / Recoil Candidate'\n",
      " 'Binary SMBH Candidate / Recoil Candidate'\n",
      " 'Binary SMBH Candidate / Dual AGN'\n",
      " 'Binary SMBH Candidate / Dual AGN Candidate / Recoil Candidate']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#gandalf = MAC[MAC['Processed System Type'].str.contains('Dual AGN', na=False)]\n",
    "\n",
    "unique_combinations = MAC['Processed System Type'].dropna().unique()\n",
    "\n",
    "print(unique_combinations)\n",
    "print(len(unique_combinations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06604396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are going to implement a system type column for primary, secondary, and tertiary system types \\\n",
    "#for better organization\n",
    "\n",
    "# Object type lists\n",
    "dualcantype = ['Dual AGN','Dual AGN Candidate','Dual SMBH Candidate']\n",
    "binarycandtype = ['Binary AGN','Binary SMBH','Binary AGN Candidate','Binary SMBH Candidate']\n",
    "recoiltype = ['Recoil Candidate']\n",
    "\n",
    "# Function to check items in the lists and assign labels\n",
    "def assign_types(row):\n",
    "    types = row['Processed System Type'].split(' / ')\n",
    "    primary, secondary, tertiary = '', '', ''\n",
    "    # Check against dualcantype\n",
    "    primary_matches = [item for item in types if item in dualcantype]\n",
    "    if primary_matches:\n",
    "        primary = ' ; '.join(primary_matches)\n",
    "        # now check against bianry types\n",
    "        secondary_matches = [item for item in types if item in binarycandtype]\n",
    "        if secondary_matches:\n",
    "            secondary = ' ; '.join(secondary_matches)\n",
    "            # now check against recoil types\n",
    "            tertiary_matches = [item for item in types if item in recoiltype]\n",
    "            if tertiary_matches:\n",
    "                tertiary = ' ; '.join(tertiary_matches)\n",
    "            else:\n",
    "                tertiary = \"-99\"\n",
    "        # and checking againast recoil types in the event thatno binary types were detected\n",
    "        else:\n",
    "            secondary_matches = [item for item in types if item in recoiltype]\n",
    "            if secondary_matches:\n",
    "                secondary = ' ; '.join(secondary_matches)\n",
    "                tertiary = \"-99\"\n",
    "            else:\n",
    "                secondary = \"-99\"\n",
    "                tertiary = \"-99\"\n",
    "    else:\n",
    "        # Check against binarycandtype if dualcantype had no matches\n",
    "        secondary_matches = [item for item in types if item in binarycandtype]\n",
    "        if secondary_matches:\n",
    "            primary = ' ; '.join(secondary_matches)\n",
    "            secondary_matches = [item for item in types if item in recoiltype]\n",
    "            if secondary_matches:\n",
    "                secondary = ' ; '.join(secondary_matches)\n",
    "                tertiary = \"-99\"\n",
    "            else:\n",
    "                secondary = \"-99\"\n",
    "                tertiary = \"-99\"\n",
    "        else:\n",
    "            # Check against recoiltype if previous lists had no matches\n",
    "            tertiary_matches = [item for item in types if item in recoiltype]\n",
    "            if tertiary_matches:\n",
    "                primary = ' ; '.join(tertiary_matches)\n",
    "                secondary = \"-99\"\n",
    "                tertiary = \"-99\"\n",
    "                \n",
    "    return pd.Series([primary, secondary, tertiary])\n",
    "\n",
    "# Apply the function to each row\n",
    "MAC[['Primary System Type', 'Secondary System Type', 'Tertiary System Type']] = MAC.apply(assign_types, axis=1)\n",
    "\n",
    "for index, row in MAC.iterrows():\n",
    "    if 'Dual AGN' in row['Primary System Type'].split(' ; '):\n",
    "        #print('True')\n",
    "        MAC.at[index, 'Primary System Type'] = 'Dual AGN'\n",
    "\n",
    "# and adding in the confidence rank columns for each system type column\n",
    "MAC['ST1 Confidence Flag'] = -99\n",
    "MAC['ST2 Confidence Flag'] = -99\n",
    "MAC['ST3 Confidence Flag'] = -99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b1ddba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40516830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "MAC_names = MAC['Name1'].to_list()\n",
    "\n",
    "# adding separations to binary candidates\n",
    "\n",
    "runnoe = ['001224.02-102226.2','015530.01-085704.0','031715.87+425150.6','074007.28+410903.6','082150.13+081907.3',\\\n",
    "          '091928.69+143202.6','092712.65+294344.0','093844.45+005715.7','094603.94+013923.7','094620.32+375953.2',\\\n",
    "          '095036.75+512838.1','095539.81+453217.0','105041.36+345631.4','110556.18+031243.2',\\\n",
    "          '111537.93+542725.2','113330.29+105223.2','113904.33+465651.1','115158.90+122128.9','120924.07+103612.1',\\\n",
    "          '125142.28+240435.3','131945.95+053002.7','140251.19+263117.5','151132.53+100953.1','153636.22+044127.0',\\\n",
    "          '153644.90+141229.7','154637.12+122832.5','155654.47+253233.5','161911.24+501109.2','162914.09+151415.3']\n",
    "runnoesep = [2.6e-5,1.1e-5,1.7e-5,1.0e-5,1.1e-5,1.3e-5,1.3e-5,1.6e-5,1.5e-5,1.5e-5,0.6e-5,0.9e-5,8.1e-5,1.3e-5,\\\n",
    "              3.3e-5,1.7e-5,3.2e-5,0.1e-5,1.4e-5,2.9e-5,0.6e-5,2.1e-5,1.7e-5,13.4e-5,1.2e-5,1.1e-5,5.7e-5,0.2e-5,\\\n",
    "              0.7e-5]\n",
    "# those are minimum separations\n",
    "\n",
    "#for i in runnoe:\n",
    "#    if i not in MAC_names:\n",
    "#        print(str(i)+' not in list.')\n",
    "\n",
    "for i, j in zip(runnoe,runnoesep):\n",
    "    MAC.loc[MAC.Name1==str(i), 'Sep(kpc)'] = j*(1.e-3)\n",
    "    #for index, row in MAC.iterrows():\n",
    "    #    if row['Name1']==str(i):\n",
    "    #        MAC.at[index, 'Sep(kpc)'] = j*(1.e-3)\n",
    "\n",
    "MAC.loc[MAC.Name1=='001224.01-102226.5', 'Sep(kpc)'] = (2.6e-2)*(1.e-3)\n",
    "MAC.loc[MAC.Name1=='094603.94+013923.6', 'Sep(kpc)'] = (1.5e-2)*(1.e-3)\n",
    "MAC.loc[MAC.Name1=='J1050+3456', 'Sep(kpc)'] = (8.1e-2)*(1.e-3)\n",
    "MAC.loc[MAC.Name1=='J154637.12+122832.5', 'Sep(kpc)'] = (1.1e-2)*(1.e-3)\n",
    "            \n",
    "# 001224.02 --> overlap with liu but liu does not have seps. can overwrite\n",
    "# 094603 --> overlap with liu but can overwrite\n",
    "# 105041 --> overlap with tsalmantza can overwrite (1050+3456)\n",
    "\n",
    "# 092712 --> this is 0927 do not overwrite?\n",
    "# 153636 --> this is 1536 do not overwrite\n",
    "\n",
    "#(these do match via name)\n",
    "# 154637--> overlap with smith can overwrite\n",
    "# 095036.75+512838.1 --> overlap wth liu but can overwrite\n",
    "# 154637.12+122832.5 --> overlap with smith and can overwrite\n",
    "\n",
    "\n",
    "#ju2013 = ['J032223.02-000803.5','J002444.11+003221.4','J095656.42+535023.2','J161609.50+434146.8',\\\n",
    "#          'J075700.70+424814.5','J093502.54+433110.7','J004918.98+002609.4']\n",
    "#\n",
    "#ju2013seps = [0.032,0.102,1.74,0.021,0.020,0.181,0.096]\n",
    "# those are maximum separations\n",
    "\n",
    "print(' ')\n",
    "\n",
    "ju2013tab = pd.read_csv('Tables/Ju2013/Ju2013_t2.csv', sep=',')\n",
    "ju2013names = ju2013tab['SDSS'].to_list()\n",
    "ju2013sep = ju2013tab['rmax(pc)'].to_list()\n",
    "\n",
    "#for i in ju2013names:\n",
    "#    if i not in MAC_names:\n",
    "#        print(str(i)+' not in list.')\n",
    " \n",
    "for i, j in zip(ju2013names,ju2013sep):\n",
    "    MAC.loc[MAC.Name1==str(i), 'Sep(kpc)'] = j*(1.e-3)\n",
    "    #for index, row in MAC.iterrows():\n",
    "    #    if row['Name1']==str(i):\n",
    "    #        MAC.at[index, 'Sep(kpc)'] = j*(1.e-3)\n",
    "\n",
    "# and fixing the one lonesome object that overlapped with Eracleous' sample\n",
    "MAC.loc[MAC.Name1=='J002444.11+003221.4', 'Sep(kpc)'] = 0.000102\n",
    "        \n",
    "#for i in ju2013:\n",
    "#    if i not in MAC_names:\n",
    "#        print(str(i)+' not in list.')\n",
    "#        # the one that isn't in the table here is the same as the overlaping target from our first loop\n",
    "        \n",
    "# first one overlaps with eraclerous but we can adopt the ju sep\n",
    "# J020646.97+001800.6 is the overlap with hennawi, so we will not overwrite the separation\n",
    "\n",
    "\n",
    "# now working on the 9 binary candidates from Liu+2014\n",
    "liu2014 = ['082930.59+272822.7','084716.03+373218.0','085237.01+200410.9','092837.98+602521.0',\\\n",
    "           '103059.09+310255.7','110050.99+170934.2','111230.89+181311.4','130534.49+181932.8',\\\n",
    "           '134548.50+114443.5']\n",
    "liu2014sep = [0.24,0.29,0.13,0.46,0.25,0.092,0.12,0.10,0.11]\n",
    "# these are maximum values drawn from the q=2 column of Liu+2014 table 3\n",
    "\n",
    "#for i in liu2014:\n",
    "#    if i not in MAC_names:\n",
    "#        print(str(i)+' not in list.')\n",
    "#        # here we're going to be adding in the separation value from Ju+2013\n",
    "#        # I've gone through and verified that we will not be overwriting any separations when we do this\n",
    "\n",
    "for i, j in zip(liu2014,liu2014sep):\n",
    "    MAC.loc[MAC.Name1==str(i), 'Sep(kpc)'] = j*(1.e-3)\n",
    "    #for index, row in MAC.iterrows():\n",
    "    #    if row['Name1']==str(i):\n",
    "    #        MAC.at[index, 'Sep(kpc)'] = j*(1.e-3)\n",
    "\n",
    "# now for Graham2015\n",
    "graham2015 = ((Table.read('Tables/Graham2015/table2.dat', readme = 'Tables/Graham2015/ReadMe', format='ascii.cds')).to_pandas())#.drop(columns=['---'])\n",
    "graham2015names = graham2015['Name'].to_list()\n",
    "graham2015sep = graham2015['r'].to_list()\n",
    "\n",
    "#for i in graham2015names:\n",
    "#    if i not in MAC_names:\n",
    "#        print(str(i)+' not in list.')\n",
    "\n",
    "for i, j in zip(graham2015names,graham2015sep):\n",
    "    MAC.loc[MAC.Name1==str(i), 'Sep(kpc)'] = j*(1.e-3)\n",
    "    #for index, row in MAC.iterrows():\n",
    "    #    if row['Name1']==str(i):\n",
    "    #        MAC.at[index, 'Sep(kpc)'] = j*(1.e-3)\n",
    "\n",
    "MAC.loc[MAC.Name1=='PG 1302-2102 / BZQJ1305-1033', 'Sep(kpc)'] = 0.008*(1.e-3)\n",
    "# ther are four objects that overlap with other samples\n",
    "# --> one overlaps with Liu2014 (RXS J10304+5516,0.435,spec,10:30:25.0,+55:16:23.4). Liu doesn;t calc sep, so we can overwtite\n",
    "# SDSS J081617.73+293639.6 not in list. --> SDSSJ081617.73+293639.6 AGN1  (overlap with Ianda, we will not defer)\n",
    "# BZQJ1305-1033 not in list. -->This is PG 1302-2102, we will defer to Graham, for now. For some reason this was 0.01 before\n",
    "# SDSS J153636.22+044127.0 not in list. --> J1536+0441 / SDSS J153636.22+044127.0 (do not overwrite sep)\n",
    "\n",
    "# now for Charisi2016\n",
    "charisi2016 = pd.read_csv('Tables/Charisi2016/Charisi2015_t2.csv', sep=',')\n",
    "charisi2016names = charisi2016['Name'].to_list()\n",
    "charisi2016sep = charisi2016['Angular'].to_list()\n",
    "\n",
    "#for i in charisi2016names:\n",
    "#    if i not in MAC_names:\n",
    "#        print(str(i)+' not in list.')\n",
    "\n",
    "for i, j in zip(charisi2016names,charisi2016sep):\n",
    "    MAC.loc[MAC.Name1==str(i), 'Sep'] = j*(1.e-6)\n",
    "    #for index, row in MAC.iterrows():\n",
    "    #    if row['Name1']==str(i):\n",
    "    #        MAC.at[index, 'Sep'] = j*(1.e-6)\n",
    "\n",
    "# we're missing the last object in the charisi2016. should be no matches                       \n",
    "\n",
    "\n",
    "# and now adding in the info from Guo+2019 (and superceding info from Liu+2014 when applicable\n",
    "\n",
    "#J0322+0055 not in liu2014 binary list but in liu2014 and shen 2013\n",
    "#J0829+2728 in liu2014\n",
    "#J0847+3732 in liu2014\n",
    "#J0852+2004 in liu2014\n",
    "#J0928+6025 in liu2014\n",
    "#J1030+3102 in liu2014\n",
    "#J1100+1709 in liu2014\n",
    "#J1112+1813 in liu2014\n",
    "#J1410+3643 not in liu2014 binary list but in shen 2013\n",
    "#J1537+0055 not in liu2014 binary list but in shen 2013\n",
    "#J1550+0521 not in liu2014 binary list but in shen 2013\n",
    "#J2349-0036 not in liu2014 binary list but in shen 2013\n",
    "\n",
    "guo2019 = ['032213.89+005513.4','082930.60+272822.7','084716.04+373218.1','085237.02+200411.0','092837.98+602521.0',\\\n",
    "           '103059.09+310255.8','110051.02+170934.3','111230.90+181311.4','141020.57+364322.7',\\\n",
    "           '153705.95+005522.8','155053.16+052112.1','234932.77-003645.8']\n",
    "\n",
    "guo2019sep = [0.056,0.070,0.088,0.11,0.10,0.072,0.059,0.050,0.050,0.039,0.061,0.072]\n",
    "# these are the larger of the two values listed in Guo+2019's table (derived from q=0.5)\n",
    "\n",
    "for i, j in zip(guo2019,guo2019sep):\n",
    "    MAC.loc[MAC.Name1==str(i), 'Sep(kpc)'] = j*(1.e-3)\n",
    "\n",
    "# and now fixing anything marked as having zero sep from Graham+2015:\n",
    "MAC.loc[MAC['Sep(kpc)']==0, 'Sep(kpc)'] = -99\n",
    "\n",
    "# once we're done here, we'll need to come back later and finally add in the 'upper/lower limit' flag\n",
    "\n",
    "\n",
    "# check with Nathan what he thinks for Hwang+2020 and Orosz+2013\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a279fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we're going to calculate angular separations for systems where we only have physical reported separations...\n",
    "\n",
    "missingsep = MAC[(MAC['Sep(kpc)']>0) & (MAC['Sep']<0)]\n",
    "objs = missingsep['Name1'].to_list()\n",
    "for i in objs:\n",
    "    for index, row in MAC[MAC['Name1']==str(i)].iterrows():\n",
    "        MAC.at[index, 'Sep'] = (row['Sep(kpc)']/(cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)))\n",
    "\n",
    "## here we're fixing the known issues in the gimli table for PG 1302, 3C 293, WISE J2332, PKS 0301, SDSS J059, \n",
    "## and PSO J334\n",
    "#\n",
    "#objs = ['PG 1302-2102 / BZQJ1305-1033','3C 293','WISE J233237.05-505643.5 (W2332-5056)','PKS 0301-243',\\\n",
    "#        'SDSS J0159+0105','PSO J334.2028+01.4075']\n",
    "#for i in objs:\n",
    "#    for index, row in MAC[MAC['Name1']==str(i)].iterrows():\n",
    "#        MAC.at[index, 'Sep'] = (row['Sep(kpc)']/(cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)))\n",
    "#    \n",
    "## and now for the gandalf targets:\n",
    "#objs = ['MGB2016+112 Core 1']\n",
    "#\n",
    "#for i in objs:\n",
    "#    for index, row in MAC[MAC['Name1']==str(i)].iterrows():\n",
    "#        MAC.at[index, 'Sep'] = (row['Sep(kpc)']/(cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)))\n",
    "\n",
    "     \n",
    "# and now for IRAS 20210; this one has distinct coordinates, so we will reomcpute the angular separation \\\n",
    "# based on the XMM souce positions\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import Angle\n",
    "\n",
    "# note here I went back and used panstarrs in aladin lite to get the optical positions of the nuclei and overwrote \\\n",
    "# the listed positions in the individual table because those were for the extraction regions used by Piconcelli \\\n",
    "# and do not correspond to the true X-ray peaks. The panstarrs coordinates give a slightly higher separation \\\n",
    "# (~12.3 kpc) than reported by pinconcelli (~11kpc)\n",
    "objs = ['I20210N']\n",
    "for i in objs:\n",
    "    for index, row in MAC[MAC['Name1']==str(i)].iterrows():\n",
    "        c1 = SkyCoord(Angle(str(row['RA1'])+' hours').degree,Angle(str(row['Dec1'])+' degrees').degree, unit='deg', frame='icrs')\n",
    "        c2 = SkyCoord(Angle(str(row['RA2'])+' hours').degree,Angle(str(row['Dec2'])+' degrees').degree, unit='deg', frame='icrs')\n",
    "        MAC.at[index, 'Sep'] = c1.separation(c2).arcsecond\n",
    "\n",
    "\n",
    "#for index, row in gandalf_white.iterrows():\n",
    "#    gandalf_white.at[index, 'dV_new'] = (2.99e+5) * ((1 + row['z1'])**2 - (1 + row['z2'])**2) / ((1 + row['z1'])**2 + (1 + row['z2'])**2)\n",
    "#    gandalf_white.at[index, 'Sep(kpc)_z1'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)\n",
    "#    gandalf_white.at[index, 'Sep(kpc)_z2'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z2'])*(u.arcmin/u.kpc)*(1/60)\n",
    "\n",
    "#MAC.loc[MAC.Name1=='I20210N']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e354bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nan_rows_in_A = MAC[MAC['Sep'].isna()]\n",
    "#nan_rows_in_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34d0d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MACcheck = MAC[(MAC['Sep(kpc)']<1) & (MAC['Sep(kpc)']>-10)]\n",
    "#len(MACcheck)\n",
    "#MACcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce8ff742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we're going to go through and make plenty of fine adjustments, including calculating separations and \\\n",
    "# adding missing information \n",
    "\n",
    "# adding in additional coordinate information here\n",
    "MAC.loc[MAC.Name1=='ESO 1327-2041 Galaxy', 'RA2'] = '13:30:06.087'\n",
    "MAC.loc[MAC.Name1=='ESO 1327-2041 Galaxy', 'Dec2'] = '-20:55:19.84'\n",
    "MAC.loc[MAC.Name1=='ESO 1327-2041 Galaxy', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='ESO 1327-2041 Galaxy', 'Coordinate_waveband2'] = 'Optical'\n",
    "MAC.loc[MAC.Name1=='ESO 1327-2041 Galaxy', 'Coordinate_Source2'] = 'PanSTARRS'\n",
    "#ESO 1327 Ejected Nucleus 13:30:06.087 -20:55:19.84\n",
    "#optical panstarrs j2000\n",
    "\n",
    "#VV 114\n",
    "MAC.loc[MAC.Name1=='VV 114 E', 'RA1'] = '01:07:47.595'\n",
    "MAC.loc[MAC.Name1=='VV 114 E', 'Dec1'] = '-17:30:24.09'\n",
    "MAC.loc[MAC.Name1=='VV 114 E', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='VV 114 E', 'Coordinate_waveband1'] = 'Optical'\n",
    "MAC.loc[MAC.Name1=='VV 114 E', 'Coordinate_Source1'] = 'PanSTARRS'\n",
    "MAC.loc[MAC.Name2=='VV 114 W', 'RA2'] = '01:07:46.551'\n",
    "MAC.loc[MAC.Name2=='VV 114 W', 'Dec2'] = '-17:30:22.27'\n",
    "MAC.loc[MAC.Name2=='VV 114 W', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name2=='VV 114 W', 'Coordinate_waveband2'] = 'Optical'\n",
    "MAC.loc[MAC.Name2=='VV 114 W', 'Coordinate_Source2'] = 'PanSTARRS'\n",
    "    \n",
    "#PKS B1345+125 NW / PKS B1345+125 SE\n",
    "MAC.loc[MAC.Name1=='PKS B1345+125 NW', 'RA2'] = '13:47:33.481'\n",
    "MAC.loc[MAC.Name1=='PKS B1345+125 NW', 'Dec2'] = '+12:17:23.86'\n",
    "MAC.loc[MAC.Name1=='PKS B1345+125 NW', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='PKS B1345+125 NW', 'Coordinate_waveband2'] = 'Optical'\n",
    "MAC.loc[MAC.Name1=='PKS B1345+125 NW', 'Coordinate_Source2'] = 'PanSTARRS'     \n",
    "\n",
    "# SBS 1421+511\n",
    "MAC.loc[MAC.Name1=='SBS 1421+511 QSO', 'RA2'] = '14:23:14.202'\n",
    "MAC.loc[MAC.Name1=='SBS 1421+511 QSO', 'Dec2'] = '+50:55:40.39'\n",
    "MAC.loc[MAC.Name1=='SBS 1421+511 QSO', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='SBS 1421+511 QSO', 'Coordinate_waveband2'] = 'Optical'\n",
    "MAC.loc[MAC.Name1=='SBS 1421+511 QSO', 'Coordinate_Source2'] = 'PanSTARRS'  \n",
    "\n",
    "# J1536+0441\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'RA1'] = '15:36:36.2232'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'Dec1'] = '+04:41:27.069'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'Coordinate_waveband1'] = 'Radio'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'Coordinate_Source1'] = 'EVN'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'RA2'] = '15:36:36.2881'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'Dec2'] = '+04:41:27.054'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'Coordinate_waveband2'] = 'Radio'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'Coordinate_Source2'] = 'EVN'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 / SDSS J153636.22+044127.0', 'Name1'] = 'J1536+0441 VLA-A'\n",
    "MAC.loc[MAC.Name1=='J1536+0441 VLA-A', 'Name2'] = 'J1536+0441 VLA-B'\n",
    "# these radio positions come from Bondi+2010 and adopt the naming convention of Wrobel+2009\n",
    "\n",
    "#Adjusted NGC 7592 E coordinates manually. Original coordinates sat between galaxies\n",
    "\n",
    "# SDSSJ1600+0000A\n",
    "MAC.loc[MAC.Name1=='SDSSJ1600+0000A', 'RA1'] = '16:00:15.506'\n",
    "MAC.loc[MAC.Name1=='SDSSJ1600+0000A', 'Dec1'] = '+00:00:45.43'\n",
    "MAC.loc[MAC.Name1=='SDSSJ1600+0000A', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='SDSSJ1600+0000A', 'Coordinate_waveband1'] = 'Optical'\n",
    "MAC.loc[MAC.Name1=='SDSSJ1600+0000A', 'Coordinate_Source1'] = 'PanSTARRS'\n",
    "MAC.loc[MAC.Name1=='SDSSJ1600+0000A', 'RA2'] = '16:00:15.591'\n",
    "MAC.loc[MAC.Name1=='SDSSJ1600+0000A', 'Dec2'] = '+00:00:46.70'\n",
    "MAC.loc[MAC.Name1=='SDSSJ1600+0000A', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='SDSSJ1600+0000A', 'Coordinate_waveband2'] = 'Optical'\n",
    "MAC.loc[MAC.Name1=='SDSSJ1600+0000A', 'Coordinate_Source2'] = 'PanSTARRS'\n",
    "#c1 = SkyCoord(Angle('16:00:15.506 hours').degree,Angle('+00:00:45.43 degrees').degree, unit='deg', frame='icrs')\n",
    "#c2 = SkyCoord(Angle('16:00:15.591 hours').degree,Angle('+00:00:46.70 degrees').degree, unit='deg', frame='icrs')\n",
    "\n",
    "# need to get coordinates for 3C 186 Quasar (in gimli table)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# now looping over double-peaked objects that we have ocordinates for\n",
    "# now the single AGNs from Comerford+2015\n",
    "MAC.loc[MAC.Name1=='J014209-005049', 'RA1'] = '01:42:09.003'\n",
    "MAC.loc[MAC.Name1=='J014209-005049', 'Dec1'] = '-00:50:49.94'\n",
    "MAC.loc[MAC.Name1=='J014209-005049', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J014209-005049', 'Coordinate_waveband1'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J014209-005049', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J085416.76+502632.0', 'RA1'] = '08:54:16.776'\n",
    "MAC.loc[MAC.Name1=='J085416.76+502632.0', 'Dec1'] = '+50:26:32.10'\n",
    "MAC.loc[MAC.Name1=='J085416.76+502632.0', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J085416.76+502632.0', 'Coordinate_waveband1'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J085416.76+502632.0', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J100654.20+464717.2', 'RA1'] = '10:06:54.237'\n",
    "MAC.loc[MAC.Name1=='J100654.20+464717.2', 'Dec1'] = '+46:47:16.71'\n",
    "MAC.loc[MAC.Name1=='J100654.20+464717.2', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J100654.20+464717.2', 'Coordinate_waveband1'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J100654.20+464717.2', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J144804.17+182537.9', 'RA1'] = '14:48:04.186'\n",
    "MAC.loc[MAC.Name1=='J144804.17+182537.9', 'Dec1'] = '+18:25:37.75'\n",
    "MAC.loc[MAC.Name1=='J144804.17+182537.9', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J144804.17+182537.9', 'Coordinate_waveband1'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J144804.17+182537.9', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "\n",
    "# now for the dual'offset' candidates from Comerford+2015\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'RA1'] = '09:52:07.611'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'Dec1'] = '+25:52:57.23'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'Coordinate_waveband1'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'RA2'] = '09:52:07.604'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'Dec2'] = '+25:52:56.24'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'Coordinate_waveband2'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'Coordinate_Source2'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'Literature Name'] = 'J09527.62+255257.2'\n",
    "MAC.loc[MAC.Name1=='J0952+2552', 'Name1'] = 'J09527.62+255257.2 / J0952+2552NE'\n",
    "MAC.loc[MAC.Name1=='J09527.62+255257.2 / J0952+2552NE', 'Name2'] = 'J0952+2552SW'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'RA1'] = '12:39:15.454'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'Dec1'] = '+53:14:15.14'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'Coordinate_waveband1'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'RA2'] = '12:39:15.454'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'Dec2'] = '+53:14:15.14'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'Coordinate_waveband2'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'Coordinate_Source2'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6', 'Name1'] = 'J123915.40+531414.6 / J1239+5314NE'\n",
    "MAC.loc[MAC.Name1=='J123915.40+531414.6 / J1239+5314NE', 'Name2'] = 'J1239+5314SW'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'RA1'] = '13:22:31.796'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'Dec1'] = '+26:31:58.65'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'Coordinate_waveband1'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'RA2'] = '13:22:31.968'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'Dec2'] = '+26:31:59.02'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'Coordinate_waveband2'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'Coordinate_Source2'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1', 'Name1'] = 'J132231.86+263159.1 / J1322+2631SW'\n",
    "MAC.loc[MAC.Name1=='J132231.86+263159.1 / J1322+2631SW', 'Name2'] = 'J1322+2631NE'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'RA1'] = '13:56:46.128'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'Dec1'] = '+10:26:08.61'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'Coordinate_waveband1'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'RA2'] = '13:56:46.120'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'Dec2'] = '+10:26:07.29'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'Coordinate_waveband2'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'Coordinate_Source2'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1', 'Name1'] = 'J135646.11+102609.1 / J1356+1026NE'\n",
    "MAC.loc[MAC.Name1=='J135646.11+102609.1 / J1356+1026NE', 'Name2'] = 'J1356+1026SW'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'RA1'] = '11:26:59.569'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'Dec1'] = '+29:44:42.63'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'Coordinate_waveband1'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'RA2'] = '11:26:59.631'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'Dec2'] = '+29:44:41.92'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'Coordinate_waveband2'] = 'F160W'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'Coordinate_Source2'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8', 'Name1'] = 'J112659.54+294442.8 / J1126+2944NW'\n",
    "MAC.loc[MAC.Name1=='J112659.54+294442.8 / J1126+2944NW', 'Name2'] = 'J1126+2944SE'\n",
    "\n",
    "\n",
    "# now for the objects in Liu+2013 and Liu+2018\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'RA1'] = '11:08:51.029'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'Dec1'] = '+06:59:01.32'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'Coordinate_waveband1'] = 'Y-band'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'RA2'] = '11:08:51.061'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'Dec2'] = '+06:59:00.81'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'Coordinate_waveband2'] = 'Y-band'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'Coordinate_Source2'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4', 'Name1'] = 'J110851.04+065901.4 / J1108+0659NW'\n",
    "MAC.loc[MAC.Name1=='J110851.04+065901.4 / J1108+0659NW ', 'Name2'] = 'J1108+0659SE'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'RA1'] = '11:31:26.042'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'Dec1'] = '-02:04:59.33'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'Coordinate_waveband1'] = 'Y-band'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'RA2'] = '11:31:26.088'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'Dec2'] = '-02:04:59.21'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'Coordinate_waveband2'] = 'Y-band'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'Coordinate_Source2'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2', 'Name1'] = 'J113126.08-020459.2 / J1131-0204W'\n",
    "MAC.loc[MAC.Name1=='J113126.08-020459.2 / J1131-0204W', 'Name2'] = 'J1131-0204E'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'RA1'] = '11:46:42.466'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'Dec1'] = '+51:10:29.46'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'Coordinate_waveband1'] = 'Y-band'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'RA2'] = '11:46:42.630'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'Dec2'] = '+51:10:31.69'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'Coordinate_waveband2'] = 'Y-band'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'Coordinate_Source2'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6', 'Name1'] = 'J114642.47+511029.6 / J1146+5110SW'\n",
    "MAC.loc[MAC.Name1=='J114642.47+511029.6 / J1146+5110SW', 'Name2'] = 'J1146+5110NE'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'RA1'] = '13:32:26.340'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'Dec1'] = '+06:06:27.31'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'Coordinate_waveband1'] = 'Y-band'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'RA2'] = '13:32:26.372'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'Dec2'] = '+06:06:28.73'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'Coordinate_waveband2'] = 'Y-band'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'Coordinate_Source2'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4', 'Name1'] = 'J133226.34+060627.4 / J1332+0606SW'\n",
    "MAC.loc[MAC.Name1=='J133226.34+060627.4 / J1332+0606SW', 'Name2'] = 'J1332+0606NE'\n",
    "\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'RA1'] = '09:24:55.277'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'Dec1'] = '+05:10:52.09'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'Equinox1'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'Coordinate_waveband1'] = '[OIII]'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'Coordinate_Source1'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'RA2'] = '09:24:55.255'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'Dec2'] = '+05:10:52.13'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'Equinox2'] = 'J2000'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'Coordinate_waveband2'] = '[OIII]'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'Coordinate_Source2'] = 'HST WFC3'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0', 'Name1'] = 'J092455.24+051052.0 / J0924+0510E'\n",
    "MAC.loc[MAC.Name1=='J092455.24+051052.0 / J0924+0510E', 'Name2'] = 'J0924+0510W'\n",
    "\n",
    "\n",
    "# tagging some additional DOI info I missed previously for J135429.06+132757.3 (tagged by Liu and Keel)\n",
    "MAC.loc[MAC.Name1=='J135429.06+132757.3', 'Paper(s)'] += ' ; Keel+2019'\n",
    "MAC.loc[MAC.Name1=='J135429.06+132757.3', 'BibCode(s)'] += ' ; 2019MNRAS.483.4847K'\n",
    "MAC.loc[MAC.Name1=='J135429.06+132757.3', 'DOI(s)'] += ' ; https://doi.org/10.1093/mnras/sty3332'\n",
    "\n",
    "# adding missing angular separations now...\n",
    "objs = ['J1558+2723 G3','IRAS 05589+2828','IRAS 03219+4031','J181611.72+423941.6 (J1816 NE)','Mrk 248',\\\n",
    "        'Mrk 268','NGC 7679','M106','NGC 3227','NGC 2992','NGC 1052','MCG +04-48-002','4C60.07 Radio Core',\\\n",
    "       'J1114+4036 A','ESO 286-G17','ESO 432-IG006 SW / WISEA J084427.19-314150.8','J1036+0221','J0122+0100 NW',\\\n",
    "       'J1045+3519 W','J1221+1137 NE','J1301+2918 NE','SDSS J084810.10+351534.4','NGC 5278','UGC 6081',\\\n",
    "       'NGC 7592 E','ESO 1327-2041 Galaxy','J1536+0441 VLA-A','SBS 1421+511 QSO','PKS B1345+125 NW','VV 114 E',\\\n",
    "       'J0122+0100 NW','J0841+0101 E','J0859+1310 NE','J0905+3747 NE','J1045+3519 W','J1159+5320 SE',\\\n",
    "       'J1221+1137 NE','J1301+2918 NE','J2356-1016 NW','SDSSJ1600+0000A','J09527.62+255257.2 / J0952+2552NE',\\\n",
    "       'J123915.\\40+531414.6 / J1239+5314NE','J132231.86+263159.1 / J1322+2631SW',\\\n",
    "        'J135646.11+102609.1 / J1356+1026NE','J112659.54+294442.8 / J1126+2944NWJ112659.54+294442.8',\\\n",
    "        'J110851.04+065901.4 / J1108+0659NW','J113126.08-020459.2 / J1131-0204W',\\\n",
    "        'J114642.47+511029.6 / J1146+5110SW',\\\n",
    "        'J133226.34+060627.4 / J1332+0606SW','J092455.24+051052.0','J020954.80-100223.00']\n",
    "\n",
    "for i in objs:\n",
    "    try:\n",
    "        for index, row in MAC[MAC['Name1']==str(i)].iterrows():\n",
    "            c1 = SkyCoord(Angle(str(row['RA1'])+' hours').degree,Angle(str(row['Dec1'])+' degrees').degree, unit='deg', frame='icrs')\n",
    "            c2 = SkyCoord(Angle(str(row['RA2'])+' hours').degree,Angle(str(row['Dec2'])+' degrees').degree, unit='deg', frame='icrs')\n",
    "            MAC.at[index, 'Sep'] = c1.separation(c2).arcsecond\n",
    "    except:\n",
    "        print(str(i))\n",
    "\n",
    "\n",
    "# and now we're overwriting any junk where I previously put 0 for a separation\n",
    "MAC.loc[MAC.Sep==0, 'Sep'] = -99\n",
    "\n",
    "# J1558+2723 G3 Eckert+2017\n",
    "# 4C60.07 Radio Core --> sedgwick target\n",
    "# BAT selected in Koss 2012:\n",
    "# 'IRAS 05589+2828','IRAS 03219+4031','J181611.72+423941.6 (J1816 NE)','Mrk 248',\\\n",
    "#        'Mrk 268','NGC 7679','M106','NGC 3227','NGC 2992','NGC 1052','MCG +04-48-002'\n",
    "#J1114+4036 A --> barrows 2016\n",
    "# ESO 286-G17 --> Sekiguchi+1992\n",
    "# ESO 432-IG006 SW / WISEA J084427.19-314150.8 --> Torres-Alba+2018\n",
    "# J1036+0221 --> Satyapal, Dutta, and Pfeifle\n",
    "# Batcheldor+2010 corrected in individual table. Separatins now included manually\n",
    "# additional coordinates now included in individual table for my 2019 paper\n",
    "# J020954.80-100223.00 from tytler seems to be a multi-arcminute sep but it's listed as 12as in their table. recomputing now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd76be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just manually corrected the separations from Lena+2014; they were listed  in mas, so I shifted them by \\\n",
    "# 1.e-3 to be arcseconds\n",
    "\n",
    "# manually adjusted the separation fo rthe sudou+2003 target. A wierd angular sep was listed. \\\n",
    "# grabbed the physical sep in cm fom paper, converted to pc, and put that into kpc for the table. Will convert from \\\n",
    "# kpc back to as here up above when we need to again\n",
    "#********''\n",
    "\n",
    "# SDSS J1201+30 manually added the 0.6mpc physical sep and will convert to angular above\n",
    "\n",
    "# sep of 0.000015 manually added for Kharb 2019\n",
    "\n",
    "# gamma ray added to qp for zhou2018\n",
    "\n",
    "# 3C 279\n",
    "\n",
    "#1823+568 just added in the physical seps measured by roland2013 manually\n",
    "#\n",
    "#3C 279  1823+568 manually adjusted; separations from roland2013 included. adjustments made to seelction methods\n",
    "#\n",
    "#1308+326 under vol'vach manually adjusted\n",
    "#***** --> but I think this is an overlap target with roland???\n",
    "\n",
    "# no sep for 3FGL J0449.4-4350 but adjusted selection methods\n",
    "\n",
    "# sep added for PKS 0426-380 and gamma-ray added to PKS 0426-380 and 0301\n",
    "\n",
    "# everything that had covino+ now has gamma-ray icluded i the periodicity selection\n",
    "\n",
    "# seps added and sel revised for mrk 231\n",
    "\n",
    "# PKS 2155-304 sel adjsusted no sep avail\n",
    "\n",
    "# S4 0954+658 sel adjusted to quasi-periodicity and no sep avail\n",
    "\n",
    "# S0528+134 no sep and keeping variability. might change the othet back too\n",
    "\n",
    "\n",
    "\n",
    "# we need to come up with a flag or upper limit choice to adopt in all binary cases when we have nothing\\\n",
    "# Krause+2019 is one example here. All of those targets do not have separations listed. We'll need to either throw \\\n",
    "# a flag or adopt an upper limit\n",
    "\n",
    "# E1821+643 flagged simply as -99 in separations\n",
    "# recoil hypothesis still seems alright but binary hypothesis is bunk\n",
    "\n",
    "# Bhatta 2018 flagged as -99 for seps but added radio imaging/radio to periodicity\n",
    "\n",
    "# for Kharb+2015 ; Das+2018, 8pc is an upper limit. We will need to introduce a flag at some point. But I don't really believe this target anyhow\n",
    "\n",
    "# kharb+2014 flagged as -99 in seps\n",
    "\n",
    "# almost no seps listed for liu 2014 radio imaging\n",
    "# only one we can include is the 6mas for 3C 454\n",
    "\n",
    "#NGC 5515 (J141238.14+391836.5)\n",
    "#Mrk 1469 (J121607.08+504930.0)\n",
    "# both from gabanyi2013a; no sep listed so flagged as -99. No addition coords avail.\n",
    "\n",
    "# papers by lewis, erlacoues 1994, gezari, doan, liu2016 (binaries), and du 21018 do not contain firm separations\\\n",
    "# just discussing in passing of some seps that are usually in conflict. We are flagging these all as -99 in sep.\n",
    "\n",
    "# added the 37 pc estimate for pesce 2018. Need to reverse calculate the angular sep (which should be ~0.1'')\n",
    "\n",
    "# added 0.1 pc for 4C+22.25 (Decarli 2010). This is an upper limit. We will need to institute a flag.\n",
    "\n",
    "# added 33micro as for Ark 120 (Du+2018 ; Li+2019 ; Hu+2020) and 0.02 pc as seps. these come from Li+\n",
    "\n",
    "# added 0.002 pc for Spikey (Hu+2020 ; Kun+2020)\n",
    "\n",
    "# 4C +01.30,\n",
    "# J0116-473,\n",
    "# no seps provided by Liu+2004, so flagged as -99\n",
    "# but machalski includes sep of optical nuclei for 3C 293. Corrected this in the individual table. Was 0.00880kpc \\\n",
    "# but now corrected to 0.880 kpc (or 880 pc)\n",
    "# 3C 293 also includes a tag for dual agn candidate since the optical nuclei suggest a dual and not a binary\n",
    "\n",
    "# for J1050+3456 (shields 2009) we have included their estimate of a 10**0.3 offset of the their recoil candidate\n",
    "\n",
    "# no seps forn WISE J020446.13-050640.8 (assef 2013)\n",
    "\n",
    "# no seps for kim +2018 (mrk 1018). flagged as -99\n",
    "\n",
    "# no seps for steinhardt target 0956. flagged as -99\n",
    "\n",
    "# no seps listed for v from liu 2003; flagging as -99\n",
    "\n",
    "# for 3C 454.3 phys sep of 0.04213 pc comes from vol'vach 2007. This is an upper limit. li06 estimated something a little smaller\n",
    "\n",
    "# BL LAC ang and phys seps drawn from caproni 2013 (0.17 pc)\n",
    "# punched yup the selection methods for BL LAC\n",
    "\n",
    "# all the sources looked only at by ciaramella have been adjusted in terms of select method and flagged as -99 in seps\n",
    "\n",
    "# items from Rieger2007: sel methods are getting adjusted to match what he claims, but if it is only mentioned by him\\\n",
    "# sep is flagged as -99. I simply don't trust that work. \n",
    "\n",
    "# 0.000005 pc adopted for phys sep of Mrk 501. Comes from Bhatta and agrees with Villata99\n",
    "\n",
    "# went through for all QPO sandrinelli targets and punched up the select methods\n",
    "\n",
    "# seps for AO 0235+164 1 mas and is upper limit. comes from ostorero+04\n",
    "\n",
    "# 5 mpc added for serafinelli target mrk 915. need to go and add selection method/possible sep to the \\\n",
    "# severgnini target that serafinelli also selected\n",
    "#*******\n",
    "\n",
    "# 3C 84 (britzen 2019) flagged as -99 for seps. added radio imaging to sel meth.\n",
    "\n",
    "# added phys sep of 0.014 pc for 1308 (britzen 2015)\n",
    "\n",
    "# 0735+178 flagged as -99 for seps (Britzen 2015)\n",
    "\n",
    "# J1536+0441 --> moving this from dual candidate to dual but also keeping the bioanary candidate status. \\\n",
    "# But bondi and wrobel do a pretty good jb og showing this is very  likely dual but the vel offset still makes\\\n",
    "# it a candidate\n",
    "\n",
    "# j0927 flagged as -99 because I'm not sure yet what we should ark as separations\n",
    "\n",
    "# xu 2009 J1316 reflagged as -99 because I don't see a separation listed in paper\n",
    "\n",
    "# NGC 5548 flagged as 0.0324078 pc for phys seps. This comes from peterson and is a lower limit. \n",
    "# peterson quote 10**17/sin i\n",
    "\n",
    "# 3C 332 getting flagged as -99 for seps since this is a highly unlikely binary\n",
    "\n",
    "# arp102b changed to -99 and -99 for seps. can't find my original sep in the papers\n",
    "  \n",
    "    \n",
    "# upper limits....\n",
    "# 4C+22.25\n",
    "\n",
    "# we will need to go back and add velocity offsets for stuff like recoil candidates/binary candidates based on \\\n",
    "# velocity offset broad lines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62c55215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now adjusting the selection, analysis, and confirmation methodologies....\n",
    "#Comerford+2009a\n",
    "#Mrk 273 asked imanishi, but still need to ask vivian u\n",
    "\n",
    "#Need to measure separations\n",
    "######## ******* Need to email Fu about 2012 and 2011 papers\n",
    "# calculating here separations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "246617a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting the confirmation method for the radio dual AGN in Fu+2015a,b\n",
    "objs = ['J220634.97+000327.6','J005113.94+002047.2']\n",
    "\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if row['Name1']==str(i):\n",
    "            MAC.at[index, 'Confirmation Methood'] = 'Radio Imaging'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f3a1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here we're going to fix up the duplicate Name1 and Name2s, duplicate coordinates between RA1 and RA2, etc...\n",
    "name2fix = ['4C+22.25 / J1000+2233','084047.58+131223.5 / 3C 207','Abell 1145 / B1059+169 (Abell 1145)',\\\n",
    "            '3C 136.1 / 3C136.1','3C 315 / 3C315','3C 403 / 3C403','3C 52 / 3C52','4C 01.30 / 4C +01.30',\\\n",
    "            '4C 12.03 / 4C12.03','4C 48.29 / 4C48.29']\n",
    "\n",
    "for index, row in MAC.iterrows():\n",
    "    if (row['RA1'] == row['RA2']) and (row['Dec1'] == row['Dec2']):\n",
    "        #gimli.at[index, 'Confidence Flag'] = -1\n",
    "        MAC.at[index, 'RA2'] = -99\n",
    "        MAC.at[index, 'Dec2'] = -99\n",
    "        MAC.at[index, 'Equinox2'] = -99\n",
    "        MAC.at[index, 'Coordinate_waveband2'] = -99\n",
    "        MAC.at[index, 'Coordinate_Source2'] = -99\n",
    "        \n",
    "for index, row in MAC.iterrows():\n",
    "    if row['Name1'] == row['Name2']:\n",
    "        MAC.at[index, 'Name2'] = '-99'\n",
    "        \n",
    "for index, row in MAC.iterrows():\n",
    "    if row['Name1'] == '3C 433 / 3C433':    \n",
    "        MAC.at[index, 'Name2'] = '-99'\n",
    "        MAC.at[index, 'RA2'] = -99\n",
    "        MAC.at[index, 'Dec2'] = -99\n",
    "        MAC.at[index, 'Equinox2'] = -99\n",
    "        MAC.at[index, 'Coordinate_waveband2'] = -99\n",
    "        MAC.at[index, 'Coordinate_Source2'] = -99\n",
    "        MAC.at[index, 'Name1'] = '3C 433'\n",
    "    elif row['Literature Name'] == 'J093201.60+031858.7':    \n",
    "        MAC.at[index, 'Name2'] = '-99'\n",
    "    elif row['Name1'] in name2fix:    \n",
    "        MAC.at[index, 'Name2'] = '-99'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c227ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>System Type</th>\n",
       "      <th>Literature Name</th>\n",
       "      <th>Selection Method</th>\n",
       "      <th>Confirmation Method</th>\n",
       "      <th>Name1</th>\n",
       "      <th>z1</th>\n",
       "      <th>z1_type</th>\n",
       "      <th>RA1</th>\n",
       "      <th>Dec1</th>\n",
       "      <th>Coordinate_waveband1</th>\n",
       "      <th>Coordinate_Source1</th>\n",
       "      <th>Equinox1</th>\n",
       "      <th>Brightness1</th>\n",
       "      <th>Brightness_band1</th>\n",
       "      <th>Brightness_type1</th>\n",
       "      <th>Name2</th>\n",
       "      <th>z2</th>\n",
       "      <th>z2_type</th>\n",
       "      <th>RA2</th>\n",
       "      <th>Dec2</th>\n",
       "      <th>Equinox2</th>\n",
       "      <th>Coordinate_waveband2</th>\n",
       "      <th>Coordinate_Source2</th>\n",
       "      <th>Brightness2</th>\n",
       "      <th>Brightness_band2</th>\n",
       "      <th>Brightness_type2</th>\n",
       "      <th>dV</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Sep(kpc)</th>\n",
       "      <th>dV_rwp</th>\n",
       "      <th>Paper(s)</th>\n",
       "      <th>BibCode(s)</th>\n",
       "      <th>DOI(s)</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Confidence Flag</th>\n",
       "      <th>Processed System Type</th>\n",
       "      <th>Legacy System Type</th>\n",
       "      <th>Primary System Type</th>\n",
       "      <th>Secondary System Type</th>\n",
       "      <th>Tertiary System Type</th>\n",
       "      <th>ST1 Confidence Flag</th>\n",
       "      <th>ST2 Confidence Flag</th>\n",
       "      <th>ST3 Confidence Flag</th>\n",
       "      <th>Confirmation Methood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, System Type, Literature Name, Selection Method, Confirmation Method, Name1, z1, z1_type, RA1, Dec1, Coordinate_waveband1, Coordinate_Source1, Equinox1, Brightness1, Brightness_band1, Brightness_type1, Name2, z2, z2_type, RA2, Dec2, Equinox2, Coordinate_waveband2, Coordinate_Source2, Brightness2, Brightness_band2, Brightness_type2, dV, Sep, Sep(kpc), dV_rwp, Paper(s), BibCode(s), DOI(s), Notes, Confidence Flag, Processed System Type, Legacy System Type, Primary System Type, Secondary System Type, Tertiary System Type, ST1 Confidence Flag, ST2 Confidence Flag, ST3 Confidence Flag, Confirmation Methood]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gandalfcheck = gandalf[(gandalf['RA1'].astype(str)==gandalf['RA2'].astype(str)) & (gandalf['Dec1'].astype(str)==gandalf['Dec2'].astype(str))]\n",
    "#gandalfcheck\n",
    "\n",
    "MACcheck = MAC[(MAC['RA1'].astype(str)==MAC['RA2'].astype(str)) & (MAC['Dec1'].astype(str)==MAC['Dec2'].astype(str))]\n",
    "\n",
    "MACcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a4fb512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>System Type</th>\n",
       "      <th>Literature Name</th>\n",
       "      <th>Selection Method</th>\n",
       "      <th>Confirmation Method</th>\n",
       "      <th>Name1</th>\n",
       "      <th>z1</th>\n",
       "      <th>z1_type</th>\n",
       "      <th>RA1</th>\n",
       "      <th>Dec1</th>\n",
       "      <th>Coordinate_waveband1</th>\n",
       "      <th>Coordinate_Source1</th>\n",
       "      <th>Equinox1</th>\n",
       "      <th>Brightness1</th>\n",
       "      <th>Brightness_band1</th>\n",
       "      <th>Brightness_type1</th>\n",
       "      <th>Name2</th>\n",
       "      <th>z2</th>\n",
       "      <th>z2_type</th>\n",
       "      <th>RA2</th>\n",
       "      <th>Dec2</th>\n",
       "      <th>Equinox2</th>\n",
       "      <th>Coordinate_waveband2</th>\n",
       "      <th>Coordinate_Source2</th>\n",
       "      <th>Brightness2</th>\n",
       "      <th>Brightness_band2</th>\n",
       "      <th>Brightness_type2</th>\n",
       "      <th>dV</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Sep(kpc)</th>\n",
       "      <th>dV_rwp</th>\n",
       "      <th>Paper(s)</th>\n",
       "      <th>BibCode(s)</th>\n",
       "      <th>DOI(s)</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Confidence Flag</th>\n",
       "      <th>Processed System Type</th>\n",
       "      <th>Legacy System Type</th>\n",
       "      <th>Primary System Type</th>\n",
       "      <th>Secondary System Type</th>\n",
       "      <th>Tertiary System Type</th>\n",
       "      <th>ST1 Confidence Flag</th>\n",
       "      <th>ST2 Confidence Flag</th>\n",
       "      <th>ST3 Confidence Flag</th>\n",
       "      <th>Confirmation Methood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, System Type, Literature Name, Selection Method, Confirmation Method, Name1, z1, z1_type, RA1, Dec1, Coordinate_waveband1, Coordinate_Source1, Equinox1, Brightness1, Brightness_band1, Brightness_type1, Name2, z2, z2_type, RA2, Dec2, Equinox2, Coordinate_waveband2, Coordinate_Source2, Brightness2, Brightness_band2, Brightness_type2, dV, Sep, Sep(kpc), dV_rwp, Paper(s), BibCode(s), DOI(s), Notes, Confidence Flag, Processed System Type, Legacy System Type, Primary System Type, Secondary System Type, Tertiary System Type, ST1 Confidence Flag, ST2 Confidence Flag, ST3 Confidence Flag, Confirmation Methood]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MACcheck = MAC[(MAC['Name1']==MAC['Name2'])]#gandalf[(gandalf['RA2']=='-99')]\n",
    "print(len(MACcheck))\n",
    "MACcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "628aa13c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>System Type</th>\n",
       "      <th>Literature Name</th>\n",
       "      <th>Selection Method</th>\n",
       "      <th>Confirmation Method</th>\n",
       "      <th>Name1</th>\n",
       "      <th>z1</th>\n",
       "      <th>z1_type</th>\n",
       "      <th>RA1</th>\n",
       "      <th>Dec1</th>\n",
       "      <th>Coordinate_waveband1</th>\n",
       "      <th>Coordinate_Source1</th>\n",
       "      <th>Equinox1</th>\n",
       "      <th>Brightness1</th>\n",
       "      <th>Brightness_band1</th>\n",
       "      <th>Brightness_type1</th>\n",
       "      <th>Name2</th>\n",
       "      <th>z2</th>\n",
       "      <th>z2_type</th>\n",
       "      <th>RA2</th>\n",
       "      <th>Dec2</th>\n",
       "      <th>Equinox2</th>\n",
       "      <th>Coordinate_waveband2</th>\n",
       "      <th>Coordinate_Source2</th>\n",
       "      <th>Brightness2</th>\n",
       "      <th>Brightness_band2</th>\n",
       "      <th>Brightness_type2</th>\n",
       "      <th>dV</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Sep(kpc)</th>\n",
       "      <th>dV_rwp</th>\n",
       "      <th>Paper(s)</th>\n",
       "      <th>BibCode(s)</th>\n",
       "      <th>DOI(s)</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Confidence Flag</th>\n",
       "      <th>Processed System Type</th>\n",
       "      <th>Legacy System Type</th>\n",
       "      <th>Primary System Type</th>\n",
       "      <th>Secondary System Type</th>\n",
       "      <th>Tertiary System Type</th>\n",
       "      <th>ST1 Confidence Flag</th>\n",
       "      <th>ST2 Confidence Flag</th>\n",
       "      <th>ST3 Confidence Flag</th>\n",
       "      <th>Confirmation Methood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Dual AGN Candidate / Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>Fiber Spectroscopy / Optical Spectroscopy / Op...</td>\n",
       "      <td>/ Radio Imaging</td>\n",
       "      <td>J005113.94+002047.2</td>\n",
       "      <td>0.1124</td>\n",
       "      <td>spec</td>\n",
       "      <td>00:51:13.94</td>\n",
       "      <td>+00:20:47.2</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>J2000</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>J005114.12+002049.2</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>spec</td>\n",
       "      <td>00:51:14.12</td>\n",
       "      <td>+00:20:49.2</td>\n",
       "      <td>J2000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>3.360020</td>\n",
       "      <td>6.867234</td>\n",
       "      <td>-53.752809</td>\n",
       "      <td>Liu+2011b ; Fu+2015 ; Fu+2015b ; Gross+2019</td>\n",
       "      <td>2011ApJ...737..101L ; 2015ApJ...799...72F ; 20...</td>\n",
       "      <td>https://doi.org/10.1088/0004-637X/737/2/101 ; ...</td>\n",
       "      <td>Two compact steep-spectrum sources identified.</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Dual AGN Candidate / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>Radio Imaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>330</td>\n",
       "      <td>Dual AGN Candidate / Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>Fiber Spectroscopy / Optical Spectroscopy / Op...</td>\n",
       "      <td>-99</td>\n",
       "      <td>J100602.14+071131.0</td>\n",
       "      <td>0.1218</td>\n",
       "      <td>spec</td>\n",
       "      <td>10:06:02.14</td>\n",
       "      <td>+07:11:31.0</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>J2000</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>J100602.51+071131.8</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>spec</td>\n",
       "      <td>10:06:02.51</td>\n",
       "      <td>+07:11:31.8</td>\n",
       "      <td>J2000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>5.564144</td>\n",
       "      <td>12.192223</td>\n",
       "      <td>346.697471</td>\n",
       "      <td>Liu+2011b ; Ge+2012 ; Rubinur+2019</td>\n",
       "      <td>2011ApJ...737..101L ; 2012ApJS..201...31G ; 20...</td>\n",
       "      <td>https://doi.org/10.1088/0004-637X/737/2/101 ; ...</td>\n",
       "      <td>. Dual AGN;dual radio sources coincident with...</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Dual AGN Candidate / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>1194</td>\n",
       "      <td>Dual AGN Candidate / Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>Fiber Spectroscopy / Optical Spectroscopy / Op...</td>\n",
       "      <td>/ Radio Imaging</td>\n",
       "      <td>J220634.97+000327.6</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>spec</td>\n",
       "      <td>22:06:34.97</td>\n",
       "      <td>+00:03:27.6</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>J2000</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>J220635.08+000323.2</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>spec</td>\n",
       "      <td>22:06:35.08</td>\n",
       "      <td>+00:03:23.2</td>\n",
       "      <td>J2000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>4.699202</td>\n",
       "      <td>4.298385</td>\n",
       "      <td>142.877614</td>\n",
       "      <td>Liu+2011b ; Fu+2015 ; Fu+2015b ; Gross+2019</td>\n",
       "      <td>2011ApJ...737..101L ; 2015ApJ...799...72F ; 20...</td>\n",
       "      <td>https://doi.org/10.1088/0004-637X/737/2/101 ; ...</td>\n",
       "      <td>Two compact steep-spectrum sources identified.</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Dual AGN Candidate / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>Radio Imaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>1359</td>\n",
       "      <td>Binary Quasar / Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>Fiber Spectroscopy / Optical Spectroscopy / Op...</td>\n",
       "      <td>Slit Optical Spectroscopy / Optical Spectrosco...</td>\n",
       "      <td>SDSSJ0117+0020A</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>spec</td>\n",
       "      <td>1:17:58.84</td>\n",
       "      <td>+0:20:21.5</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>J2000</td>\n",
       "      <td>17.67</td>\n",
       "      <td>SDSS g PSF ext-corr</td>\n",
       "      <td>asinh</td>\n",
       "      <td>SDSSJ0117+0021B</td>\n",
       "      <td>0.6110</td>\n",
       "      <td>spec</td>\n",
       "      <td>1:17:58.0</td>\n",
       "      <td>+0:21:4.1</td>\n",
       "      <td>J2000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>20.01</td>\n",
       "      <td>SDSS g PSF ext-corr</td>\n",
       "      <td>asinh</td>\n",
       "      <td>370.967599</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>Hennawi+2006 ; Farina+2011</td>\n",
       "      <td>2006AJ....131....1H ; 2011MNRAS.415.3163F</td>\n",
       "      <td>https://doi.org/10.1086/498235 ; https://doi.o...</td>\n",
       "      <td>Coordinates not provided by Farina+. This pair...</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Binary Quasar / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>1386</td>\n",
       "      <td>Binary Quasar / Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>Fiber Spectroscopy / Optical Spectroscopy / Op...</td>\n",
       "      <td>Slit Optical Spectroscopy / Optical Spectrosco...</td>\n",
       "      <td>SDSSJ0747+4318A</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>spec</td>\n",
       "      <td>7:47:59.02</td>\n",
       "      <td>+43:18:5.4</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>J2000</td>\n",
       "      <td>19.24</td>\n",
       "      <td>SDSS g PSF ext-corr</td>\n",
       "      <td>asinh</td>\n",
       "      <td>SDSSJ0747+4318B</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>spec</td>\n",
       "      <td>7:47:59.66</td>\n",
       "      <td>+43:18:11.5</td>\n",
       "      <td>J2000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>19.45</td>\n",
       "      <td>SDSS g PSF ext-corr</td>\n",
       "      <td>asinh</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>Hennawi+2006 ; Farina+2011 ; Sandrinelli+2014</td>\n",
       "      <td>2006AJ....131....1H ; 2011MNRAS.415.3163F ; 20...</td>\n",
       "      <td>https://doi.org/10.1086/498235 ; https://doi.o...</td>\n",
       "      <td>Coordinates not provided by Farina+. This pair...</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Binary Quasar / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>1390</td>\n",
       "      <td>Binary Quasar / Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>Fiber Spectroscopy / Optical Spectroscopy / Op...</td>\n",
       "      <td>Slit Optical Spectroscopy / Optical Spectrosco...</td>\n",
       "      <td>SDSSJ0824+2357A</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>spec</td>\n",
       "      <td>8:24:40.61</td>\n",
       "      <td>+23:57:9.9</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>J2000</td>\n",
       "      <td>18.51</td>\n",
       "      <td>SDSS g PSF ext-corr</td>\n",
       "      <td>asinh</td>\n",
       "      <td>SDSSJ0824+2357B</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>spec</td>\n",
       "      <td>8:24:39.83</td>\n",
       "      <td>+23:57:20.3</td>\n",
       "      <td>J2000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>18.67</td>\n",
       "      <td>SDSS g PSF ext-corr</td>\n",
       "      <td>asinh</td>\n",
       "      <td>194.724825</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>Hennawi+2006 ; Farina+2011 ; Sandrinelli+2014</td>\n",
       "      <td>2006AJ....131....1H ; 2011MNRAS.415.3163F ; 20...</td>\n",
       "      <td>https://doi.org/10.1086/498235 ; https://doi.o...</td>\n",
       "      <td>Coordinates not provided by Farina+. This pair...</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Binary Quasar / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1395</td>\n",
       "      <td>Binary Quasar / Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>Fiber Spectroscopy / Optical Spectroscopy / Op...</td>\n",
       "      <td>Slit Optical Spectroscopy / Optical Spectrosco...</td>\n",
       "      <td>SDSSJ0845+0711A</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>spec</td>\n",
       "      <td>8:45:41.53</td>\n",
       "      <td>+7:11:52.3</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>J2000</td>\n",
       "      <td>18.47</td>\n",
       "      <td>SDSS g PSF ext-corr</td>\n",
       "      <td>asinh</td>\n",
       "      <td>SDSSJ0845+0710B</td>\n",
       "      <td>0.5370</td>\n",
       "      <td>spec</td>\n",
       "      <td>8:45:41.19</td>\n",
       "      <td>+7:10:50.3</td>\n",
       "      <td>J2000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>19.24</td>\n",
       "      <td>SDSS g PSF ext-corr</td>\n",
       "      <td>asinh</td>\n",
       "      <td>-194.598092</td>\n",
       "      <td>62.200000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>Hennawi+2006 ; Farina+2011 ; Sandrinelli+2014</td>\n",
       "      <td>2006AJ....131....1H ; 2011MNRAS.415.3163F ; 20...</td>\n",
       "      <td>https://doi.org/10.1086/498235 ; https://doi.o...</td>\n",
       "      <td>Coordinates not provided by Farina+. This pair...</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Binary Quasar / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1397</td>\n",
       "      <td>Binary Quasar / Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>Fiber Spectroscopy / Optical Spectroscopy / Op...</td>\n",
       "      <td>Slit Optical Spectroscopy / Optical Spectrosco...</td>\n",
       "      <td>SDSSJ0856+5111A</td>\n",
       "      <td>0.5430</td>\n",
       "      <td>spec</td>\n",
       "      <td>8:56:25.63</td>\n",
       "      <td>+51:11:37.4</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>J2000</td>\n",
       "      <td>18.52</td>\n",
       "      <td>SDSS g PSF ext-corr</td>\n",
       "      <td>asinh</td>\n",
       "      <td>SDSSJ0856+5111B</td>\n",
       "      <td>0.5430</td>\n",
       "      <td>spec</td>\n",
       "      <td>8:56:26.71</td>\n",
       "      <td>+51:11:18.2</td>\n",
       "      <td>J2000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>19.55</td>\n",
       "      <td>SDSS g PSF ext-corr</td>\n",
       "      <td>asinh</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>Hennawi+2006 ; Farina+2011 ; Sandrinelli+2014</td>\n",
       "      <td>2006AJ....131....1H ; 2011MNRAS.415.3163F ; 20...</td>\n",
       "      <td>https://doi.org/10.1086/498235 ; https://doi.o...</td>\n",
       "      <td>Coordinates not provided by Farina+. This pair...</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Binary Quasar / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>1822</td>\n",
       "      <td>Dual AGN Candidate / Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>Optical Imaging / Optical Colors / Optical Spe...</td>\n",
       "      <td>Optical Spectroscopy / Optical Spectroscopy / ...</td>\n",
       "      <td>J155330.23+223010.22</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>spec</td>\n",
       "      <td>15:53:30.23</td>\n",
       "      <td>22:30:10.22</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>J2000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>J155330.55+223014.36</td>\n",
       "      <td>0.6420</td>\n",
       "      <td>spec</td>\n",
       "      <td>15:53:30.55</td>\n",
       "      <td>22:30:14.36</td>\n",
       "      <td>J2000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-182.150455</td>\n",
       "      <td>6.111000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>Eftekharzadeh+2017 ; Sandrinelli+2014</td>\n",
       "      <td>2017MNRAS.468...77E ; 2014MNRAS.444.1835S</td>\n",
       "      <td>https://doi.org/10.1093/mnras/stx412 ; https:/...</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Dual AGN Candidate / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>4886</td>\n",
       "      <td>Likely Single AGN / Dual AGN</td>\n",
       "      <td>SDSS J171544.05+600835.7</td>\n",
       "      <td>Double-Peaked Optical Spectroscopic Emission L...</td>\n",
       "      <td>-99</td>\n",
       "      <td>SDSS J171544.05+600835.7</td>\n",
       "      <td>0.1569</td>\n",
       "      <td>spec</td>\n",
       "      <td>17:15:44.033</td>\n",
       "      <td>+60:08:35.71</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>Chandra</td>\n",
       "      <td>J2000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>J171544.05+600835.7</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>Comerford+2011 ; Liu+2010a ; Smith+2010 ; Smit...</td>\n",
       "      <td>2011ApJ...737L..19C ; 2010ApJ...708..427L ; 20...</td>\n",
       "      <td>https://doi.org/10.1088/2041-8205/737/1/L19 ; ...</td>\n",
       "      <td>Individual redshifts not listed but velocity o...</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Likely Single AGN / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>5505</td>\n",
       "      <td>Dual AGN Candidate / Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>Fiber Optical Spectroscopy / Optical Spectrosc...</td>\n",
       "      <td>Optical Fiber Spectroscopy / Optical Imaging /...</td>\n",
       "      <td>SDSS J1120+6711A</td>\n",
       "      <td>1.4940</td>\n",
       "      <td>-99</td>\n",
       "      <td>11:20:12.11</td>\n",
       "      <td>+67:11:16.0</td>\n",
       "      <td>Optical</td>\n",
       "      <td>SDSS</td>\n",
       "      <td>J2000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>SDSS J1120+6711B</td>\n",
       "      <td>1.4900</td>\n",
       "      <td>spec</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>Inada+2008 ; Pindor+2006</td>\n",
       "      <td>2008AJ....135..496I ; 2006AJ....131...41P</td>\n",
       "      <td>https://doi.org/10.1088/0004-6256/135/2/496 ; ...</td>\n",
       "      <td>velocoity difference of roughly 10 km per s. R...</td>\n",
       "      <td>-99</td>\n",
       "      <td>Dual AGN / Dual AGN Candidate</td>\n",
       "      <td>Dual AGN Candidate / Dual AGN</td>\n",
       "      <td>Dual AGN</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                    System Type           Literature Name  \\\n",
       "21            21  Dual AGN Candidate / Dual AGN                       -99   \n",
       "330          330  Dual AGN Candidate / Dual AGN                       -99   \n",
       "1194        1194  Dual AGN Candidate / Dual AGN                       -99   \n",
       "1359        1359       Binary Quasar / Dual AGN                       -99   \n",
       "1386        1386       Binary Quasar / Dual AGN                       -99   \n",
       "1390        1390       Binary Quasar / Dual AGN                       -99   \n",
       "1395        1395       Binary Quasar / Dual AGN                       -99   \n",
       "1397        1397       Binary Quasar / Dual AGN                       -99   \n",
       "1822        1822  Dual AGN Candidate / Dual AGN                       -99   \n",
       "4886        4886   Likely Single AGN / Dual AGN  SDSS J171544.05+600835.7   \n",
       "5505        5505  Dual AGN Candidate / Dual AGN                       -99   \n",
       "\n",
       "                                       Selection Method  \\\n",
       "21    Fiber Spectroscopy / Optical Spectroscopy / Op...   \n",
       "330   Fiber Spectroscopy / Optical Spectroscopy / Op...   \n",
       "1194  Fiber Spectroscopy / Optical Spectroscopy / Op...   \n",
       "1359  Fiber Spectroscopy / Optical Spectroscopy / Op...   \n",
       "1386  Fiber Spectroscopy / Optical Spectroscopy / Op...   \n",
       "1390  Fiber Spectroscopy / Optical Spectroscopy / Op...   \n",
       "1395  Fiber Spectroscopy / Optical Spectroscopy / Op...   \n",
       "1397  Fiber Spectroscopy / Optical Spectroscopy / Op...   \n",
       "1822  Optical Imaging / Optical Colors / Optical Spe...   \n",
       "4886  Double-Peaked Optical Spectroscopic Emission L...   \n",
       "5505  Fiber Optical Spectroscopy / Optical Spectrosc...   \n",
       "\n",
       "                                    Confirmation Method  \\\n",
       "21                                      / Radio Imaging   \n",
       "330                                                 -99   \n",
       "1194                                    / Radio Imaging   \n",
       "1359  Slit Optical Spectroscopy / Optical Spectrosco...   \n",
       "1386  Slit Optical Spectroscopy / Optical Spectrosco...   \n",
       "1390  Slit Optical Spectroscopy / Optical Spectrosco...   \n",
       "1395  Slit Optical Spectroscopy / Optical Spectrosco...   \n",
       "1397  Slit Optical Spectroscopy / Optical Spectrosco...   \n",
       "1822  Optical Spectroscopy / Optical Spectroscopy / ...   \n",
       "4886                                                -99   \n",
       "5505  Optical Fiber Spectroscopy / Optical Imaging /...   \n",
       "\n",
       "                         Name1      z1 z1_type           RA1          Dec1  \\\n",
       "21         J005113.94+002047.2  0.1124    spec   00:51:13.94   +00:20:47.2   \n",
       "330        J100602.14+071131.0  0.1218    spec   10:06:02.14   +07:11:31.0   \n",
       "1194       J220634.97+000327.6  0.0466    spec   22:06:34.97   +00:03:27.6   \n",
       "1359           SDSSJ0117+0020A  0.6130    spec    1:17:58.84    +0:20:21.5   \n",
       "1386           SDSSJ0747+4318A  0.5010    spec    7:47:59.02    +43:18:5.4   \n",
       "1390           SDSSJ0824+2357A  0.5360    spec    8:24:40.61    +23:57:9.9   \n",
       "1395           SDSSJ0845+0711A  0.5360    spec    8:45:41.53    +7:11:52.3   \n",
       "1397           SDSSJ0856+5111A  0.5430    spec    8:56:25.63   +51:11:37.4   \n",
       "1822      J155330.23+223010.22  0.6410    spec   15:53:30.23   22:30:10.22   \n",
       "4886  SDSS J171544.05+600835.7  0.1569    spec  17:15:44.033  +60:08:35.71   \n",
       "5505          SDSS J1120+6711A  1.4940     -99   11:20:12.11   +67:11:16.0   \n",
       "\n",
       "     Coordinate_waveband1 Coordinate_Source1 Equinox1 Brightness1  \\\n",
       "21                Optical               SDSS    J2000       -99.0   \n",
       "330               Optical               SDSS    J2000       -99.0   \n",
       "1194              Optical               SDSS    J2000       -99.0   \n",
       "1359              Optical               SDSS    J2000       17.67   \n",
       "1386              Optical               SDSS    J2000       19.24   \n",
       "1390              Optical               SDSS    J2000       18.51   \n",
       "1395              Optical               SDSS    J2000       18.47   \n",
       "1397              Optical               SDSS    J2000       18.52   \n",
       "1822              Optical               SDSS    J2000      -100.0   \n",
       "4886                X-ray            Chandra    J2000      -100.0   \n",
       "5505              Optical               SDSS    J2000      -100.0   \n",
       "\n",
       "         Brightness_band1 Brightness_type1                 Name2       z2  \\\n",
       "21                    -99              -99   J005114.12+002049.2   0.1126   \n",
       "330                   -99              -99   J100602.51+071131.8   0.1205   \n",
       "1194                  -99              -99   J220635.08+000323.2   0.0461   \n",
       "1359  SDSS g PSF ext-corr            asinh       SDSSJ0117+0021B   0.6110   \n",
       "1386  SDSS g PSF ext-corr            asinh       SDSSJ0747+4318B   0.5010   \n",
       "1390  SDSS g PSF ext-corr            asinh       SDSSJ0824+2357B   0.5350   \n",
       "1395  SDSS g PSF ext-corr            asinh       SDSSJ0845+0710B   0.5370   \n",
       "1397  SDSS g PSF ext-corr            asinh       SDSSJ0856+5111B   0.5430   \n",
       "1822                 -100             -100  J155330.55+223014.36   0.6420   \n",
       "4886               -100.0           -100.0   J171544.05+600835.7 -99.0000   \n",
       "5505                 -100             -100      SDSS J1120+6711B   1.4900   \n",
       "\n",
       "     z2_type          RA2         Dec2 Equinox2 Coordinate_waveband2  \\\n",
       "21      spec  00:51:14.12  +00:20:49.2    J2000              Optical   \n",
       "330     spec  10:06:02.51  +07:11:31.8    J2000              Optical   \n",
       "1194    spec  22:06:35.08  +00:03:23.2    J2000              Optical   \n",
       "1359    spec    1:17:58.0    +0:21:4.1    J2000              Optical   \n",
       "1386    spec   7:47:59.66  +43:18:11.5    J2000              Optical   \n",
       "1390    spec   8:24:39.83  +23:57:20.3    J2000              Optical   \n",
       "1395    spec   8:45:41.19   +7:10:50.3    J2000              Optical   \n",
       "1397    spec   8:56:26.71  +51:11:18.2    J2000              Optical   \n",
       "1822    spec  15:53:30.55  22:30:14.36    J2000              Optical   \n",
       "4886     -99          -99          -99      -99                  -99   \n",
       "5505    spec          -99          -99      -99                  -99   \n",
       "\n",
       "     Coordinate_Source2 Brightness2     Brightness_band2 Brightness_type2  \\\n",
       "21                 SDSS       -99.0                  -99              -99   \n",
       "330                SDSS       -99.0                  -99              -99   \n",
       "1194               SDSS       -99.0                  -99              -99   \n",
       "1359               SDSS       20.01  SDSS g PSF ext-corr            asinh   \n",
       "1386               SDSS       19.45  SDSS g PSF ext-corr            asinh   \n",
       "1390               SDSS       18.67  SDSS g PSF ext-corr            asinh   \n",
       "1395               SDSS       19.24  SDSS g PSF ext-corr            asinh   \n",
       "1397               SDSS       19.55  SDSS g PSF ext-corr            asinh   \n",
       "1822               SDSS      -100.0                 -100             -100   \n",
       "4886                -99      -100.0               -100.0           -100.0   \n",
       "5505                -99      -100.0                 -100             -100   \n",
       "\n",
       "              dV        Sep   Sep(kpc)      dV_rwp  \\\n",
       "21     64.000000   3.360020   6.867234  -53.752809   \n",
       "330   354.000000   5.564144  12.192223  346.697471   \n",
       "1194  124.000000   4.699202   4.298385  142.877614   \n",
       "1359  370.967599  44.500000 -99.000000  -99.000000   \n",
       "1386    0.000000   9.200000 -99.000000  -99.000000   \n",
       "1390  194.724825  14.900000 -99.000000  -99.000000   \n",
       "1395 -194.598092  62.200000 -99.000000  -99.000000   \n",
       "1397    0.000000  21.800000 -99.000000  -99.000000   \n",
       "1822 -182.150455   6.111000 -99.000000  -99.000000   \n",
       "4886  334.000000   0.680000 -99.000000  -99.000000   \n",
       "5505    0.000000   1.710000 -99.000000  -99.000000   \n",
       "\n",
       "                                               Paper(s)  \\\n",
       "21          Liu+2011b ; Fu+2015 ; Fu+2015b ; Gross+2019   \n",
       "330                  Liu+2011b ; Ge+2012 ; Rubinur+2019   \n",
       "1194        Liu+2011b ; Fu+2015 ; Fu+2015b ; Gross+2019   \n",
       "1359                         Hennawi+2006 ; Farina+2011   \n",
       "1386      Hennawi+2006 ; Farina+2011 ; Sandrinelli+2014   \n",
       "1390      Hennawi+2006 ; Farina+2011 ; Sandrinelli+2014   \n",
       "1395      Hennawi+2006 ; Farina+2011 ; Sandrinelli+2014   \n",
       "1397      Hennawi+2006 ; Farina+2011 ; Sandrinelli+2014   \n",
       "1822              Eftekharzadeh+2017 ; Sandrinelli+2014   \n",
       "4886  Comerford+2011 ; Liu+2010a ; Smith+2010 ; Smit...   \n",
       "5505                           Inada+2008 ; Pindor+2006   \n",
       "\n",
       "                                             BibCode(s)  \\\n",
       "21    2011ApJ...737..101L ; 2015ApJ...799...72F ; 20...   \n",
       "330   2011ApJ...737..101L ; 2012ApJS..201...31G ; 20...   \n",
       "1194  2011ApJ...737..101L ; 2015ApJ...799...72F ; 20...   \n",
       "1359          2006AJ....131....1H ; 2011MNRAS.415.3163F   \n",
       "1386  2006AJ....131....1H ; 2011MNRAS.415.3163F ; 20...   \n",
       "1390  2006AJ....131....1H ; 2011MNRAS.415.3163F ; 20...   \n",
       "1395  2006AJ....131....1H ; 2011MNRAS.415.3163F ; 20...   \n",
       "1397  2006AJ....131....1H ; 2011MNRAS.415.3163F ; 20...   \n",
       "1822          2017MNRAS.468...77E ; 2014MNRAS.444.1835S   \n",
       "4886  2011ApJ...737L..19C ; 2010ApJ...708..427L ; 20...   \n",
       "5505          2008AJ....135..496I ; 2006AJ....131...41P   \n",
       "\n",
       "                                                 DOI(s)  \\\n",
       "21    https://doi.org/10.1088/0004-637X/737/2/101 ; ...   \n",
       "330   https://doi.org/10.1088/0004-637X/737/2/101 ; ...   \n",
       "1194  https://doi.org/10.1088/0004-637X/737/2/101 ; ...   \n",
       "1359  https://doi.org/10.1086/498235 ; https://doi.o...   \n",
       "1386  https://doi.org/10.1086/498235 ; https://doi.o...   \n",
       "1390  https://doi.org/10.1086/498235 ; https://doi.o...   \n",
       "1395  https://doi.org/10.1086/498235 ; https://doi.o...   \n",
       "1397  https://doi.org/10.1086/498235 ; https://doi.o...   \n",
       "1822  https://doi.org/10.1093/mnras/stx412 ; https:/...   \n",
       "4886  https://doi.org/10.1088/2041-8205/737/1/L19 ; ...   \n",
       "5505  https://doi.org/10.1088/0004-6256/135/2/496 ; ...   \n",
       "\n",
       "                                                  Notes  Confidence Flag  \\\n",
       "21      Two compact steep-spectrum sources identified.               -99   \n",
       "330    . Dual AGN;dual radio sources coincident with...              -99   \n",
       "1194    Two compact steep-spectrum sources identified.               -99   \n",
       "1359  Coordinates not provided by Farina+. This pair...              -99   \n",
       "1386  Coordinates not provided by Farina+. This pair...              -99   \n",
       "1390  Coordinates not provided by Farina+. This pair...              -99   \n",
       "1395  Coordinates not provided by Farina+. This pair...              -99   \n",
       "1397  Coordinates not provided by Farina+. This pair...              -99   \n",
       "1822                                                -99              -99   \n",
       "4886  Individual redshifts not listed but velocity o...              -99   \n",
       "5505  velocoity difference of roughly 10 km per s. R...              -99   \n",
       "\n",
       "              Processed System Type             Legacy System Type  \\\n",
       "21    Dual AGN / Dual AGN Candidate  Dual AGN Candidate / Dual AGN   \n",
       "330   Dual AGN / Dual AGN Candidate  Dual AGN Candidate / Dual AGN   \n",
       "1194  Dual AGN / Dual AGN Candidate  Dual AGN Candidate / Dual AGN   \n",
       "1359  Dual AGN / Dual AGN Candidate       Binary Quasar / Dual AGN   \n",
       "1386  Dual AGN / Dual AGN Candidate       Binary Quasar / Dual AGN   \n",
       "1390  Dual AGN / Dual AGN Candidate       Binary Quasar / Dual AGN   \n",
       "1395  Dual AGN / Dual AGN Candidate       Binary Quasar / Dual AGN   \n",
       "1397  Dual AGN / Dual AGN Candidate       Binary Quasar / Dual AGN   \n",
       "1822  Dual AGN / Dual AGN Candidate  Dual AGN Candidate / Dual AGN   \n",
       "4886  Dual AGN / Dual AGN Candidate   Likely Single AGN / Dual AGN   \n",
       "5505  Dual AGN / Dual AGN Candidate  Dual AGN Candidate / Dual AGN   \n",
       "\n",
       "     Primary System Type Secondary System Type Tertiary System Type  \\\n",
       "21              Dual AGN                   -99                  -99   \n",
       "330             Dual AGN                   -99                  -99   \n",
       "1194            Dual AGN                   -99                  -99   \n",
       "1359            Dual AGN                   -99                  -99   \n",
       "1386            Dual AGN                   -99                  -99   \n",
       "1390            Dual AGN                   -99                  -99   \n",
       "1395            Dual AGN                   -99                  -99   \n",
       "1397            Dual AGN                   -99                  -99   \n",
       "1822            Dual AGN                   -99                  -99   \n",
       "4886            Dual AGN                   -99                  -99   \n",
       "5505            Dual AGN                   -99                  -99   \n",
       "\n",
       "      ST1 Confidence Flag  ST2 Confidence Flag  ST3 Confidence Flag  \\\n",
       "21                    -99                  -99                  -99   \n",
       "330                   -99                  -99                  -99   \n",
       "1194                  -99                  -99                  -99   \n",
       "1359                  -99                  -99                  -99   \n",
       "1386                  -99                  -99                  -99   \n",
       "1390                  -99                  -99                  -99   \n",
       "1395                  -99                  -99                  -99   \n",
       "1397                  -99                  -99                  -99   \n",
       "1822                  -99                  -99                  -99   \n",
       "4886                  -99                  -99                  -99   \n",
       "5505                  -99                  -99                  -99   \n",
       "\n",
       "     Confirmation Methood  \n",
       "21          Radio Imaging  \n",
       "330                   NaN  \n",
       "1194        Radio Imaging  \n",
       "1359                  NaN  \n",
       "1386                  NaN  \n",
       "1390                  NaN  \n",
       "1395                  NaN  \n",
       "1397                  NaN  \n",
       "1822                  NaN  \n",
       "4886                  NaN  \n",
       "5505                  NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MACcheck = MAC[MAC['Processed System Type']=='Dual AGN / Dual AGN Candidate']\n",
    "MACcheck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb31e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gandalfcheck = gandalf[(gandalf['Name1']==gandalf['Name2'])]#gandalf[(gandalf['RA2']=='-99')]\n",
    "#print(len(gandalfcheck))\n",
    "#gandalfcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccfa1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gandalfcheck = gandalf[(gandalf['Name1']==gandalf['Name2'])]#gandalf[(gandalf['RA2']=='-99')]\n",
    "#print(len(gandalfcheck))\n",
    "#gandalfcheck\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6010e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gimlicheck = gimli[(gimli['Name1']==gimli['Name2'])]#gandalf[(gandalf['RA2']=='-99')]\n",
    "#print(len(gimlicheck))\n",
    "#gimlicheck\n",
    "\n",
    "# did this check; no objects that have matching Name1 and Name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3dfeeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I'm corrected some issues with spec/phot not being listed under the redshifts:\n",
    "\n",
    "# For Inada+2008, these objects all have spec-zs for z1 and z2\n",
    "pairs = ['SDSSJ084710.40-001302.6','SDSSJ093207.15+072251.3','SDSSJ100859.55+035104.4','SDSSJ112012.11+671116.0',\\\n",
    "         'SDSSJ121244.33+091208.1','SDSSJ004757.25+144741.9','SDSSJ074013.44+292648.4','SDSSJ082046.24+035742.1',\\\n",
    "         'SDSSJ083557.50+341455.4','SDSSJ083649.55+484154.0','SDSSJ090955.54+580143.2','SDSSJ092024.21+030636.0',\\\n",
    "         'SDSSJ094309.66+103400.6','SDSSJ094510.75+472448.8','SDSSJ095711.08+640548.6','SDSSJ100034.17+540628.6',\\\n",
    "         'SDSSJ103519.36+075258.0','SDSSJ104213.61+061942.0','SDSSJ104658.02+471726.9','SDSSJ110932.13+531635.7',\\\n",
    "         'SDSSJ114546.22+032251.9','SDSSJ121002.47+495312.7','SDSSJ121636.02+543159.2','SDSSJ121647.22+495720.4',\\\n",
    "         'SDSSJ125422.00+610421.6','SDSSJ133945.37+000946.1','SDSSJ140016.87+542131.7','SDSSJ142359.48+545250.8',\\\n",
    "         'SDSSJ143433.45+613752.7','SDSSJ160547.59+511330.2','SDSSJ162902.59+372430.8','SDSSJ204113.41-060158.5',\\\n",
    "         'SDSSJ211102.60+105038.3','SDSSJ211230.33-063332.1','RXJ1629+3724A','SDSS J1120+6711A']\n",
    "\n",
    "# RXJ1629+3724A was listed by Mason+2000 and optical spectroscopy from Inada+20008 confirmed\n",
    "# SDSS J1120+6711A was listed by Pindor+ and confirmed with Inada+\n",
    "\n",
    "for index, row in MAC.iterrows():\n",
    "    if row['Name1'] in pairs:\n",
    "        MAC.at[index, 'z1_type'] = 'spec'\n",
    "        MAC.at[index, 'z2_type'] = 'spec'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84d773c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dual AGN Candidate' 'Dual AGN / Dual AGN Candidate'\n",
      " 'Dual AGN Candidate / Dual SMBH Candidate'\n",
      " 'Dual AGN Candidate / Recoil Candidate' 'Dual AGN'\n",
      " 'Binary AGN Candidate / Dual AGN Candidate'\n",
      " 'Binary SMBH Candidate / Dual AGN Candidate'\n",
      " 'Binary AGN Candidate / Binary SMBH Candidate / Dual AGN Candidate'\n",
      " 'Binary AGN Candidate / Dual AGN Candidate / Recoil Candidate'\n",
      " 'Binary AGN Candidate / Binary SMBH Candidate / Dual AGN Candidate / Recoil Candidate'\n",
      " 'Binary SMBH Candidate / Dual AGN'\n",
      " 'Binary SMBH Candidate / Dual AGN Candidate / Recoil Candidate']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "gandalf = MAC[MAC['Processed System Type'].str.contains('Dual AGN', na=False)]\n",
    "\n",
    "unique_combinations = gandalf['Processed System Type'].dropna().unique()\n",
    "\n",
    "print(unique_combinations)\n",
    "print(len(unique_combinations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f759a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aragorn = gandalf[(gandalf['RA1']==gandalf['RA2']) & gandalf['Dec1']==gandalf['Dec2']]\n",
    "#\n",
    "#boromir = gandalf[(gandalf['RA1']==gandalf['RA2'])]\n",
    "#\n",
    "#legolas = gandalf[gandalf['RA1']!=gandalf['RA2']]\n",
    "#\n",
    "#print(len(aragorn),len(legolas),len(boromir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "133d3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gandalf_grey = gandalf[((gandalf['z1']>0) & (gandalf['z2']<0))|((gandalf['z1']<0) & (gandalf['z2']>0))]\n",
    "gandalf_white = gandalf[(gandalf['z1']>0) & (gandalf['z2']>0)]\n",
    "saruman = gandalf[(gandalf['z1']<0) & (gandalf['z2']<0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded26b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now down below here we're going to start working on formatting the separations and ensuring we have \\\n",
    "# angular separations where needed/applicable and that we don't overwrite physical separations by accident\n",
    "\n",
    "gg = gandalf_white[(gandalf_white['Sep(kpc)']>0) & (gandalf_white['Sep']<0)]\n",
    "len(gg)\n",
    "#gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c6eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = gandalf_grey[(gandalf_grey['Sep(kpc)']>0) & (gandalf_grey['Sep']<0)]\n",
    "len(gg)\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = gandalf_grey[(gandalf_grey['Sep']<0)]\n",
    "len(gg)\n",
    "#gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a75e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gg = gimli[(gimli['Sep(kpc)']>0) & (gimli['Sep']<0)]\n",
    "len(gg)\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in MAC.iterrows():\n",
    "#    if row['z1']!=\n",
    "#MAC[~MAC[\"z2\"].apply(np.isreal)]  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc62a15b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_n/4v22wftn7354wlkmn_g7rtdr0000gn/T/ipykernel_40742/2127810117.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gandalf_white['dV_new'] = -99\n",
      "/var/folders/_n/4v22wftn7354wlkmn_g7rtdr0000gn/T/ipykernel_40742/2127810117.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gandalf_white.at[index, 'dV_new'] = (2.99e+5) * ((1 + row['z1'])**2 - (1 + row['z2'])**2) / ((1 + row['z1'])**2 + (1 + row['z2'])**2)\n",
      "/var/folders/_n/4v22wftn7354wlkmn_g7rtdr0000gn/T/ipykernel_40742/2127810117.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gandalf_white.at[index, 'Sep(kpc)_z1'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)\n",
      "/var/folders/_n/4v22wftn7354wlkmn_g7rtdr0000gn/T/ipykernel_40742/2127810117.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gandalf_white.at[index, 'Sep(kpc)_z2'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z2'])*(u.arcmin/u.kpc)*(1/60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 327\n"
     ]
    }
   ],
   "source": [
    "# running calculations for gandalf_white, where we have redshifts for both\n",
    "gandalf_white['dV_new'] = -99\n",
    "\n",
    "for index, row in gandalf_white.iterrows():\n",
    "    gandalf_white.at[index, 'dV_new'] = (2.99e+5) * ((1 + row['z1'])**2 - (1 + row['z2'])**2) / ((1 + row['z1'])**2 + (1 + row['z2'])**2)\n",
    "    gandalf_white.at[index, 'Sep(kpc)_z1'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)\n",
    "    gandalf_white.at[index, 'Sep(kpc)_z2'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z2'])*(u.arcmin/u.kpc)*(1/60)\n",
    "\n",
    "# now to cull the stuff we're not interested in...\n",
    "\n",
    "bad = gandalf_white[(np.abs(gandalf_white['dV_new'])>2000)] \n",
    "bad2 = gandalf_white[((gandalf_white['Sep(kpc)_z1']>110) & (gandalf_white['Sep(kpc)_z2']>110))]\n",
    "print(len(bad),len(bad2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "079733b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_n/4v22wftn7354wlkmn_g7rtdr0000gn/T/ipykernel_40742/582216016.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gandalf_grey['dV_new'] = -99\n",
      "/var/folders/_n/4v22wftn7354wlkmn_g7rtdr0000gn/T/ipykernel_40742/582216016.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gandalf_grey.at[index, 'Sep(kpc)_z1'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)\n",
      "/Users/ryan/anaconda3/lib/python3.9/site-packages/astropy/cosmology/flrw/lambdacdm.py:404: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return 2 * np.sqrt(x) * hyp2f1(1.0 / 6, 1.0 / 2, 7.0 / 6, -(x**3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# running calculations for gandalf_grey, where we have redshifts for both\n",
    "gandalf_grey['dV_new'] = -99\n",
    "\n",
    "for index, row in gandalf_grey.iterrows():\n",
    "    #gandalf_grey.at[index, 'dV_new'] = (2.99e+5) * ((1 + row['z1'])**2 - (1 + row['z2'])**2) / ((1 + row['z1'])**2 + (1 + row['z2'])**2)\n",
    "    gandalf_grey.at[index, 'Sep(kpc)_z1'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)\n",
    "\n",
    "# now to cull the stuff we're not interested in...\n",
    "\n",
    "bad3 = gandalf_grey[(gandalf_grey['Sep(kpc)_z1']>110)]\n",
    "print(len(bad3))\n",
    "\n",
    "#<0.4 is a double peaked object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6285b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5683 3956 1727\n"
     ]
    }
   ],
   "source": [
    "# combining these tables back together to format the confidence flags without having the contaminants...\n",
    "gandalf_white = gandalf_white[~gandalf_white['Name1'].isin(bad['Name1'])]\n",
    "gandalf_white = gandalf_white[~gandalf_white['Name1'].isin(bad2['Name1'])]\n",
    "\n",
    "gandalf_grey = gandalf_grey[~gandalf_grey['Name1'].isin(bad3['Name1'])]\n",
    "\n",
    "gandalf = pd.concat([gandalf_white,gandalf_grey,saruman])\n",
    "\n",
    "# and we also need to remove the bad objects from the full MAC table since we use the intersectino of the MAC \\\n",
    "# table with the gandalf table to generate the gimli table\n",
    "\n",
    "MAC = MAC[~MAC['Name1'].isin(bad['Name1'])]\n",
    "MAC = MAC[~MAC['Name1'].isin(bad2['Name1'])]\n",
    "MAC = MAC[~MAC['Name1'].isin(bad3['Name1'])]\n",
    "\n",
    "\n",
    "# here we're going to run the same calculations but run a few if else statements to make sure we're not \\\n",
    "# overwriting things unnecessarily\n",
    "MAC['dV_new'] = -99\n",
    "#MAC.at[index, 'Sep(kpc)_z1'] = -99\n",
    "#MAC.at[index, 'Sep(kpc)_z2'] = -99\n",
    "\n",
    "#gandalf_grey = gandalf[((gandalf['z1']>0) & (gandalf['z2']<0))|((gandalf['z1']<0) & (gandalf['z2']>0))]\n",
    "#gandalf_white = gandalf[(gandalf['z1']>0) & (gandalf['z2']>0)]\n",
    "#saruman = gandalf[(gandalf['z1']<0) & (gandalf['z2']<0)]\n",
    "\n",
    "for index, row in gandalf_white.iterrows():\n",
    "    if ((row['z1']<0) | (row['z2']<0)) & (row['dV']!=-99):\n",
    "        MAC.at[index, 'dV_new'] = row['dV']\n",
    "    elif (row['z1']>0) and (row['z2']>0):\n",
    "        MAC.at[index, 'dV_new'] = (2.99e+5) * ((1 + row['z1'])**2 - (1 + row['z2'])**2) / ((1 + row['z1'])**2 + (1 + row['z2'])**2)\n",
    "        #MAC.at[index, 'Sep(kpc)_z1'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)\n",
    "        #MAC.at[index, 'Sep(kpc)_z2'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z2'])*(u.arcmin/u.kpc)*(1/60)\n",
    "        MAC.at[index, 'Sep(kpc)'] = max(row['Sep']*cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60), row['Sep']*cosmo.kpc_proper_per_arcmin(row['z2'])*(u.arcmin/u.kpc)*(1/60))\n",
    "    elif (row['z1']>0) and (row['z2']<0):\n",
    "        MAC.at[index, 'Sep(kpc)'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)\n",
    "    elif (row['z1']<0) and (row['z2']>0):\n",
    "        MAC.at[index, 'Sep(kpc)'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z2'])*(u.arcmin/u.kpc)*(1/60)\n",
    "\n",
    "\n",
    "#gandalf_grey = gandalf[(gandalf['z1']>0) & (gandalf['z2']<0)]\n",
    "#gandalf_white = gandalf[(gandalf['z1']>0) & (gandalf['z2']>0)]\n",
    "#saruman = gandalf[(gandalf['z1']<0) & (gandalf['z2']<0)]\n",
    "\n",
    "\n",
    "# and generating the gimli table here\n",
    "gimli = MAC[~MAC['Name1'].isin(gandalf['Name1'])]\n",
    "print(len(MAC),len(gandalf),len(gimli))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2a6e0110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>System Type</th>\n",
       "      <th>Literature Name</th>\n",
       "      <th>Selection Method</th>\n",
       "      <th>Confirmation Method</th>\n",
       "      <th>Name1</th>\n",
       "      <th>z1</th>\n",
       "      <th>z1_type</th>\n",
       "      <th>RA1</th>\n",
       "      <th>Dec1</th>\n",
       "      <th>Coordinate_waveband1</th>\n",
       "      <th>Coordinate_Source1</th>\n",
       "      <th>Equinox1</th>\n",
       "      <th>Brightness1</th>\n",
       "      <th>Brightness_band1</th>\n",
       "      <th>Brightness_type1</th>\n",
       "      <th>Name2</th>\n",
       "      <th>z2</th>\n",
       "      <th>z2_type</th>\n",
       "      <th>RA2</th>\n",
       "      <th>Dec2</th>\n",
       "      <th>Equinox2</th>\n",
       "      <th>Coordinate_waveband2</th>\n",
       "      <th>Coordinate_Source2</th>\n",
       "      <th>Brightness2</th>\n",
       "      <th>Brightness_band2</th>\n",
       "      <th>Brightness_type2</th>\n",
       "      <th>dV</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Sep(kpc)</th>\n",
       "      <th>dV_rwp</th>\n",
       "      <th>Paper(s)</th>\n",
       "      <th>BibCode(s)</th>\n",
       "      <th>DOI(s)</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Confidence Flag</th>\n",
       "      <th>Processed System Type</th>\n",
       "      <th>Legacy System Type</th>\n",
       "      <th>Primary System Type</th>\n",
       "      <th>Secondary System Type</th>\n",
       "      <th>Tertiary System Type</th>\n",
       "      <th>ST1 Confidence Flag</th>\n",
       "      <th>ST2 Confidence Flag</th>\n",
       "      <th>ST3 Confidence Flag</th>\n",
       "      <th>Confirmation Methood</th>\n",
       "      <th>dV_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, System Type, Literature Name, Selection Method, Confirmation Method, Name1, z1, z1_type, RA1, Dec1, Coordinate_waveband1, Coordinate_Source1, Equinox1, Brightness1, Brightness_band1, Brightness_type1, Name2, z2, z2_type, RA2, Dec2, Equinox2, Coordinate_waveband2, Coordinate_Source2, Brightness2, Brightness_band2, Brightness_type2, dV, Sep, Sep(kpc), dV_rwp, Paper(s), BibCode(s), DOI(s), Notes, Confidence Flag, Processed System Type, Legacy System Type, Primary System Type, Secondary System Type, Tertiary System Type, ST1 Confidence Flag, ST2 Confidence Flag, ST3 Confidence Flag, Confirmation Methood, dV_new]\n",
       "Index: []"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAC[MAC['Sep']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9396cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC[((MAC['z1']<0) & (MAC['z2']<0)) & (MAC['dV']!=-99)]\n",
    "MACcheck = MAC[MAC['Confidence Flag']==1]\n",
    "len(MACcheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247dbe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACcheck[MACcheck['dV']>2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gandalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75edcfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gandalf['Confidence Flag'] = -99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "158365de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now adding in the subjective flag for all of the objects in the gimli table (which are by and large binary \\\n",
    "# and recoil candidates, with some dual AGN and SMBH candidates added in)\n",
    "\n",
    "# we're going to use this list of papers to apply flags\n",
    "papers = ['Hwang+2020','Orosz+2013','Lyu+2016','Yuan+2016','Barrows+2013','Ge+2012','Lyu+2016 ; Yuan+2016',\\\n",
    "         'Wang+2009 ; Liu+2010a ; Ge+2012','Smith+2010 ; Song+2020','Shi+2014','Wang+2009 ; Ge+2012 ; Shi+2014',\\\n",
    "          'Liu+2010a ; Ge+2012','Liu+2010a ; Ge+2012','Liu+2010a','Kim+2020','Spiniello+2018','Rusu+2019',\\\n",
    "          'Wang+2009 ; Ge+2012','Wang+2009','Liu+2010a ; Yuan+2016','Liu+2010a ; Ge+2012 ; Yuan+2016',\\\n",
    "          'Ge+2012 ; Orosz+2013','Wang+2009 ; Shi+2014','Ge+2012 ; Comerford+2013','Smith+2010 ; Smith+2012 ; Song+2020',\\\n",
    "          'Smith+2010 ; Smith+2012 ; Ge+2012 ; Song+2020','Smith+2010 ; Smith+2012 ; Ge+2012 ; Song+2020 ',\\\n",
    "          'Smith+2010 ; Ge+2012 ; Song+2020 ','Yuan+2016 ; Yang+2019 ; Joshi+2019','Kim+2020 ; Liu+2014',\\\n",
    "          'Kim+2020 ; Kim+2016','Spiniello+2018 ; Rusu+2019',\\\n",
    "          'Yuan+2016 ; Cheung+2007 ; Roberts+2018 ; Saripalli+2018 ; Saripalli+2018',]\n",
    "\n",
    "for i in papers:\n",
    "    for index, row in gandalf.iterrows():\n",
    "        if row['Paper(s)'] == str(i):\n",
    "            gandalf.at[index, 'Confidence Flag'] = 0\n",
    "            \n",
    "for index, row in gandalf.iterrows():       \n",
    "    if row['Paper(s)'] == 'Lemon+2018':\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5  \n",
    "    elif row['Paper(s)'] == 'Lemon+2019':\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5                                           \n",
    "    elif row['Paper(s)'] == 'Lemon+2020':\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5   \n",
    "    elif row['Paper(s)'] == 'Koss+2012':\n",
    "        gandalf.at[index, 'Confidence Flag'] = +1  \n",
    "    elif 'Smith+2010 ; Song+2020' in row['Paper(s)']:\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0 \n",
    "    elif row['Paper(s)'] == 'Liu+2011b ; Ge+2012':\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif row['Paper(s)']=='Komossa+2008 ; Shields+2009 ; Bogdanović+2009 ; Dotti+2009 ; Heckman+2009 ; Decarli+2009 ; Decarli+2010 ; Tsalmantza+2011 ; Decarli+2013 ; Lusso+2014 ; Liu+2014 ; Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020': \n",
    "        gandalf.at[index, 'Confidence Flag'] = 0 # updated on 24 jan 2024\n",
    "    elif row['Paper(s)'] == 'Fu+2018':\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif row['Paper(s)']=='Fu+2015':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5 # come back and fix this so that we differentiate between\\\n",
    "        # the grade A and B targets!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6d835b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing as above, but now I'm focusing on the gandalf_grey2 table \n",
    "ds = ['NGC 5278','Mrk 273 N','3C 321','WISE 2215-3056','J162345.20+080851.1','J114642.47+511029.6 / J1146+5110SW',\\\n",
    "     'J112659.54+294442.8 / J1126+2944NW','J110851.04+065901.4 / J1108+0659NW','J102325.57+324348.4','J115822.58+323102.2',\\\n",
    "     ]\n",
    "# decide if you really believe J110851.04+065901.4\n",
    "# fu classify as binary: J115106.69+471157.7 but they also note that confirmation is needed\n",
    "\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in ds:\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1\n",
    "\n",
    "# same thing here, except that we're going to go with objects that deserve +0.5\n",
    "\n",
    "dcs = ['III Zw 035 NE','J1221+1137 NE','J1301+2918 NE','J1536+0441 VLA-A',\\\n",
    "      'COSMOS J100043.15+020637.2 / CID-42','J132323.33-015941.9','VV 114 E','CXOJ1426+35','IRAS 12072-0444 N',\\\n",
    "      '3C 459 N1','CLASS B0827+525 A','HE0450-2958','WISE 1051-1142','PKS 1155+251 C','J115714.97+081632.0',\\\n",
    "      'J124859.72-025730.7','J125327.50+254747.4','J130128.77-005804.3','J132318.81+030807.1',\\\n",
    "      'J135024.66+240251.4','J144541.31+334107.9','J154107.81+203608.8','J155645.97+241828.5','J172049.25+310646.4',\\\n",
    "      'J132947.52+431357.36','J020011.52-093126.1','J072554.42+374436.9','J080337.32+392633.1',\\\n",
    "       'J081507.41+430427.0','J084049.47+272704.8','J090246.93+012028.2','J090615.92+121845.6',\\\n",
    "       'J091201.68+532036.6','J092455.24+051052.0 / J0924+0510E','J094236.68+192541.1','J105104.54+625159.3',\\\n",
    "       'J124813.82+362423.6','J113126.08-020459.2 / J1131-0204W','J151735.17+214532.5','J160524+152233',\\\n",
    "      'J115523.74+150756.9','J123915.40+531414.6 / J1239+5314NE','J132231.86+263159.1 / J1322+2631SW','J133226.34+060627.4 / J1332+0606SW',\\\n",
    "      'J161027.41+130806.8','J080418.23+305157.2','J123420.14+475155.9','J124037.84+353437.3',\\\n",
    "      'J115106.69+471157.7','J135646.11+102609.1 / J1356+1026NE']\n",
    "\n",
    "# J115714.97+081632.0is a dual candidate bcause of the companion at ~30 kpc that cmerford found, NOT \\\n",
    "# because of the double peaks\n",
    "# same for J124859.72-025730.7 except there are also companions within 3'' but Fu considered this to double peaked\\\n",
    "# object to be due to extended narrow line region\n",
    "# same for J130128.77-005804.3  except fu considered it unresolved NLR\n",
    "# same for J132318.81+030807.1\n",
    "# same for J154107.81+203608.8\n",
    "# comerford also flags J161027.41+130806.8, when Fu and others argued that the companions within 3'' has no detected emission\n",
    "\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in dcs:\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "# IRAS 12072-0444 N from Imanishi+ is listed as 0.5 \n",
    "# HE0450-2958 should be a slam dunk near-IR spectroscopic proposal\n",
    "\n",
    "# and now for objects that will get a 0 flag\n",
    "\n",
    "unclear = ['4C 40.24 (0945+408) / J094855.34+403944.6','J0841+0101 E','J0841+0101 E ','NGC 5515 (J141238.14+391836.5)',\\\n",
    "          'Mrk 1469 (J121607.08+504930.0)','MGB2016+112 Core 1','J1159+5320 SE','SDSS J133039.82-001035.7',\\\n",
    "          'J121855.80+020002.1','J162011.28+172427.5','J132450.59+175815.0','J134909.63+040448.3',\\\n",
    "           'J141316.25+211937.5','J142031.48+400815.9','J150102.58+394200.2','J164413.90+252828.4 ',\\\n",
    "           'J233604.03+000447.1','J091405.28+171554.36','J011341.11+010608.50', 'J083127.50+321926.9 / B2 0828+32',\\\n",
    "          'J095840.09+285239.2','J164413.90+252828.4','SDSS J1316+1753','J135251.22+654113.2','J140816.02+015528.3',\\\n",
    "          'J012613.31+142013.4','J080740+390015 / Mrk 622','J113721.36+612001.2','J124358.36-005845.4',\\\n",
    "          'J145050.60+083832.6','J085431.28-003650.6','PKS 0235+023 / J023832.67+023349.1','J101927.56+013422.5',\\\n",
    "          'J100921.26+013334.6','J094205.83+125433.7','J132848.46+275227.8','J145050.60+083832.6',\\\n",
    "           'J225252.94+002928.4','J225510.12-081234.4','J002729.24+211152.08','SDSSJ095324.39+570319.5',\\\n",
    "          'SDSSJ085122.37+472249.0','3C 293']\n",
    "#PKS 0235+023 / J023832.67+023349.1 for the binary hypothesis it is -0.5 but for dual it is 0\n",
    "# 'J085431.28-003650.6' had been put down in -0.5 for some reason\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in unclear:\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "# the barrows 2013/ciamarella target isn't convincing enough to give it a 0.5\n",
    "        \n",
    "# and here for objects that should be flagged as -0.5\n",
    "less = ['KISSR 1494','J160027.78+083743.0','J094124+394441 / 3C223.1','J121911.16+042905.9',\\\n",
    "       'J130724.08+460400.9','J140845.73+353218.5','J144012.74+615633.0','J151656.59+183021.5',\\\n",
    "       'J160631.37+273643.0','J161847.93+215925.4','J235256.62+001155.2','J140914.35+565625.7','J000656+154847',\\\n",
    "       'J073509+403624','J073849.75+315611.9','J074729+344018','J080315.67+483603.1','J080841.22+481351.9',\\\n",
    "       'J084130.18+393119.2','J085512+642345','J094032.25+311328.6','J105052.46+083934.8','J110215+290725',\\\n",
    "       'J152431.41+323750.6','J210449.13-000919.1','J231051.95-090011.9','J231051.95-090011.9',\\\n",
    "       'J233313.17+004911.8']\n",
    "# J110215+290725 has a z-shaped xray source which means to me that this is prob an ism-jet iteraction\n",
    "# J094032.25+311328.6 has spatially coincident emission lines within 0.15'', so they should not be originating from a companion\n",
    "# J085512+642345 was looked at by comerford+ but also claimed to be a binary by severgnini and rejected by liu\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in less:\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "# J094124+394441 / 3C223.1 being an x-shaped radio source with double peaks and no companion makes me think \n",
    "# it's def just jet-ism interactions\n",
    "\n",
    "# and here for objects that should be flagged as -1\n",
    "morebad = ['HE 0512-3329A','J151709.21+335324.7','SDSS J171544.05+600835.7','J112939.77+605742.5','J120320+131931',\\\n",
    "          'SDSS J1048+0055']\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in morebad:\n",
    "        gandalf.at[index, 'Confidence Flag'] = -1\n",
    "# J151709.21+335324.7 is the jet-ism object follow-up by Rosario\n",
    "\n",
    "        \n",
    "# figure out the problem with J095840.09+285239.2, this was apparently not in rubinur2019?\n",
    "        \n",
    "# and down below here, we are focusing on the double-peaked objects that have gotten a lot of attention\n",
    "# we may need to come back here and fix this\n",
    "#Can wholesale throw these:\n",
    "#    Liu+2010a ; Yuan+2016 ; Comerford+2018 0 \n",
    "#    Ge+2012 ; de Ruiter+1986 ; Merritt+2002 ; Cheung+2007 ; Merritt+2002 ; Lal+2007 0 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17775cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Notes']=='No companion within 3 arcseconds. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        #print('True')\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' Fu+2011 found no companions within 3 arcseconds, No companion within 3 arcseconds. No companion within 3 arcseconds.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Comerford+2018 studied the kinematics that give rise to the double-peaks.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' Fu+2011 found no companions within 3 arcseconds, Fu+2011 argue the origin of the double-peaked lines is Extended narrow-line region No companion within 3 arcseconds. No companion within 3 arcseconds. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Tingay+ find no evidence of double radio cores in VLBA imaging. Fu+2011 found no companions within 3 arcseconds, No companion within 3 arcseconds. No companion within 3 arcseconds.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Tingay+ find no evidence of double radio cores in VLBA imaging. No companion within 3 arcseconds. No companion within 3 arcseconds.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Single structure observed in Keck AO near-IR imaging. Fu+2011 found no companions within 3 arcseconds, Fu+2011 argue the origin of the double-peaked lines is Unresolved narrow-line region No companion within 3 arcseconds. No companion within 3 arcseconds. Kim+2020 reselected this based on double-peaked lines and compared to spectra from known dual AGNs. Also looked for companions. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Tingay+ find no evidence of double radio cores in VLBA imaging.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' No companion within 3 arcseconds. Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed. No companion within 3 arcseconds.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' No companion within 3 arcseconds. No companion within 3 arcseconds. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' No companion within 3 arcseconds. Comerford+2018 studied the kinematics that give rise to the double-peaks. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Single structure observed in Keck AO near-IR imaging. Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed. No companion within 3 arcseconds. Comerford+2018 studied the kinematics that give rise to the double-peaks. Kim+2020 reselected this based on double-peaked lines and compared to spectra from known dual AGNs. Also looked for companions. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' No companion within 3 arcseconds. No companion within 3 arcseconds.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' No companion within 3 arcseconds. No companion within 3 arcseconds. Comerford+2018 studied the kinematics that give rise to the double-peaks. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed.':\n",
    "        #--> maybe a +0.5 for this, but if no companions it swings to -0.5?\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif row['Notes']==' Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed. Comerford+2018 studied the kinematics that give rise to the double-peaks. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        #--> again maybe a +0.5 for this, but if no companions it swings to -0.5?\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif row['Notes']==' Single structure observed in Keck AO near-IR imaging. No companion within 3 arcseconds. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' No companion within 3 arcseconds. Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed. No companion within 3 arcseconds. Comerford+2018 studied the kinematics that give rise to the double-peaks. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed. No companion within 3 arcseconds.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' No companion within 3 arcseconds. No companion within 3 arcseconds. Comerford+2018 studied the kinematics that give rise to the double-peaks.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Shi+ also selected this in LAMOST. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' Comerford+2018 studied the kinematics that give rise to the double-peaks. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed. Comerford+2012 consider this a strong dual AGN candidate. Double optical emission line peaks observed oriented along the plane of the galaxy. Gabanyi+ do not detect a source in this system but Muller-Sanchez+ do detect two components. No companion within 3 arcseconds. Comerford+2018 studied the kinematics that give rise to the double-peaks.':\n",
    "        # this was a bona fide dual confirmed by muller sanchez\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1\n",
    "    elif row['Notes']==' Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed.Muller-Sanchez+2015 find that the origin of the double-peaked emission is still ambiguous. Comerford+2018 studied the kinematics that give rise to the double-peaks. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0 # muller sanchez claim this is still ambiguous\n",
    "    elif row['Notes']==' No companion within 3 arcseconds. No companion within 3 arcseconds. Kim+2020 reselected this based on double-peaked lines and compared to spectra from known dual AGNs. Also looked for companions. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Detected in follow-up 8.4 GHz VLBA imaging but unambiguous sub-kpc dual AGNs are not identified.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' Fu+2011 found no companions within 3 arcseconds, No companion within 3 arcseconds. No companion within 3 arcseconds. Comerford+2018 studied the kinematics that give rise to the double-peaks. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' No companion within 3 arcseconds. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Detected in follow-up 8.4 GHz VLBA imaging but unambiguous sub-kpc dual AGNs are not identified. Comerford+2018 studied the kinematics that give rise to the double-peaks.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' Comerford+2018 studied the kinematics that give rise to the double-peaks. Comerford+2018 found a companion within 30 kpc that also shows optical evidence of being an AGN. This is therefore a stronger case for dual AGN but not due at all to the double-peaked emission lines. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif row['Notes']==' Lyu+2016 also selected this object with BOSS. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' Kim+2020 reselected this based on double-peaked lines and compared to spectra from known dual AGNs. Also looked for companions.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed. Comerford+2018 studied the kinematics that give rise to the double-peaks.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif row['Notes']==' Kim+2020 reselected this based on double-peaked lines and compared to spectra from known dual AGNs. Also looked for companions. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' Fu+2011 found no companions within 3 arcseconds, No companion within 3 arcseconds. No companion within 3 arcseconds. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed. No companion within 3 arcseconds. Comerford+2018 studied the kinematics that give rise to the double-peaks. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Fu+2011 found no companions within 3 arcseconds, No companion within 3 arcseconds. Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed. Comerford+2012 consider this a strong dual AGN candidate. Double optical emission line peaks observed oriented along the plane of the galaxy. No companion within 3 arcseconds.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Fu+2011 argue the origin of the double-peaked lines is Extended narrow-line region Comerford+2018 studied the kinematics that give rise to the double-peaks.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Fu+2011 found no companions within 3 arcseconds, Fu+2011 argue the origin of the double-peaked lines is Unresolved narrow-line region No companion within 3 arcseconds. No companion within 3 arcseconds. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Fu+2011 companions within 3 arcseconds, Fu+2011 argue the origin of the double-peaked lines is Unresolved narrow-line region Companion(s) within 3 arcseconds. Companion within 3 arcseconds.Emssion line peaks show separations incompatible with the second peak originating in the companion. No continuum observed in companion or at location of second peak.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Comerford+ examined long slit spectra of this target. Two spatially distinct emission peaks observed. Comerford+2012 consider this a strong dual AGN candidate. Double optical emission line peaks observed oriented along the plane of the galaxy. No companion within 3 arcseconds.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Notes']==' Detected in follow-up 8.4 GHz VLBA imaging but unambiguous sub-kpc dual AGNs are not identified.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Notes']==' Companion within 3 arcseconds. Song+2020 examined a subsample of the double-peaked objects in Smith+2010 but did not include a table specifying the objects. We include a reference to all of them for now. Song+ disfavor a binary hypothesis.':\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b83c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we're going to assemble a list of objects that we know should be flagged as +1, and we'll then feed \\\n",
    "# that list to our for loop so we can rapidly get through objects\n",
    "\n",
    "ds = ['Mrk 266NE','FIRST J164311.3+315618A','SDSS J125455.09+084653.9 (SDSS J1254+0846 A)',\\\n",
    "      '1635+267A / J163700.93+263609.86','PKS 1614+051 QSO','0023+171 AB_opt','1343.4+2640A','Q1009-0252A',\\\n",
    "      'MGC 2214+3550A','CTQ 839A','RX J0921+4529A','SDSS J2336-0107A','NGC 6240 North','NGC 3690 E','ESO509-IG066E',\\\n",
    "      'Mrk 739W','4C60.07 Radio Core','J0038+4128N','X1 (Eastern)','M51a','UGC 6081',\\\n",
    "     'ESO 432-IG006 SW / WISEA J084427.19-314150.8','GQ 1114+1549A','SDSS J113502.03-022110.9 (QSO 1)',\\\n",
    "     'ELAN0101+0201 Q1','SDSS J1502+1115p','PKS 1145-071A','PHL 1222A (Q0151+048A)','Q2138-431A','2153-2056A',\\\n",
    "     'LBQS 0015+0239A','PKS 0347+05','J081312.63+541649.8','005113.93+002047.0','220634.96+000327.6',\\\n",
    "     '223222.43+001225.8','230010.19-000531.8','Mrk 463E','J0321-455N','Was 49a',' Was 49a',\\\n",
    "      'J113725.69+141101.3','J113725.69+141101.3','Q0142-BX195 A','J155330.23+223010.22','RXJ1629+3724A',\\\n",
    "      'SDSSJ084710.40-001302.6','SDSS J1120+6711A','J005113.94+002047.2','J220634.97+000327.6',\\\n",
    "     'J090714.45+520343.4','J154403.45+044607.5','J100602.14+071131.0','WISE 2215-3056A','IC 5338']\n",
    "\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in ds:\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1\n",
    "\n",
    "# same thing here, except that we're going to go with objects that deserve +0.5\n",
    "\n",
    "dcs = ['ESO 286-G17','NGC 5252','J1036+0221','J1425+3231 NW','AM1211-465NE','J1045+3519 W','J1045+3519 W ',\\\n",
    "       'SDSS J084810.10+351534.4','J0859+1310 NE','EGSD2 J142033.66+525917.5','UM 425A','Arp 220A','QJ0240-343A',\\\n",
    "       'NGC 7592 E','IRAS 14348-1447 NE','EGSD2 J141550.8+520929','NGC7674 Eastern C1','PSO J308-21 QSO',\\\n",
    "       'PKS 0537-441','RBS797 C1','3C 294 W','J1629+4037NW','J1107+6506N','J135225.64+142919.3 / J1352+1429W',\\\n",
    "       'J080529.88+241004.4','LQAC_052-000_030','LQAC_122+031_018','J2032-2358','LQAC_238+004_003',\\\n",
    "       'LQAC_253+026_011','J160933.21+283058.1','J031722.06+004801.8','J080523.29+281815.8','J141116.45+194436.2',\\\n",
    "       'J141447.15-000013.3','J085312.36+162619.5','142314.18+505537.2 / SBS 1421+511 QSO',\\\n",
    "      'J121345.95+024839.0 / IRAS 12112+0305 SW','J133031.75-003611.9','J105842.44+314457.6','J091543.02+300914.0',\\\n",
    "      'J000249.07+004504.8','J161708.89+222623.9','J1114+4036 A','J09527.62+255257.2 / J0952+2552NE',\\\n",
    "       'J011812.03-010442.53','022958+032031','J135429.06+132757.3','J0122+0100 NW']\n",
    "# check that the redshifts for UM 425A are correct\n",
    "# double check with others if they think Arp 220 is a dual based on Imanishi's work\n",
    "# lemon's table lists QJ0240-343A as a binary. double check this.\n",
    "# NGC7674 Eastern C1 is getting +0.5 because I think follow-up confirmation is needed \n",
    "# Teng+2012 objects getting a +0.5 because they're are larger seps and still optically selected (despite the \\\n",
    "# somewhat ambiguous X-ray results)\n",
    "# Gattano's targets are getting 0.5 flag; eventually we'll track down if their redshifts are spec or not\n",
    "\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in dcs:\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "\n",
    "# and now for objects that will get a 0 flag\n",
    "unclear = ['IRAS 18329+5950E','J0905+3747 NE','J2356-1016 NW','Q1208+1011A','J144804.17+182537.9',\\\n",
    "           'J083713.49+150037.2','J075223.35+273643.1']\n",
    "# Lemon's catalog lists Q1208+1011A as a lens. We need to follow-up on this\n",
    "\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in unclear:\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "        \n",
    "# and here for objects that should be flagged as -0.5\n",
    "less = ['FBQ 1633+3134A','J085837.53+182221.6','J094741.58+633941.4','J111519.23+542310.9','J164658.38+241132.7']\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in less:\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "# morgan+2001 originally I was going to flag as 0 or 0.5, but given the intevening metal system, and Lemon's \\\n",
    "# table flagging it as a lens, I'll flag it as -0.5\n",
    "\n",
    "# and here for objects that should be flagged as -1\n",
    "morebad = ['SDSSJ132059.17+164402.59','SDSS J0818+0601A','LQAC_052-000_030','013412.78-010729.6',\\\n",
    "           '222051.44+005815.0','J011333.06+002947.9','J120401.97+012641.6','J000911.58-003654.7',\\\n",
    "           'J073117.55+452803.2','J073656.47+475946.8','J080218.65+304622.7','J084624.51+425842.8',\\\n",
    "           'J085841.76+104122.1','J091646.03+283526.7','J093024.84+343057.3','J115249.33+190300.3',\\\n",
    "           'J111201+275053','J155619.30+094855.6','J225420.99-005134.1','J230442.82-093345.3',\\\n",
    "           'J163056.75+164957.2','J160436.21+500958.1','J155205.93+043317.5','J134114.87+221957.8',\\\n",
    "           'J114610.04-022619.2','J103850.13+025555.1','J100654.20+464717.2','J095833.20-005118.6',\\\n",
    "           'J085416.76+502632.0','J085121.94+132702.2','J040001.59-065254.1','J015605.14-000721.7',\\\n",
    "           'J014209-005049','J013555.82+143529.7','J013546.93-005858.5','J011659.59-102539.1'] \n",
    "# two objects here are the two objects from Fu+2015 that are FR II sources\n",
    "# see also notes below about the double-peaked objects getting flagged here\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in morebad:\n",
    "        gandalf.at[index, 'Confidence Flag'] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "133e71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding more confidence flags:\n",
    "\n",
    "# cleaning this up ad of 24 January 2024\n",
    "papers = ['Eftekharzadeh+2017','Inada+2008','Inada+2010','Inada+2012','More+2016','Ge+2012 ; Yuan+2016',\\\n",
    "          'Inada+2012 ; Yang+2019','Inada+2010 ; Comerford+2014','Comerford+2013',\\\n",
    "          'Inada+2008 ; Graham+2015 ; Guo+2020','Inada+2008 ; Spiniello+2018',\\\n",
    "          'Inada+2012 ; Hwang+2020 ; Hwang+2020','Schecter+2017 ; Agnello+2018','Agnello+2018',\\\n",
    "          'Shi+2014 ; Lyu+2016']\n",
    "\n",
    "for i in papers:\n",
    "    for index, row in gandalf.iterrows():\n",
    "        if (row['Paper(s)'] == str(i)) and ((row['z1']>0)) and ((row['z2']<0)):\n",
    "            gandalf.at[index, 'Confidence Flag'] = 0\n",
    "        elif (row['Paper(s)'] == str(i)) and ((row['z1']<0)) and ((row['z2']<0)):\n",
    "            gandalf.at[index, 'Confidence Flag'] = 0\n",
    "\n",
    "\n",
    "for index, row in gandalf.iterrows():\n",
    "    if ('Hennawi+2006' in row['Paper(s)']) and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')) and (np.abs(row['dV_new'])<=600):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1\n",
    "    elif ('Hennawi+2006' in row['Paper(s)']) and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')) and (np.abs(row['dV_new'])>600):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif ('Hennawi+2010' in row['Paper(s)']) and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')) and (np.abs(row['dV_new'])<=600):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1\n",
    "    elif ('Hennawi+2010' in row['Paper(s)']) and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')) and (np.abs(row['dV_new'])>600):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif ('Findlay+2018' in row['Paper(s)']) and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')) and (np.abs(row['dV_new'])<=600):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1        \n",
    "    elif ('Findlay+2018' in row['Paper(s)']) and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')) and (np.abs(row['dV_new'])>600):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif row['Paper(s)']=='Herzog+2015':\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    elif (row['Paper(s)']=='Fischer+2011') and ((row['z1']>0)) and ((row['z2']<0)):\n",
    "        gandalf.at[index, 'Confidence Flag'] = -1\n",
    "    elif (row['Paper(s)']=='Assef+2016') and ((row['z1']>0)) and ((row['z2']<0)):\n",
    "        gandalf.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif (row['Paper(s)']=='Goulding+2019') and ((row['z1']>0)) and ((row['z2']<0)):\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif (row['Paper(s)']=='Foord+2019') and ((row['z1']>0)) and ((row['z2']<0)):\n",
    "        gandalf.at[index, 'Confidence Flag'] = -1\n",
    "\n",
    "\n",
    "papers = ['Eftekharzadeh+2017','Inada+2010 ; Gattano+2014','Myers+2007 ; Myers+2008 ; Eftekharzadeh+2017',\\\n",
    "         'Inada+2012 ; Eftekharzadeh+2017','Inada+2012','Inada+2010','More+2016',\\\n",
    "         'Myers+2007 ; Eftekharzadeh+2017','Myers+2007 ; Myers+2008 ; Inada+2010 ; Eftekharzadeh+2017',\\\n",
    "         'Myers+2007 ; Myers+2008 ; Inada+2012 ; Eftekharzadeh+2017','Myers+2007',\\\n",
    "         'Myers+2007 ; Myers+2008 ; Eftekharzadeh+2017 ; Rusu+2019','Inada+2008']\n",
    "\n",
    "#for flag one\n",
    "for i in papers:\n",
    "    for index, row in gandalf.iterrows():\n",
    "        if (row['Paper(s)']== str(i)) and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec'))  and (np.abs(row['dV_new'])<=600):\n",
    "            gandalf.at[index, 'Confidence Flag'] = 1\n",
    "        elif (row['Paper(s)']== str(i)) and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec'))  and (np.abs(row['dV_new'])>600):\n",
    "            gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "        elif (row['Paper(s)']== str(i)) and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='phot')) and (row['z2_type']=='phot'):\n",
    "            gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "        elif (row['Paper(s)']== str(i)) and ((row['z1']<0)) and ((row['z2']>0)) and ((row['z2_type']=='spec')):\n",
    "            gandalf.at[index, 'Confidence Flag'] = 0\n",
    "\n",
    "for index, row in gandalf.iterrows():\n",
    "    if (row['Paper(s)']=='Eftekharzadeh+2017 ; Lemon+2020') and ((row['z1']<0)) and ((row['z2']>0)) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif (row['Paper(s)']=='Rusu+2019 ; Lemon+2020') and ((row['z1']<0)) and ((row['z2']>0)) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif (row['Paper(s)']=='Eftekharzadeh+2017 ; Lemon+2020 ') and ((row['z1']<0)) and ((row['z2']>0)) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif (row['Paper(s)']=='Rusu+2019 ; Lemon+2020 ') and ((row['z1']<0)) and ((row['z2']>0)) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif (row['Paper(s)']=='Owen+1985 ; Hudson+2006') and ((row['z1']>0)) and ((row['z2']>0)):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1        \n",
    "    elif (row['Paper(s)']=='Fabbiano+2011 ; Imanishi+2014 ; Koss+2015'):\n",
    "        gandalf.at[index, 'Confidence Flag'] = -1        \n",
    "    elif (row['Paper(s)']=='Koss+2012 ; Hainline+2016') and ((row['z1']>0)) and (row['z2']>0):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1        \n",
    "    elif (row['Paper(s)']=='Winter+2008 ; Koss+2012 ; Koss+2016') and ((row['z1']>0)) and ((row['z2']>0)):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1        \n",
    "    elif (row['Paper(s)']=='Eckert+2017') and ((row['z1']>0)) and ((row['z2']>0)):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1\n",
    "    elif (row['Paper(s)']=='Piconcelli+2010 ; Imanishi+2014') and ((row['z1']>0)) and ((row['z2']>0)):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1\n",
    "    elif (row['Paper(s)']=='Junkkarinen+2001 ; Shields+2012') and ((row['z1']>0)) and ((row['z2']>0)):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1           \n",
    "#Inada+2012 ; Hwang+2020 ; Hwang+2020 --> still not working....\n",
    "#Inada+2008 ; Spiniello+2018\n",
    "#Inada+2008 ; Graham+2015 ; Guo+2020\n",
    "#Comerford+2013\n",
    "#Inada+2010 ; Comerford+2014\n",
    "#Inada+2012 ; Yang+2019\n",
    "#Fischer+2011\n",
    "#Assef+2013\n",
    "#Goulding+2019\n",
    "#Foord+2019\n",
    "    \n",
    "# we need to go back and fix the damn overlapping object between lemon2020 and rusu2019. For some reasoon\n",
    "# we do not defer to lemon 2020 for the redshifts?\n",
    "\n",
    "#Smith+2010 ; Smith+2012 ; Song+2020\n",
    "#Smith+2010 ; Smith+2012 ; Ge+2012 ; Song+2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a0418af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in gandalf.iterrows():\n",
    "    if (row['Paper(s)']=='Liu+2011b ; Comerford+2014') and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif (row['Paper(s)']=='Liu+2011b ; Liu+2010a ; Ge+2012 ; Nevin+2016') and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif (row['Paper(s)']=='Liu+2011b ; Wang+2009 ; Tingay+2011') and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif (row['Paper(s)']=='Liu+2011b ; Satyapal+2017 ; Pfeifle+2019a') and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif (row['Paper(s)']=='Liu+2011b ; Wang+2009 ; Ge+2012') and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif (row['Paper(s)']=='Liu+2011b ; Koss+2012') and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1\n",
    "    elif (row['Paper(s)']=='Liu+2011b ; Kharb+2019') and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif (row['Paper(s)']=='Liu+2011b ; Wang+2009') and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif (row['Paper(s)']=='Liu+2011b ; Fu+2018') and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif (row['Paper(s)']=='Liu+2011b ; Liu+2010a') and ((row['z1']>0)) and ((row['z2']>0)) and ((row['z1_type']=='spec')) and ((row['z2_type']=='spec')):\n",
    "        gandalf.at[index, 'Confidence Flag'] = 0.5    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d23a441b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xliu = pd.read_csv('xliu2011_formated_catalog_forrflags.csv', sep=',')\n",
    "\n",
    "xliu_agns = xliu[((xliu['FAGN1']==0) | (xliu['FAGN1']==3) | (xliu['FAGN1']==4) | (xliu['FAGN1']==5)) & \\\n",
    "                 ((xliu['FAGN2']==0) | (xliu['FAGN2']==3) | (xliu['FAGN2']==4) | (xliu['FAGN2']==5)) & \\\n",
    "                 (xliu['Sep']>10)]\n",
    "\n",
    "len(xliu_agns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e75597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the notes from the Liu 2011 ReadME file. We'll use the optical types to add confidence flags\n",
    "#--------------------------------------------------------------------------------\n",
    "#      64  I1    ---     FAGN    [0/5] Sub-population flag (1)\n",
    "#--------------------------------------------------------------------------------\n",
    "#Note (1): Flag for sub-populations in the parent AGN sample: \n",
    "# * \"0\" through \"2\" are for narrow-line AGNs contained in the MPA-JHU DR7 catalog, where \"0\" stands for Seyferts,\\\n",
    "# \"1\" for LINERs, and \"2\" for composites, respectively, according to the Kewley et al. (2001ApJ...556..121K) and \\\n",
    "# Kauffmann et al. (2003MNRAS.346.1055K) criteria for separating AGNs and composites from HII regions, and \\\n",
    "# the Ho et al. (1997, Cat. J/ApJS/112/315) criterion for separating Seyferts from LINERS (Figure 4). \n",
    "# * \"3\" for narrow-line quasars in the Reyes et al. (2008, Cat. J/AJ/136/2373) sample but not in the MPA-JHU DR7 catalog; \n",
    "# * \"4\" for broad-line quasars, and \"5\" for broad-line AGNs accordinG to the Hao et al. (2005AJ....129.1783H) selection.\n",
    "\n",
    "# so for the optical types, pairs with the flag combinations of:\n",
    "# (0|3|4|5) and (0|3|4|5) will have flags of +1\n",
    "\n",
    "# for flag combos of:\n",
    "#(1|2) and (1|2) or any combo of AGN + non-AGN\n",
    "# so basically once we run through and set the flags for the true AGN optical pairs, we can set the remaindeer \n",
    "# we will use flags of +0.5\n",
    "\n",
    "#gimli = MAC[~MAC['Name1'].isin(gandalf['Name1'])]\n",
    "xliu_agns_1list = xliu_agns['Name1'].to_list()\n",
    "xliu_agns_2list = xliu_agns['Name2'].to_list()\n",
    "\n",
    "for index, row in gandalf.iterrows():\n",
    "    if row['Name1'] in xliu_agns_1list:\n",
    "        #print('True')\n",
    "        gandalf.at[index, 'Confidence Flag'] = 1 \n",
    "        gandalf.at[index, 'Confirmation Method'] = gandalf.at[index, 'Selection Method']\n",
    "        gandalf.at[index, 'Primary System Type'] = 'Dual AGN'\n",
    "    elif (row['Paper(s)']=='Liu+2011b') and (row['Name1'] not in xliu_agns_1list):\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif (row['Paper(s)']=='Liu+2011b ; Barrows+2016') and (row['Name1'] not in xliu_agns_1list):\n",
    "        gandalf.at[index, 'Confidence Flag'] = +0.5\n",
    "    \n",
    "#('2011ApJ...737..101L' in row['BibCode(s)']) and (row['Name1'] not in xliu_agns_1list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gandalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d278fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## these are getting a -1 flag\n",
    "#J011333.06+002947.9 # allen+2015 results\n",
    "#J120401.97+012641.6 # allen+2015 results\n",
    "#J000911.58-003654.7 # mullersanchez find DP lines originate from radio-driven outflow\n",
    "#J073117.55+452803.2 #agn-driven outflow\n",
    "#J073656.47+475946.8 # disk rotation\n",
    "#J080218.65+304622.7 # agn driven outflow\n",
    "#J084624.51+425842.8 # agn driven outflow\n",
    "#J085841.76+104122.1 # radio jet driven outflow\n",
    "#J091646.03+283526.7 # agn driven outflow\n",
    "#J093024.84+343057.3 # agn driven outflow\n",
    "#J115249.33+190300.3 # radio jet driven outflow\n",
    "#J111201+275053 # agn driven outflow\n",
    "#J155619.30+094855.6 # agn driven outflow\n",
    "#J225420.99-005134.1 # radio jet driven outflow\n",
    "#J230442.82-093345.3 # no companions with 3'', shen+ attributed DP lines to NLR kinematics. Gabanyi+2016 conclude radio-ISM interaction\n",
    "#J163056.75+164957.2 # no compaions within 3''. Shen find single nucleus and note that expect sep is >0.6'', meaning DP lines not from a dual\n",
    "#J160436.21+500958.1 # evidence all points to a single AGN\n",
    "#J155205.93+043317.5 # Shen find single nucleus and offset from peaks implies >0.6'' sep. DP lines liekyl arise from NLR kinematics\n",
    "#J134114.87+221957.8 # Shen find single nucleus and offset from peaks implies >0.6'' sep. DP lines liekyl arise from NLR kinematics\n",
    "#J114610.04-022619.2 # Shen find single nucleus and offset from peaks implies >0.6'' sep. DP lines liekyl arise from NLR kinematics\n",
    "#J103850.13+025555.1 # Shen find single nucleus and offset from peaks implies >0.6'' sep. DP lines liekyl arise from NLR kinematics\n",
    "#J100654.20+464717.2 # evidence points to single asgn\n",
    "#J095833.20-005118.6 # evidence points to single. Shen find single nucleus and offset from peaks implies >0.6'' sep. DP lines liekyl arise from NLR kinematics\n",
    "#J085416.76+502632.0 # evidence points toward single AGN\n",
    "#J085121.94+132702.2 # Shen find single nucleus and offset from peaks implies >0.6'' sep. DP lines liekyl arise from NLR kinematics\n",
    "#J040001.59-065254.1 # Shen find single nucleus and offset from peaks implies >0.6'' sep. DP lines liekyl arise from NLR kinematics and Fu+ and others conclude this is also a single\n",
    "#J015605.14-000721.7 # Shen find single nucleus and offset from peaks implies >0.6'' sep. DP lines liekyl arise from NLR kinematics\n",
    "#J014209-005049 # evidence points to single AGN\n",
    "#J013555.82+143529.7 # shen result again and no compaions found by Fu and co+\n",
    "#J013546.93-005858.5 # shen results again\n",
    "#J011659.59-102539.1 # shen results again; comerford 2012 results conflict but we're still consideing this a single AGN\n",
    "#\n",
    "#\n",
    "#J144804.17+182537.9 # this is getting zero because Foord suggests still candiate but other works concluded single AGN\n",
    "#J083713.49+150037.2 # this is getting zero because Shen concluded single AGN but mcgurk found companion within 3''\n",
    "#J075223.35+273643.1 # getting zero due to Foord's analysis\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7573fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gandalf[gandalf['Confidence Flag']<-5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea842f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gandalf[gandalf['Confidence Flag']<-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b88e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "gandalfnames = gandalf['Name1'].to_list()\n",
    "gandalfconf = gandalf['Confidence Flag'].to_list()\n",
    "\n",
    "for i,j in zip(gandalfnames,gandalfconf):\n",
    "    MAC.loc[MAC.Name1==str(i), 'Confidence Flag'] = j\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb7a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MACcheck = MAC[MAC['Confidence Flag']>-5]\n",
    "#len(MACcheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "gandalf[gandalf['Confidence Flag']>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2df347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the table up again so that we can assign flags more easily...\n",
    "gandalf['Notes'] = gandalf['Notes'].astype(str)\n",
    "\n",
    "gandalf_grey = gandalf[((gandalf['z1']>0) & (gandalf['z2']<0))|((gandalf['z1']<0) & (gandalf['z2']>0))]\n",
    "gandalf_white = gandalf[(gandalf['z1']>0) & (gandalf['z2']>0)]\n",
    "saruman = gandalf[(gandalf['z1']<0) & (gandalf['z2']<0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec302e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now assigning more confidence flags...\n",
    "\n",
    "gandalf_grey2 = gandalf_grey[gandalf_grey['Confidence Flag']<-10]\n",
    "gandalf_white2 = gandalf_white[gandalf_white['Confidence Flag']<-10]\n",
    "saruman2 = saruman[saruman['Confidence Flag']<-10]\n",
    "print(len(gandalf_grey2),len(gandalf_white2),len(saruman2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(gandalf),len(gandalf_grey),len(gandalf_white),len(saruman))\n",
    "\n",
    "# okay, so the problem children in terms a of redshift \n",
    "# and fu2015 \n",
    "\n",
    "\n",
    "# Orosz has partial redshift coverage. Hwang has no redshifts.\n",
    "# I've added in the available redshifts for Lemon 2018, 2019, and 2020.\n",
    "# Spiniello+ is simply going to be a problem. No redshifts and no separations listed. We'll have to reach out.\n",
    "# Fu 2015 is lacking redshifts for most\n",
    "# Eftek has a subset that do not have redshifts\n",
    "# Rusu2019 is lacking redshifts for pretty much everything\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fe57b5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Binary AGN Candidate / Binary SMBH Candidate' 'Dual SMBH Candidate'\n",
      " 'Binary AGN Candidate / Dual SMBH Candidate / Recoil Candidate'\n",
      " 'Binary AGN Candidate / Dual SMBH Candidate' 'Binary AGN Candidate'\n",
      " 'Binary SMBH Candidate' 'Recoil Candidate'\n",
      " 'Binary AGN Candidate / Recoil Candidate' 'Binary AGN'\n",
      " 'Binary SMBH Candidate / Dual SMBH Candidate / Recoil Candidate'\n",
      " 'Binary SMBH Candidate / Recoil Candidate']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# carving up the table now to format individual pieces (hopefully this will make it easier to format... \\\n",
    "# it's been nothing but headaches so far...)\n",
    "\n",
    "unique_combinations = gimli['Processed System Type'].dropna().unique()\n",
    "\n",
    "print(unique_combinations)\n",
    "print(len(unique_combinations))\n",
    "\n",
    "\n",
    "#merry = gimli[gimli['Processed System Type']=='Binary SMBH Candidate']\n",
    "\n",
    "\n",
    "### Fixed:\n",
    "# AGN Recoil Candidate (Steinhardt+2012 target) --> changed to 'Recoil Candidate' in individual target list\n",
    "# Binary AGN Candidate (Single AGN) --> changed to 'Binary AGn Candidate' in individual target list; this will get\\\n",
    "#     a flag of -1 in the catalog.\n",
    "# Ejected Nucleus Candidate (this is the Keeney+2011 paper) --> changed this to recoil candidate. komossa+ \\\n",
    "#     refers to this work as a candidate, and Keeney+ also seem to suggest this could  be a recoil or ejected nucleus\n",
    "# Binary SMBH Candidate / Dual SMBH Candidate / Recoil Candidate --> single menezes+2014 target\n",
    "#    I'm okay with this classification until I check masses and compare against my binary definition.\n",
    "# These are all converted back to dual AGN candidate, and a command has been added to insert a confidence flag:\n",
    "#     Single AGNs --> these are the 2 single AGN objects from Fu+2015\n",
    "#     Single AGN --> double-peaked selected, from varying samples\n",
    "#     Likely Single AGN --> various double-peaked selection objects\n",
    "## Offset AGN Candidate --> converting this to dual SMBH candidate in all cases\n",
    "\n",
    "# Notes on flags to adjust:\n",
    "#For literature name == LGGS J004527.30+413254.3, give flag of -1. Barth swiftly rejected this target.\n",
    "# For the two 'Single AGNs'from Fu+2015a,b --> flag of -1 for these\n",
    "# For the 'Single AGN' --> most likely flag -1 for these\n",
    "# 'Likely Single AGN' --> most likely flag of -1 for these\n",
    "# offset AGN candidate --> changing this to 'dual SMBH candidate' ? Since this is what Julie is trying to select \\\n",
    "# for. \n",
    "\n",
    "# Other things adjusted:\n",
    "# Just finally added a redshift for NGC 1068\n",
    "# Adjusted the matching stuff for the Barrows+2011 target so that a secondary z and name are not adopted\n",
    "# Added 'bulge' and 'red blob' in name1 and name2 for the Markakis+ target\n",
    "\n",
    "#merry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02fa2a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_n/4v22wftn7354wlkmn_g7rtdr0000gn/T/ipykernel_40742/3632438601.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gimli['Selection Method'] = gimli['Selection Method'].astype(str)\n",
      "/var/folders/_n/4v22wftn7354wlkmn_g7rtdr0000gn/T/ipykernel_40742/3632438601.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gimli['Processed Selection Method'] = processed_types.apply(' / '.join)\n"
     ]
    }
   ],
   "source": [
    "# and now cleaning up the selection method column...\n",
    "gimli['Selection Method'] = gimli['Selection Method'].astype(str)\n",
    "types = gimli['Selection Method'].dropna().str.split(' / ')\n",
    "\n",
    "# Step 2 and 3: Remove duplicates and alphabetize for each cell\n",
    "def process_cell(cell):\n",
    "    # Remove duplicates using set and then convert back to list\n",
    "    unique_labels = list(set(cell))\n",
    "    # Alphabetize the contents\n",
    "    unique_labels.sort()\n",
    "    return unique_labels\n",
    "\n",
    "processed_types = types.apply(process_cell)\n",
    "\n",
    "# Step 4: Join the contents back into a single string\n",
    "gimli['Processed Selection Method'] = processed_types.apply(' / '.join)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#print(gimli[['Processed Selection Method']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af07b839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_n/4v22wftn7354wlkmn_g7rtdr0000gn/T/ipykernel_40742/2185669576.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gimli.at[index, 'Confidence Flag'] = -0.5\n"
     ]
    }
   ],
   "source": [
    "# now adding in the subjective flag\n",
    "\n",
    "papers = ['']\n",
    "\n",
    "\n",
    "#for index, row in gimli.iterrows():\n",
    "# objects in procmeth are getting -0.5\n",
    "procmeth = ['Gamma-Ray Quasi-Periodicity','X-ray Imaging / X-ray Periodicity','Radio Imaging / Radio Periodicity',\\\n",
    "'Hard X-ray Periodicity','Optical Periodicity / Radio Periodicity','Optical Periodicity','Optical Periodicity',\\\n",
    "'Radio Periodicity','Modeling / X-Shaped Radio Source','Radio Jet Precession / Modeling / Radio Imaging',\\\n",
    "            'Modeling / Optical Periodicity / Radio Quasi-Periodicity / Radio Periodicity / X-ray Periodicity',\\\n",
    "            'Radio Jet Precession / Modeling / Radio Quasi-Periodicity / Radio Periodicity',\\\n",
    "            'Gamma-Ray Quasi-Periodicity / Modeling / Near-IR Quasi-Periodicity / Optical Quasi-Periodicity',\\\n",
    "            'Near-IR Quasi-Periodicity / Optical Quasi-Periodicity','Radio Jet Precession / Variability','Modeling',\\\n",
    "            'Gamma-Ray Quasi-Periodicity / Optical Quasi-Periodicity','Periodicity / Variability',\\\n",
    "           'Modeling / Optical Periodicity / Radio Periodicity / Radio Quasi-Periodicity / X-ray Periodicity',\\\n",
    "           'Radio Jet Precession / Modeling / Radio Periodicity / Radio Quasi-Periodicity',\\\n",
    "           'Modeling / Optical Periodicity / Radio Periodicity / Radio Quasi-Periodicity / X-ray Periodicity',\\\n",
    "           'Quasi-Periodicity','Periodicity','Radio Jet Precession / Radio Imaging','Variability','Radio Jet Precession',\\\n",
    "           'Quasi-Periodicity / Variability','Variability / Periodicity',\\\n",
    "            'Radio Jet Precession / Periodicity / Variability','Radio Imaging / Radio Jet Precession',\\\n",
    "           'Optical Periodicity / Optical Quasi-Periodicity / Radio Imaging / Radio Jet Precession',\\\n",
    "            'Optical LOS Radial Velocity Shifts / Optical Periodicity / Optical Spectroscopy / Optical Velocity Offset Broad Spectroscopic Emission Lines',\\\n",
    "           'Optical Periodicity / Optical Quasi-Periodicity / Radio Imaging / Radio Jet Precession',\\\n",
    "           'Optical Fiber Spectroscopy / Optical Periodicity / Optical Spectroscopy',\\\n",
    "           'Near-IR Quasi-Periodicity / Optical Quasi-Periodicity / Radio Quasi-Periodicity',\\\n",
    "           'Modeling / Radio Jet Precession / Radio Periodicity / Radio Quasi-Periodicity',\\\n",
    "           'Modeling / Radio Imaging / Radio Jet Precession','Radio Quasi-Periodicity']\n",
    "\n",
    "for index, row in gimli.iterrows():\n",
    "    if row['Paper(s)'] == 'Graham+2015':\n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Processed Selection Method'] in procmeth: # \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    #elif row['Processed Selection Method']=='Quasi-Periodicity': # \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    #elif row['Processed Selection Method']=='Periodicity': #\n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    #elif row['Processed Selection Method']=='Radio Jet Precession / Radio Imaging': # \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    #elif row['Processed Selection Method']=='Variability': # \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    #elif row['Processed Selection Method']=='Quasi-Periodicity / Variability': # \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    #elif row['Processed Selection Method']=='Variability / Periodicity': # \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    #elif row['Processed Selection Method']=='Radio Jet Precession / Periodicity / Variability': # \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    #elif row['Processed Selection Method']=='Periodicity / Variability': # \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5      \n",
    "    #elif row['Processed Selection Method']=='Modeling': # \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5    \n",
    "    #elif row['Processed Selection Method']=='Radio Jet Precession': # \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5  \n",
    "    #elif row['Processed Selection Method']=='Radio Jet Precession / Variability': # \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -0.5 \n",
    "    elif row['Processed Selection Method']=='X-Shaped Radio Source': # \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)'] == 'Graham+2015 ; Guo+2020':\n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)'] == 'Charisi+2016':\n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)'] == 'Charisi+2016 ; Guo+2020':\n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)'] == 'Comerford+2014':\n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)'] == 'Yang+2019':\n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)'] == 'Yang+2019 ; Joshi+2019':\n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)'] == 'Krause+2019': # this is claimed Radio Jet Precession\n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['BibCode(s)'] == '2014ApJ...789..140L':\n",
    "        gimli.at[index, 'Confidence Flag'] = 0    \n",
    "    elif row['Paper(s)'] == 'Proctor+2011': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)'] == 'Cheung+2007 ; Proctor+2011 ; Roberts+2018 ; Saripalli+2018 ; Saripalli+2018 ; Lal+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)'] == 'Cheung+2007 ; Roberts+2018 ; Saripalli+2018 ; Saripalli+2018': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)'] == 'Cheung+2007 ; Proctor+2011 ; Roberts+2018 ; Saripalli+2018 ; Saripalli+2018': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)'] == 'Cheung+2007 ; Roberts+2018': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)'] == 'Cheung+2007 ; Roberts+2018 ; Saripalli+2018 ; Saripalli+2018 ; Lal+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)'] == 'Proctor+2011 ; Yang+2019 ; Joshi+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)'] == 'Proctor+2011 ; Yang+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)'] == 'Proctor+2011 ; Merritt+2002 ; Lal+2007': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)'] == 'Jonker+2010 ; Heida+2015': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)'] == 'Caldwell+2014': \n",
    "        gimli.at[index, 'Confidence Flag'] = -1\n",
    "    elif row['Paper(s)'] == 'Pesce+2018': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif 'Single AGN' in row['Legacy System Type']: \n",
    "        gimli.at[index, 'Confidence Flag'] = -1\n",
    "    elif row['Paper(s)'] == 'Lena+2014': # these are recoil candidates based on positional offsets\n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif 'Maness+2004' in row['Paper(s)']: # this is the rodriguez+06 target, CSO 0402\n",
    "        gimli.at[index, 'Confidence Flag'] = 1\n",
    "    elif row['BibCode(s)'] == '2016ApJ...824..122K': # this is Kim+2016\n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif '1988ApJ...325..628S' in row['BibCode(s)']: # this is OJ 287 and Salanpää+88\n",
    "        gimli.at[index, 'Confidence Flag'] = +0.5 \n",
    "    elif row['Literature Name'] == 'LGGS J004527.30+413254.3': # Barth+ showed emphatically this is not a good candidate\n",
    "        gimli.at[index, 'Confidence Flag'] = -1 #2017ApJ...850...86D ; 2018ApJ...859...10B\n",
    "    elif row['Paper(s)']=='Keeney+2011': # this is recoil candidate/ejected nucleus\n",
    "        gimli.at[index, 'Confidence Flag'] = +0.5\n",
    "    # below here are the three promosing targets from E12, bumping it to +0.5, \n",
    "    #e12prom = ['093844','095036','161911']\n",
    "    elif row['Name1']=='093844.45+005715.7':\n",
    "        gimli.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif row['Name1']=='095036.75+512838.1':\n",
    "        gimli.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif row['Name1']=='161911.24+501109.2':\n",
    "        gimli.at[index, 'Confidence Flag'] = 0.5\n",
    "    # and now for the remainder of their sample\n",
    "    elif row['Paper(s)']=='Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Tsalmantza+2011 ; Decarli+2013 ; Lusso+2014': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Tsalmantza+2011 ; Decarli+2013 ; Lusso+2014 ; Liu+2014 ; Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Halpern+1992 ; Eracleous+1997 ; Gezari+2007 ; Liu+2016 ; Doan+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -1\n",
    "    elif row['Paper(s)']=='Halpern+1988 ; Miller+1990 ; Halpern+1992 ; Eracleous+1997 ; Gezari+2007 ; Liu+2016 ; Doan+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -1\n",
    "    elif row['Paper(s)']=='Peterson+1987 ; Sergeev+1997 ; Sergeev+2007 ; Li+2016; Bon+2016 ; Ilić+2017': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Marziani+1993 ; Gezari+2007 ; Liu+2016 ; Doan+2020 ; Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -1\n",
    "    elif row['Paper(s)']=='Lewis+2010 ; Liu+2016 ; Doan+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5        \n",
    "    elif row['Paper(s)']=='Gezari+2007 ; Krause+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5        \n",
    "    elif row['Paper(s)']=='Krezinger+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5        \n",
    "    elif row['Paper(s)']=='Webb+1990 ; Caproni+2004b ; Vol\\'vach+2010 ; Du+2018': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Hu+2020 ; Kun+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Schmidt+1965 ; Merritt+2002 ; Cheung+2007 ; Merritt+2002 ; Lal+2007': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Schmidt+1965 ; Merritt+2002 ; Cheung+2007 ; Merritt+2002 ; Lal+2007 ; Krause+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Graham+2015a ; D\\'Orazio+2015 ; Charisi+2015 ; Kun+2015 ; Jun+2015 ; Vaughan+2015 ; Mohan+2016 ; Liu+2018 ; Kovacevic+2019 ; Graham+2015 ; Guo+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -1\n",
    "    elif row['Paper(s)']=='Sudou+2003 ; Jenet+2004 ; Iguchi+2010 ; Sudou+2017': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Blundell+2001 ; Robinson+2010 ; Shapovalova+2016 ; Ilić+2017': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Roland+2013 ; Qian+2013 ; Sandrinelli+2016 ; Qian+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Conway+1995 ; Villata+1999 ; Rieger+2000 ; Rieger+2003 ; Rieger+2007 ; Bhatta+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Batcheldor+2010': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Yan+2015 ; Leighly+2016 ; Kovaˇcevi´c+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -1\n",
    "    elif row['Paper(s)']=='Menezes+2016': \n",
    "        gimli.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif row['Paper(s)']=='Menezes+2014': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Tsai+2013': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Shen+2013': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Ju+2013': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)']=='Yan+2015 ; Leighly+2016 ; Kovaˇcevi´c+2020': \n",
    "    #    gimli.at[index, 'Confidence Flag'] = -1\n",
    "    elif row['Paper(s)']=='Liu+2014 ; Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Liu+2014 ; Kim+2016': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Liu+2014 ; Krause+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Koss+2014': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Eracleous+1994 ; Lewis+2010 ; Liu+2016 ; Doan+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Hummel+1992 ; Roos+1993 ; Murphy+2003 ; Kun+2014': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020 ; Ju+2013 ; Wang+2017': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Comerford+2014 ; Kharb+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Comerford+2014 ; Yang+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Ju+2013 ; Wang+2017': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Paper(s)']=='Wang+2017': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Markakis+2015': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Ackermann+2015 ; Sobacchi+2017 ; Cavaliere+2017 ; Caproni+2017 ; Tavani+2018 ; Sandrinelli+2018 ; Munar-Adrover+2019 ; Covino+2019':\n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5        \n",
    "    elif row['Paper(s)']=='Eracleous+1994': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0       \n",
    "    elif row['Paper(s)']=='Eracleous+1994 ; Krause+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Doan+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5        \n",
    "    elif row['Paper(s)']=='Gezari+2007 ; Liu+2016 ; Doan+2020 ; Proctor+2011': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0 # proctor's work could still suggest it's a recoil or binary but optically this is not a binary        \n",
    "    elif row['Paper(s)']=='Du+2018': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Comerford+2013': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Comerford+2009a': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Barrows+2016': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0.5\n",
    "    elif row['Paper(s)']=='Du+2018 ; Li+2019 ; Hu+2020': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Paper(s)']=='Ciaramella+2004 ; Rieger+2007 ; Vol\\'vach+2010 ; Caproni+2013 ; Sandrinelli+2017 ; Covino+2019': \n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "\n",
    "#Liu+2014 ; Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020 --> 0\n",
    "#Liu+2014 ; Kim+2016 --> 0\n",
    "#Liu+2014 ; Krause+2019 --> 0\n",
    "#Koss+2014 --> 0\n",
    "#Eracleous+1994 ; Lewis+2010 ; Liu+2016 ; Doan+2020 --> -0.5\n",
    "#Ackermann+2015 ; Sobacchi+2017 ; Cavaliere+2017 ; Caproni+2017 ; Tavani+2018 ; Sandrinelli+2018 ; Munar-Adrover+2019 ; Covino+2019 --> -0.5\n",
    "#Hummel+1992 ; Roos+1993 ; Murphy+2003 ; Kun+2014 --> -0.5\n",
    "#Markakis+2015 --> 0\n",
    "#Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020 ; Ju+2013 ; Wang+2017 --> -0.5\n",
    "#Comerford+2014 ; Kharb+2020 --> 0\n",
    "#Comerford+2014 ; Yang+2019 --> 0\n",
    "#Ju+2013 ; Wang+2017 --> -0.5\n",
    "#Wang+2017 --> 0\n",
    "#Eracleous+1994 --> 0      \n",
    "        \n",
    "#Single AGN\n",
    "#Lewis+2010 ; Liu+2016 ; Doan+2020 --> -0.5\n",
    "#Gezari+2007 ; Krause+2019 --> -0.5\n",
    "#Krezinger+2020 --> -0.5\n",
    "#Menezes+2016 --> +0.5\n",
    "#Menezes+2014 --> 0\n",
    "#Tsai+2013 --> 0\n",
    "#Hu+2020 ; Kun+2020 --> -0.5\n",
    "#Webb+1990 ; Caproni+2004b ; Vol'vach+2010 ; Du+2018 --> -0.5\n",
    "#Shen+2013 --> 0\n",
    "#Ju+2013 --> 0\n",
    "#Halpern+1992 ; Eracleous+1997 ; Gezari+2007 ; Liu+2016 ; Doan+2020 --> -1\n",
    "#Halpern+1988 ; Miller+1990 ; Halpern+1992 ; Eracleous+1997 ; Gezari+2007 ; Liu+2016 ; Doan+2020 --> -1\n",
    "#Peterson+1987 ; Sergeev+1997 ; Sergeev+2007 ; Li+2016; Bon+2016 ; Ilić+2017 --> -0.5\n",
    "#Marziani+1993 ; Gezari+2007 ; Liu+2016 ; Doan+2020 ; Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020 --> -1\n",
    "#Tsalmantza+2011 ; Decarli+2013 ; Lusso+2014 --> -0.5\n",
    "#Tsalmantza+2011 ; Decarli+2013 ; Lusso+2014 ; Liu+2014 ; Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020 --> -0.5\n",
    "#Komossa+2008 ; Shields+2009 ; Bogdanović+2009 ; Dotti+2009 ; Heckman+2009 ; Decarli+2009 ; Decarli+2010 ; Tsalmantza+2011 ; Decarli+2013 ; Lusso+2014 ; Liu+2014 ; Eracleous+2012 ; Runnoe+2015 ; Runnoe+2017 ; Nguyen+2020 --> +0.5\n",
    "#Schmidt+1965 ; Merritt+2002 ; Cheung+2007 ; Merritt+2002 ; Lal+2007 --> 0\n",
    "#Schmidt+1965 ; Merritt+2002 ; Cheung+2007 ; Merritt+2002 ; Lal+2007 ; Krause+2019 --> 0\n",
    "#Graham+2015a ; D'Orazio+2015 ; Charisi+2015 ; Kun+2015 ; Jun+2015 ; Vaughan+2015 ; Mohan+2016 ; Liu+2018 ; Kovacevic+2019 ; Graham+2015 ; Guo+2020\n",
    "#--> -1\n",
    "#Sudou+2003 ; Jenet+2004 ; Iguchi+2010 ; Sudou+2017 --> -0.5\n",
    "#Blundell+2001 ; Robinson+2010 ; Shapovalova+2016 ; Ilić+2017 --> 0 # only for the recoil, the bianry is -0.5\n",
    "#Roland+2013 ; Qian+2013 ; Sandrinelli+2016 ; Qian+2019 --> -0.5\n",
    "#Conway+1995 ; Villata+1999 ; Rieger+2000 ; Rieger+2003 ; Rieger+2007 ; Bhatta+2019 --> 0\n",
    "# not sure how i feel about this one\n",
    "#Batcheldor+2010 --> 0\n",
    "#Yan+2015 ; Leighly+2016 ; Kovaˇcevi´c+2020 --> -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d5438b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcs = ['084716.03+373218.0','085237.01+200410.9','092837.98+602521.0','103059.09+310255.7',\\\n",
    "      '111230.89+181311.4','4C55.19 (J100157.93+554047.8 / NGC 3079)','B2 1213 + 350 (J121555.60+344815.2)',\\\n",
    "      'B2 1630 + 35','4C+22.25 / J1000+2233','3C 186 HOST',' 3C 186 HOST','SDSS 0956+5128','CXO J101527.2+625911',\\\n",
    "      '153705.95+005522.8']\n",
    "#4C55.19 (J100157.93+554047.8 / NGC 3079)\n",
    "# B2 1213 + 350 (J121555.60+344815.2)\n",
    "#B2 1630 + 35\n",
    "# Despite the overall lack of info on the above three objects, they were selected based on radio morphology \\\n",
    "# so I think it makes sens to give them a +0.5 because they could easily be ruled out with new obs. \\\n",
    "# They're much less ambiguous\n",
    "# SDSS 0956+5128 steinhardt's target is getting a +0.5\n",
    "# CXO J101527.2+625911 has both a spatial and spectra offset. promising.\n",
    "# 4C+22.25 / J1000+2233 had HUGE blue shifts. Seems reasonable to give it a 0.5 based on this\n",
    "# guo consider these as binary candidates: 153705.95+005522.8\n",
    "\n",
    "# these get flags of 0\n",
    "unclear = ['110050.99+170934.2','082930.59+272822.7','SDSS J1201+30','B1834+620','OX 169','RXS J10304+5516',\\\n",
    "          'RX J1042+1212','Mrk 1018','SDSSJ0932+0318 / J0932+0318']\n",
    "# being conservative with Mrk 1018\n",
    "# unclear for binary on SDSSJ0932+0318 / J0932+0318 but is really a -0.5 for recoil\n",
    "\n",
    "# these get flags of -0.5\n",
    "less = ['Mrk 6','3C 454.3','3C 390.3','032213.89+005513.4','141020.57+364322.7','155053.16+052112.1',\\\n",
    "       '234932.77-003645.8','J1714+3327','NGC 4151']\n",
    "# guo do not consider these as candidates for sub-pc binaries:\n",
    "#032213.89+005513.4\n",
    "#141020.57+364322.7\n",
    "#155053.16+052112.1\n",
    "#234932.77-003645.8\n",
    "\n",
    "\n",
    "# these get flags of -1\n",
    "remove = ['J101847.57+294114.1','J105553.64+152027.5','J111729.22+614015.2','J134640.79+522836.5']\n",
    "\n",
    "\n",
    "for index, row in gimli.iterrows():\n",
    "    if row['Name1'] in dcs:\n",
    "        gimli.at[index, 'Confidence Flag'] = +0.5\n",
    "    elif row['Name1'] in unclear:\n",
    "        gimli.at[index, 'Confidence Flag'] = 0\n",
    "    elif row['Name1'] in less:\n",
    "        gimli.at[index, 'Confidence Flag'] = -0.5\n",
    "    elif row['Name1'] in remove:\n",
    "        gimli.at[index, 'Confidence Flag'] = -1\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c5e7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727\n"
     ]
    }
   ],
   "source": [
    "gimlinames = gimli['Name1'].to_list()\n",
    "gimliconf = gimli['Confidence Flag'].to_list()\n",
    "\n",
    "for i,j in zip(gimlinames,gimliconf):\n",
    "    MAC.loc[MAC.Name1==str(i), 'Confidence Flag'] = j\n",
    "\n",
    "print(len(gimli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5bebdf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "gimli1 = gimli[gimli['Confidence Flag'] < -5]\n",
    "print(len(gimli1))\n",
    "#gimli1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d31f3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now here we're adding the confidence flag to the primary confidence flag column before preparing to add \\\n",
    "# secondary and tertiary confidence flags\n",
    "\n",
    "# first we apply the original confidence flag to the primary confidence flag column. \\\n",
    "#That should be sufficient for the majority of the sample\n",
    "MAC['ST1 Confidence Flag'] = MAC['Confidence Flag']\n",
    "\n",
    "# now we're going to check to see how many objects need a secondary class flag\n",
    "#print(len(MAC[(MAC['Secondary System Type']!='-99') & (MAC['Tertiary System Type']=='-99')]))\n",
    "#print(len(MAC[(MAC['Secondary System Type']!='-99') & (MAC['Tertiary System Type']!='-99')]))\n",
    "\n",
    "# here we can start to assign secondary and tertiary flags\n",
    "selmeth = ['X-Shaped Radio Source','Radio Imaging / X-Shaped Radio Source','X-Shaped Radio Source / Radio Imaging']\n",
    "\n",
    "for i in selmeth:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Selection Method']==str(i)) & (row['Secondary System Type']!='-99') & (row['Tertiary System Type']=='-99'):\n",
    "            MAC.at[index, 'ST2 Confidence Flag'] = 0\n",
    "        #elif row[MAC['Selection Method']==str(i)] and (MAC['Secondary System Type']!='-99') and (MAC['Tertiary System Type']=='-99'):\n",
    "        #    MAC.at[index, 'ST2 Confidence Flag'] = 0\n",
    "\n",
    "# manually adding in flags for objects that have two object classes:\n",
    "\n",
    "papers = ['Orosz+2013','Proctor+2011 ; Merritt+2002 ; Lal+2007','Popovic+2012','Ge+2012 ; Orosz+2013',\\\n",
    "          'Ciaramella+2004 ; Barrows+2013','Kim+2020 ; Liu+2014']\n",
    "for i in papers:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Paper(s)']==str(i)) & (row['Secondary System Type']!='-99'): # and (row['Tertiary System Type']=='-99'):\n",
    "            MAC.at[index, 'ST2 Confidence Flag'] = 0\n",
    "\n",
    "objs = ['J080529.88+241004.4','J140343.63+292045.3 / KISSR 434 A+B','J141116.45+194436.2',\\\n",
    "        'J124135.09+285036.5 / KISSR 102 N1-A','3C 433','3C 433 / 3C433','E1821+643','4C +01.30',\\\n",
    "        'J0116-473','J0437+2456','PKS 0537-441','3C 227 / J094745.2+072518','J080740+390015 / Mrk 622',\\\n",
    "        'J085431.28-003650.6','145824.46+363119.5','075819.69+421935.1','J155318.72+170202.9',\\\n",
    "       'J132848.46+275227.8','J154637.12+122832.5','J020011.52-093126.1','J09527.62+255257.2 / J0952+2552NE'] \n",
    "# these objects only warrant a 0 in the secondary column\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)) & (row['Secondary System Type']!='-99'): # and (row['Tertiary System Type']=='-99'):\n",
    "            MAC.at[index, 'ST2 Confidence Flag'] = 0    \n",
    "\n",
    "objs = ['HE0450-2958','COSMOS J100043.15+020637.2 / CID-42'] \n",
    "# these objects only warrant a -0.5 in the secondary column\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)) & (row['Secondary System Type']!='-99'): # and (row['Tertiary System Type']=='-99'):\n",
    "            MAC.at[index, 'ST2 Confidence Flag'] = 0.5    \n",
    "\n",
    "objs = ['SDSSJ081617.73+293639.6','PKS 0235+023 / J023832.67+023349.1']  \n",
    "# these objects only warrant a -0.5 in the secondary column\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)) & (row['Secondary System Type']!='-99'): # and (row['Tertiary System Type']=='-99'):\n",
    "            MAC.at[index, 'ST2 Confidence Flag'] = -0.5    \n",
    "\n",
    "objs = ['SDSS J1048+0055','J1536+0441 VLA-A'] \n",
    "# these objects only warrant a -0.5 in the secondary column\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)) & (row['Secondary System Type']!='-99'): # and (row['Tertiary System Type']=='-99'):\n",
    "            MAC.at[index, 'ST2 Confidence Flag'] = -1    \n",
    "            \n",
    "            \n",
    "# manually adding the second and third flags for the handful of targets that have three object classes (15)\n",
    "\n",
    "#0.5 and 0.5 for now?\n",
    "objs = ['SDSS J0927+2943']\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)): #and (row['Secondary System Type']!='-99') and (row['Tertiary System Type']=='-99'):\n",
    "            MAC.at[index, 'ST2 Confidence Flag'] = -1\n",
    "            MAC.at[index, 'ST3 Confidence Flag'] = -1\n",
    "\n",
    "objs = ['3C 293','NGC 3115','J083127.50+321926.9 / B2 0828+32','J094124+394441 / 3C223.1','J114016.98+174340.4',\\\n",
    "        'SDSSJ152806.63+132345.8 / J1528+1323','J003636.21+004853.45','J155416.08+381132.64',\\\n",
    "        'J091405.28+171554.36','J131638.16+242732.40','J014719.27-085119.58','J011341.11+010608.50',\\\n",
    "        'J161847.93+215925.4']\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)): #and (row['Secondary System Type']!='-99') and (row['Tertiary System Type']=='-99'):\n",
    "            MAC.at[index, 'ST2 Confidence Flag'] = 0\n",
    "            MAC.at[index, 'ST3 Confidence Flag'] = 0\n",
    "\n",
    "\n",
    "objs = ['142314.18+505537.2 / SBS 1421+511 QSO']\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)): #and (row['Secondary System Type']!='-99') and (row['Tertiary System Type']=='-99'):\n",
    "            MAC.at[index, 'ST2 Confidence Flag'] = 0\n",
    "            MAC.at[index, 'ST3 Confidence Flag'] = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12accab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(MAC[(MAC['Secondary System Type']!='-99') & (MAC['Tertiary System Type']=='-99')])\n",
    "#len(MAC[(MAC['Secondary System Type']!='-99') & (MAC['Tertiary System Type']=='-99') & \\\n",
    "#        (MAC['ST2 Confidence Flag']==-99) & (MAC['ST3 Confidence Flag']==-99)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4500b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAC[(MAC['Secondary System Type']!='-99') & (MAC['Tertiary System Type']=='-99') & \\\n",
    "#        (MAC['ST2 Confidence Flag']==-99) & (MAC['ST3 Confidence Flag']==-99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC[(MAC['Secondary System Type']!='-99') & (MAC['Tertiary System Type']!='-99')]['Name1'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "644da8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAC.to_csv('MAC_DR0p8_formatting.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e924b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAC = pd.read_csv('MAC_DR0p8_formatting.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5b29084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're going to work on reformatting some of the phrases used for the selection techniques\n",
    "\n",
    "\n",
    "types = MAC['Selection Method'].dropna().str.split(' / ')\n",
    "\n",
    "# Step 2 and 3: Remove duplicates, alphabetize, and replace 'binary quasar' with 'dual AGN' in any context for each cell\n",
    "def process_cell(cell):\n",
    "    cell = [x.replace('Fiber Spectroscopy', 'Optical Fiber Spectroscopy') for x in cell]\n",
    "    cell = [x.replace('Optical Optical Fiber Spectroscopy', 'Optical Fiber Spectroscopy') for x in cell]\n",
    "    cell = [x.replace('Fiber Optical Spectroscopy', 'Optical Fiber Spectroscopy') for x in cell]\n",
    "    cell = [x.replace('Slit Optical Spectroscopy', 'Optical Slit Spectroscopy') for x in cell]\n",
    "    cell = [x.replace('Long-Slit Optical Spectroscopy', 'Optical Long-Slit Spectroscopy') for x in cell]\n",
    "    cell = [x.replace('IFU Optical Spectroscopy', 'Optical IFU Spectroscopy') for x in cell]\n",
    "    cell = [x.replace('Double Radio Sources', 'Radio Double Sources') for x in cell]\n",
    "    cell = [x.replace('IFU Optical Imaging', 'Optical IFU Imaging') for x in cell]\n",
    "    cell = [x.replace('X-Shaped Radio Source', 'Radio X-Shaped Source') for x in cell]\n",
    "    cell = [x.replace('LOS Radial Velocity Shifts', 'Optical LOS Radial Velocity Shifts') for x in cell]\n",
    "    cell = [x.replace('Velocity Offset Broad Optical Spectroscopic Emission Lines', 'Optical Velocity Offset Broad Spectroscopic Emission Lines') for x in cell]\n",
    "    cell = [x.replace('Double-Peaked Optical Spectroscopic Emission Lines', 'Optical Double-Peaked Spectroscopic Emission Lines') for x in cell]\n",
    "    cell = [x.replace('Double-Peaked Broad Optical Spectroscopic Emission Lines', 'Optical Double-Peaked Broad Spectroscopic Emission Lines') for x in cell]\n",
    "    cell = [x.replace('Velocity Offset Narrow Optical Spectroscopic Emission Lines', 'Optical Velocity Offset Narrow Spectroscopic Emission Lines') for x in cell]\n",
    "    cell = [x.replace('Double-Peaked Narrow UV Spectroscopic Emission Lines', 'UV Double-Peaked Narrow Spectroscopic Emission Lines') for x in cell]\n",
    "    cell = [x.replace('Varstrometry', 'Optical Varstrometry') for x in cell]\n",
    "    # Remove duplicates using set and then convert back to list\n",
    "    unique_labels = list(set(cell))\n",
    "    # Alphabetize the contents\n",
    "    unique_labels.sort()\n",
    "    return unique_labels\n",
    "\n",
    "processed_types = types.apply(process_cell)\n",
    "\n",
    "# Step 4: Join the contents back into a single string\n",
    "MAC['Processed Selection Method'] = processed_types.apply(' / '.join)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5c1023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we're going to be working on the confrimation and new analysis methods column\n",
    "\n",
    "MAC['Analysis Method'] = MAC['Selection Method']\n",
    "\n",
    "#xliu_agns_1list = xliu_agns['Name1'].to_list()\n",
    "#xliu_agns_2list = xliu_agns['Name2'].to_list()\n",
    "\n",
    "for index, row in MAC.iterrows():\n",
    "    if row['Name1'] in xliu_agns_1list:\n",
    "        #print('True')\n",
    "        MAC.at[index, 'Confirmation Method'] = MAC.at[index, 'Selection Method']\n",
    "        MAC.at[index, 'Primary System Type'] = 'Dual AGN'\n",
    "        \n",
    "for index, row in MAC.iterrows():\n",
    "    if (row['Confidence Flag'] == 1) and ((row['Confirmation Method']!='-99') or (row['Confirmation Method']!=-99)):\n",
    "        MAC.at[index, 'Analysis Method'] += ' / ' + str(MAC.at[index, 'Confirmation Method'])\n",
    "    elif (row['Confidence Flag'] == 0.5) and (row['Confirmation Method']!='-99'):\n",
    "        MAC.at[index, 'Analysis Method'] += ' / ' + str(MAC.at[index, 'Confirmation Method'])   \n",
    "        MAC.at[index, 'Confirmation Method'] = '-99'\n",
    "    elif (row['Confidence Flag'] == 0.0) and (row['Confirmation Method']!='-99'):\n",
    "        MAC.at[index, 'Analysis Method'] += ' / ' + str(MAC.at[index, 'Confirmation Method'])   \n",
    "        MAC.at[index, 'Confirmation Method'] = '-99'    \n",
    "    elif (row['Confidence Flag'] == -0.5) and (row['Confirmation Method']!='-99'):\n",
    "        MAC.at[index, 'Analysis Method'] += ' / ' + str(MAC.at[index, 'Confirmation Method'])   \n",
    "        MAC.at[index, 'Confirmation Method'] = '-99'   \n",
    "    elif (row['Confidence Flag'] == -1) and (row['Confirmation Method']!='-99'):\n",
    "        MAC.at[index, 'Analysis Method'] += ' / ' + str(MAC.at[index, 'Confirmation Method'])   \n",
    "        MAC.at[index, 'Confirmation Method'] = '-99'   \n",
    "\n",
    "# manually adjusting the confirmation strats on a few targets\n",
    "papers = ['Inada+2010 ; Gattano+2014','Inada+2012 ; Eftekharzadeh+2017','Inada+2012','Dutta+2018 ; Keel+2019']\n",
    "for i in papers:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Paper(s)']==str(i)) and (row['Confidence Flag'] == 1) and ((row['Confirmation Method']=='-99') or row['Confirmation Method']==-99):\n",
    "            MAC.at[index, 'Confirmation Method'] = str(MAC.at[index, 'Selection Method'])\n",
    "\n",
    "\n",
    "# more manual adjustments to confirmation strategies:\n",
    "objs = ['J100602.14+071131.0','J102325.57+324348.4','J115822.58+323102.2','J162345.20+080851.1','IC 5338']\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)) and (row['Confidence Flag'] == 1) and (row['Confirmation Method']=='-99'):\n",
    "            MAC.at[index, 'Confirmation Method'] = 'Radio Imaging'\n",
    "\n",
    "# and down below here we'll need to make 'Dual AGN Candidate' --> 'Dual AGN' for confidence flags of 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15cf8ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(MAC[MAC['System Type']=='Dual AGN']))\n",
    "# print(len(MAC[(MAC['System Type']=='Dual AGN') & (MAC['Confidence Flag']!=1)]))\n",
    "# print(len(MAC[MAC['Confidence Flag']==1]))\n",
    "# print(len(MAC[(MAC['Confidence Flag']==1) & (MAC['Sep(kpc)']<10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f06b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC[MAC['Name1']=='UGC 6081']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ba2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC[(MAC['System Type']=='Dual AGN') & (MAC['Confidence Flag']!=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d18b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC[MAC['Confidence Flag']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd644323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(len(MAC[MAC['Confirmation Method']!='-99']))\n",
    "# print(len(MAC[(MAC['Confirmation Method']!='-99') & (MAC['Confidence Flag']==-99)]))\n",
    "# print(len(MAC[(MAC['Confirmation Method']!='-99') & (MAC['Confidence Flag']==1)]))\n",
    "# print(len(MAC[(MAC['Confirmation Method']==-99) & (MAC['Confidence Flag']==1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(MAC[(MAC['Confirmation Method']=='-99') & (MAC['Confidence Flag']==-99)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4848f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC[MAC['Confidence Flag']==-99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(MAC[MAC['Confidence Flag']==-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ee68cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making manual adjustments to confirmation strategies for objects that we've flagged as -1:\n",
    "objs = ['J101847.57+294114.1','J105553.64+152027.5','J111729.22+614015.2','J134640.79+522836.5',\\\n",
    "        '013412.78-010729.6','222051.44+005815.0','Mrk 78','J112939.77+605742.5']\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)) and (row['Confidence Flag'] == -1) and (row['Confirmation Method']=='-99'):\n",
    "            MAC.at[index, 'Confirmation Method'] = 'Radio Imaging'\n",
    "\n",
    "objs = ['SDSS J0914+0853']\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)) and (row['Confidence Flag'] == -1) and (row['Confirmation Method']=='-99'):\n",
    "            MAC.at[index, 'Confirmation Method'] = 'X-ray Imaging / X-ray Spectroscopy'\n",
    "\n",
    "objs = ['SDSS J0818+0601A']\n",
    "for i in objs:\n",
    "    for index, row in MAC.iterrows():\n",
    "        if (row['Name1']==str(i)) and (row['Confidence Flag'] == 1) and (row['Confirmation Method']=='-99'):\n",
    "            MAC.at[index, 'Confirmation Method'] = 'Optical Imaging / Optical Spectroscopy'\n",
    "\n",
    "\n",
    "\n",
    "#MAC[MAC['Confidence Flag']==-1]\n",
    "\n",
    "\n",
    "# need tocome back and fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC[MAC['Confirmation Method']!='-99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gloin = gimli[(gimli['z1']>0) & (gimli['z2']<0)]\n",
    "#oin = gimli[(gimli['z1']>0) & (gimli['z2']>0)]\n",
    "#bombur = gimli[(gimli['z1']<0) & (gimli['z2']<0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e97989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kili = gimli[(gimli['RA1']!=gimli['RA2']) & (gimli['RA2']!=-99)]\n",
    "#print(len(kili))\n",
    "#kili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fili = gimli[gimli['Name2']!='-99']\n",
    "#print(len(fili))\n",
    "#fili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ded73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gloin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289fc094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bombur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d795cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "# df = pd.DataFrame(data=d)\n",
    "\n",
    "# df['SelMeth'] = [{'Opt':['Image', 'Spec', 'Color'], 'MidIR':['Image', 'Color']},{}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876e10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     'Selection Method': [\n",
    "#         'Optical Imaging / Optical Spectroscopy / Fiber Spectroscopy / Mid-IR Colors',\n",
    "#         'Optical Fiber Spectroscopy / Mid-IR Colors',\n",
    "#         'Mid-IR Imaging / Mid-IR Colors',\n",
    "#         'Radio Imaging'\n",
    "#         # ... other rows\n",
    "#     ]\n",
    "# })\n",
    "\n",
    "# import re\n",
    "\n",
    "# def parse_selection_method(s):\n",
    "#     # Split the string by slashes\n",
    "#     methods = s.split(' / ')\n",
    "    \n",
    "#     result_dict = {}\n",
    "#     for method in methods:\n",
    "#         Use regular expressions to find wavebands and terms\n",
    "#         match = re.match(r'([a-zA-Z\\-]+)\\s([a-zA-Z]+)', method)\n",
    "#         if match:\n",
    "#             waveband, term = match.groups()\n",
    "#             if waveband in result_dict:\n",
    "#                 result_dict[waveband].append(term)\n",
    "#             else:\n",
    "#                 result_dict[waveband] = [term]\n",
    "    \n",
    "#     return result_dict\n",
    "\n",
    "# # Apply the function to each row\n",
    "# df['Parsed Selection Method'] = df['Processed Selection Method'].apply(parse_selection_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0db6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def parse_selection_method(s, wavebands, compound_wavebands):\n",
    "#     # Split the string by slashes\n",
    "#     methods = s.split(' / ')\n",
    "\n",
    "#     result_dict = {}\n",
    "#     for method in methods:\n",
    "#         # First check for compound wavebands\n",
    "#         compound_processed = False\n",
    "#         for compound in compound_wavebands:\n",
    "#             if compound in method:\n",
    "#                 term = method.replace(compound, '').strip()\n",
    "#                 for wb in compound.split('-'):\n",
    "#                     if wb in result_dict:\n",
    "#                         result_dict[wb].append(compound + ' ' + term)\n",
    "#                     else:\n",
    "#                         result_dict[wb] = [compound + ' ' + term]\n",
    "#                 compound_processed = True\n",
    "#                 break\n",
    "        \n",
    "#         if not compound_processed:\n",
    "#             # Process standard wavebands\n",
    "#             for waveband in wavebands:\n",
    "#                 if waveband in method:\n",
    "#                     term_start_idx = method.index(waveband) + len(waveband)\n",
    "#                     term = method[term_start_idx:].strip()\n",
    "\n",
    "#                     if waveband in result_dict:\n",
    "#                         result_dict[waveband].append(term)\n",
    "#                     else:\n",
    "#                         result_dict[waveband] = [term]\n",
    "\n",
    "#     return result_dict\n",
    "\n",
    "# # List of known wavebands\n",
    "# known_wavebands = ['Optical', 'Mid-IR', 'Radio', 'Hard X-ray', 'X-ray', 'UV', 'Infrared', 'Submillimeter',\\\n",
    "#                    'Near-IR','Gamma-Ray']\n",
    "\n",
    "# # List of compound wavebands\n",
    "# compound_wavebands = ['Radio-Optical', 'Optical-Mid-IR', 'Radio-Infrared']\n",
    "\n",
    "# # Apply the function to each row\n",
    "# MAC['Parsed Selection Method'] = MAC['Processed Selection Method'].apply(lambda x: parse_selection_method(x, known_wavebands, compound_wavebands))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "35689939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_selection_method(s, wavebands, compound_wavebands):\n",
    "    # Split the string by slashes\n",
    "    methods = s.split(' / ')\n",
    "\n",
    "    result_dict = {}\n",
    "    for method in methods:\n",
    "        # Explicitly handle 'Optical-Mid-IR Colors'\n",
    "        if 'Optical-Mid-IR Colors' in method:\n",
    "            for wb in ['Optical', 'Mid-IR']:\n",
    "                if wb in result_dict:\n",
    "                    result_dict[wb].append('Optical-Mid-IR Colors')\n",
    "                else:\n",
    "                    result_dict[wb] = ['Optical-Mid-IR Colors']\n",
    "        else:\n",
    "            # First check for compound wavebands\n",
    "            compound_processed = False\n",
    "            for compound in compound_wavebands:\n",
    "                if compound in method:\n",
    "                    term = method.replace(compound, '').strip()\n",
    "                    for wb in compound.split('-'):\n",
    "                        if wb in result_dict:\n",
    "                            result_dict[wb].append(compound + ' ' + term)\n",
    "                        else:\n",
    "                            result_dict[wb] = [compound + ' ' + term]\n",
    "                    compound_processed = True\n",
    "                    break\n",
    "            \n",
    "            if not compound_processed:\n",
    "                # Process standard wavebands\n",
    "                for waveband in wavebands:\n",
    "                    if waveband in method:\n",
    "                        term_start_idx = method.index(waveband) + len(waveband)\n",
    "                        term = method[term_start_idx:].strip()\n",
    "\n",
    "                        if waveband in result_dict:\n",
    "                            result_dict[waveband].append(term)\n",
    "                        else:\n",
    "                            result_dict[waveband] = [term]\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# List of known wavebands\n",
    "known_wavebands = ['Optical', 'Mid-IR', 'Radio', 'Hard X-ray', 'X-ray', 'UV', 'Infrared', 'Submillimeter',\\\n",
    "                   'Near-IR','Gamma-Ray']\n",
    "\n",
    "# List of compound wavebands\n",
    "compound_wavebands = ['Radio-Optical', 'Optical-Mid-IR', 'Radio-Infrared']\n",
    "\n",
    "# Apply the function to each row\n",
    "MAC['Parsed Selection Method'] = MAC['Processed Selection Method'].apply(lambda x: parse_selection_method(x, known_wavebands, compound_wavebands))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC['Parsed Selection Method'] = MAC['Processed Selection Method'].apply(parse_selection_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef29480",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC.to_csv('MAC_DR0p9.csv', sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfa99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Parsed Selection Method']['Optical']['Imaging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this was for finding the number of objects that did not have selection methods mentioned\n",
    "## we no longer needed this to be an active cell now that we've fixed those issues\n",
    "#gandalf_nosel = gandalf[gandalf['Selection Method']=='-99']\n",
    "#\n",
    "#gandalf['Selection Method'] = gandalf['Selection Method'].astype(str)\n",
    "#len(gandalf_nosel)\n",
    "#\n",
    "#num = 0\n",
    "#for index, row in gandalf.iterrows():\n",
    "#    if '-99' in row['Selection Method']:\n",
    "#        num += 1\n",
    "#    else:\n",
    "#        num += 0\n",
    "#print(num)\n",
    "#\n",
    "##for index, row in gandalf.iterrows():\n",
    "##    if '-99' in row['Selection Method']:\n",
    "##        print(row)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5325e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the formatted version here\n",
    "#MAC = pd.concat([gandalf,gimli])\n",
    "MAC.reset_index(drop=True, inplace=True)\n",
    "\n",
    "MAC.to_csv('MAC_DR0p8_formatted.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea4499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now we'll work to format the selection methodology cell\n",
    "\n",
    "# Step 2 and 3: Remove duplicates and alphabetize for each cell\n",
    "def process_cell(cell):\n",
    "    # Remove duplicates using set and then convert back to list\n",
    "    unique_labels = list(set(cell))\n",
    "    # Alphabetize the contents\n",
    "    unique_labels.sort()\n",
    "    return unique_labels\n",
    "\n",
    "types = MAC['Selection Method'].dropna().str.split(' / ')\n",
    "processed_types = types.apply(process_cell)\n",
    "# Step 4: Join the contents back into a single string\n",
    "MAC['Processed Selection Method'] = processed_types.apply(' / '.join)\n",
    "\n",
    "types = MAC['Analysis Method'].dropna().str.split(' / ')\n",
    "processed_types = types.apply(process_cell)\n",
    "MAC['Processed Analysis Method'] = processed_types.apply(' / '.join)\n",
    "\n",
    "types = MAC['Confirmation Method'].str.split(' / ')\n",
    "arg = types.to_list()\n",
    "processed_types = types.apply(process_cell)\n",
    "MAC['Processed Confirmation Method'] = processed_types.apply(' / '.join)\n",
    "# Display the updated DataFrame\n",
    "#print(MAC[['Processed Selection Method']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14525ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_iterable_rows = MAC[MAC['Confirmation Method'].apply(lambda x: not isinstance(x, (list, str)))]\n",
    "#print(non_iterable_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd97948",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = MAC['Processed Selection Method'].dropna().str.split(' / ')\n",
    "\n",
    "# Flatten the lists and find unique labels\n",
    "unique_methods = set(method for sublist in methods for method in sublist)\n",
    "\n",
    "print(\"Unique selection methods:\", unique_methods)\n",
    "print(len(unique_methods))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea805222",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['Near-IR Slit Spectroscopy', 'Optical LOS Radial Velocity Shifts', 'Radio-Infrared Colors', 'Optical Narrow-Band Imaging', 'Optical Astrometry', 'Near-IR Periodicity', 'X-ray Periodicity', 'BAT Selection', 'Optical Colors', 'Gamma-Ray Periodicity', 'Mid-IR Imaging', 'Optical Double-Peaked Spectroscopic Emission Lines', 'Optical Photometry', 'Optical Slit Spectroscopy', 'Optical Quasi-Periodicity', 'Optical Spectroscopic Emission Line Ratios', 'Hard X-ray Periodicity', 'Optical Varstrometry', 'Optical Fiber Spectroscopy', 'Positional Offset', 'UV Spectroscopy', 'Radio Periodicity', 'Submillimeter Imaging', 'Radio Double Sources', 'Optical Velocity Offset Broad Spectroscopic Emission Lines', 'X-ray Spectroscopy', 'Optical-Mid-IR Colors', 'Optical IFU Spectroscopy', 'Mid-IR Spectroscopy', 'Optical Periodicity', 'Gamma-Ray Quasi-Periodicity', 'Optical Spectroscopy', 'Modeling', 'Radio X-Shaped Source', 'UV Imaging', 'Near-IR Imaging', 'Infrared Luminosity', 'X-ray Quasi-Periodicity', 'Optical Double-Peaked Broad Spectroscopic Emission Lines', 'Radio-Optical Offsets', 'Near-IR Quasi-Periodicity', 'Radio Double Jet', 'Radio Imaging', 'Optical Velocity Offset Narrow Spectroscopic Emission Lines', 'Serendipitous', 'UV Double-Peaked Narrow Spectroscopic Emission Lines', 'Optical Imaging', 'Optical IFU Imaging', 'X-ray Imaging', 'Optical Slitless Spectroscopy', 'Near-IR Spectroscopy', 'Optical Long-Slit Spectroscopy', 'Mid-IR Colors', 'Near-IR Colors', 'Velocity Offset Emission Lines', 'Radio Quasi-Periodicity', 'Radio Jet Precession']\n",
    "\n",
    "    #['Velocity Offset','Asymmetric','Serendipitous','Optical-Mid-IR Colors','Myers+','Extreme Velocity Offsets',\\\n",
    "#'IFU Optical Imaging','Optical Photometry','UV Spectroscopy','X-ray Imaging',\\\n",
    "#'Velocity Offset Optical Spectroscopic Emission Lines','Radial Velocity Shifts','BAT Selection',\\\n",
    "#'Optical Spectroscopic Emission Line Ratios ; Integral Field Unit Optical Spectroscopy',\\\n",
    "#'Narrow-Band Optical imaging','Optical Colors','Optical Spectroscopic Emission Line Ratios',\\\n",
    "#'Double-Peaked Broad Optical Spectroscopic Emission Lines ; Temporal Velocity Shifts in Mg II',\\\n",
    "#'Slit Optical Spectroscopy','Radio Imaging','Modeling','Jet precession','Lens','Jet Precession',\\\n",
    "#'Long-Slit Optical Spectroscopy','Radial Velocity Shifts ; Offset Broad Lines','Periodicity',\\\n",
    "#'Quasi-Periodicity','Submillimeter Imaging','Fiber Spectroscopy','X-Shaped Radio Source',\\\n",
    "#'Optical Light Curve Variability','SMBH Peculiar Motion','Mid-IR Spectroscopy','Complex. Needs review.',\\\n",
    "#'Optical Spectroscopy','Velocity Shifts between Narrow and Broad Lines','Velocity Offset Emission Lines',\\\n",
    "#'IR Colors','Radio-Optical Offsets','Integral Field Unit Optical Spectroscopy','Offset Broad Lines',\\\n",
    "#'Near-IR Imaging','X-ray Spectroscopy','Near-IR Slit Spectroscopy','Near-Infared Imaging',\\\n",
    "#'Radio Morphology+Helical Model or Structure','Mid-IR Colors','Fiber Spectra','Offset Emission Lines',\\\n",
    "#'1.487','Optical Flare','-99','Hard X-ray Imaging','Slitless Optical Spectroscopy',\\\n",
    "#'Possible Double cores+jets','Double Radio Sources','Double-Peaked Optical Spectroscopic Emission Lines',\\\n",
    "#'Low-Dispersion Spectroscopy','Optical Slit Spectroscopy','IFU Spectroscopy','Jet kinematics',\\\n",
    "#'Photocenter variability','Offset Optical Emission Lines','Optical Imaging','Positional Offsets',\\\n",
    "#'Optical Periodicity','Radial Velocity Shift','Spectroscopic Modeling','Mid-IR Imaging',\\\n",
    "#'Double-Peaked Spectroscopic Emission Lines','Hard X-ray Spectroscopy',\\\n",
    "#'Offset Optical Spectroscopic Emission Lines','Offset Broad Optical Lines',\\\n",
    "#'SED Features (Blue Excess)','Mid-infrared Selection','Time Varying Offset Spectroscopic Emission Lines',\\\n",
    "#'Near-IR Colors','Offset Spectroscopic Emission Lines','DDRG Modeling','Velocity Shifted Emission Lines',\\\n",
    "#'UV Imaging','Radio-to-infrared Colors','Variability','Near-IR Spectroscopy',\\\n",
    "#'Temporal Velocity Shifts in Mg II','Fiber Optical Spectroscopy','IFU Optical Spectroscopy',\\\n",
    "#'Varstrometry','Astrometry','Double-Peaked Broad Optical Spectroscopic Emission Lines',\\\n",
    "#'Double Jet','Positional Offset']\n",
    "\n",
    "for i in methods:\n",
    "    num = 0\n",
    "    for index,row in MAC.iterrows():\n",
    "        if i in row['Processed Selection Method']:\n",
    "            num += 1\n",
    "        else:\n",
    "            num += 0\n",
    "    print(\"Method \"+str(i)+\" identified \"+str(num)+\" times!\")\n",
    "\n",
    "# Adjust the selection technique for:\n",
    "#E1821+643\n",
    "\n",
    "# Note: we're shifting asymmetric to Velocity Offset Broad Optical Spectroscopic Emission Lines\n",
    "\n",
    "# LQAC_052-000_030 --> check coords but should be optical imaging / optical spectroscopy / fiber spectroscopy\n",
    "# LQAC_171+003_009 same\n",
    "# LQAC_122+031_018 same \n",
    "# LQAC_179+028_004 same\n",
    "# LQAC_230+056_004 same\n",
    "# LQAC_250+039_019,hewitt and burbidge and then sdss for second\n",
    "# LQAC_144+033_040 sdss and sdss\n",
    "# LQAC_136+000_002 sdss and sdss\n",
    "# LQAC_143+033_020 sdss and sdss\n",
    "# SDSSJ165502.02+260516.5 / LQAC_253+026_011_012 sdss and sdss\n",
    "# SDSSJ155218.09+045635.2 / LQAC_238+004_003_004 sdss and sdss\n",
    "\n",
    "# LQAC_052-000_030 --> flagged now as bad; I've seen the optical imaging. \n",
    "# The fiber spectra is clearly contaminated and not centered on a companion. Flagged as -1.\n",
    "# There is a weak optical companion but it is likely a star or a background quasar.\n",
    "# LQAC_171+003_009--> I am suspicious of this as well but will leave it for now. Will change it's flag to 0\n",
    "\n",
    "# all of these need to have their selection methods to changed to 'Optical Spectroscopy' and 'fiber spectroscopy' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb202f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the fle here with the columns rearranged:\n",
    "\n",
    "#MAC2 = MAC[['Primary System Type', 'ST1 Confidence Flag', 'Secondary System Type', 'ST2 Confidence Flag', \\\n",
    "#           'Tertiary System Type','ST3 Confidence Flag', 'Literature Name', 'Parsed Selection Method',\\\n",
    "#           'Confirmation Method', 'Name1', 'z1', 'z1_type', 'RA1', 'Dec1','Coordinate_waveband1', \\\n",
    "#           'Coordinate_Source1', 'Equinox1', 'Brightness1','Brightness_band1', 'Brightness_type1', \\\n",
    "#           'Name2', 'z2', 'z2_type', 'RA2','Dec2', 'Equinox2', 'Coordinate_waveband2', 'Coordinate_Source2',\\\n",
    "#           'Brightness2', 'Brightness_band2', 'Brightness_type2', 'dV', 'Sep','Sep(kpc)', 'dV_rwp',\\\n",
    "#           'Paper(s)', 'BibCode(s)', 'DOI(s)','Legacy System Type','Notes','dV_new']].copy()\n",
    "#\n",
    "#\n",
    "#MAC2.to_csv('MAC_DR0p8_formatted.csv', sep=',', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now down below here we're going to start working on formatting the separations and ensuring we have \\\n",
    "# angular separations where needed/applicable and that we don't overwrite physical separations by accident\n",
    "\n",
    "\n",
    "gg = gandalf_white[(gandalf_white['Sep(kpc)']>0) & (gandalf_white['Sep']<0)]\n",
    "len(gg)\n",
    "#gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d345a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = gandalf_grey[(gandalf_grey['Sep(kpc)']>0) & (gandalf_grey['Sep']<0)]\n",
    "len(gg)\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = gandalf_grey[(gandalf_grey['Sep']<0)]\n",
    "len(gg)\n",
    "#gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = gimli[(gimli['Sep(kpc)']>0) & (gimli['Sep']<0)]\n",
    "len(gg)\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8801713",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = MAC['System Type'].dropna().str.split(' / ')\n",
    "\n",
    "# Flatten the lists and find unique labels\n",
    "unique_types = set(method for sublist in types for method in sublist)\n",
    "\n",
    "print(\"Unique System Types and combos:\", unique_types)\n",
    "print(len(unique_types))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47213c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_combinations = MAC['Processed System Type'].dropna().unique()\n",
    "\n",
    "print(unique_combinations)\n",
    "print(len(unique_combinations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,j in MAC.iterrows():\n",
    "#    if MAC.at[i, 'Processed System Type']=='Quasar Pairs':\n",
    "#        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33edb312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here we're going to introduce the subjective flag for system confidence\n",
    "\n",
    "# literature and Name 1 == HVGC-1 is highly unlikely to be a recoil\n",
    "# Lens Candidate,WISE 0326-3122 is a lens candidate also based on Schechter+2017\n",
    "# Lens Candidate,WISE 1051-1142 is a lens candidate also based on Schechter+2017\n",
    "\n",
    "# we flagged IRAS 16474+3430 as a dual agn candidate but it might be a real dual!\n",
    "\n",
    "# (Unlikely),PKS 0537-441 listed oth a binary uqasar and as a smbh binary candidate but i consider it to be a very \\\n",
    "# weak binary candidate\n",
    "\n",
    "# / Lens,Q1208+1011 could still be a lens based on literature. Need to double check\n",
    "\n",
    "# cdouble check QJ0240-343AB\n",
    "\n",
    "# double check Q0101.8-3012\n",
    "\n",
    "# double check FBQ 1633+3134\n",
    "\n",
    "\n",
    "# PG 1553+113 angular separation is an upper limit on the separation (<)\n",
    "\n",
    "# for 4C+22.25 there was a binary separation (kpc) limit range of lim0.04-0.08e-3\n",
    "\n",
    "# for Mrk 231 there was an angular limit of lim1e-3\n",
    "\n",
    "# Tsai+2013's target was listed as having a 1pc separation....\n",
    "\n",
    "# the Zhou+2004 ; Jaiswal+2019 target evidently had a matxch with another catalog and I'd previously listed multiple\\\n",
    "# separations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa39a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "\n",
    "MAC1 = MAC.drop(['Notes'], axis=1)\n",
    "t = Table.from_pandas(MAC1)\n",
    "\n",
    "t.write('MAC_DR0p5_beta_webtable_16Jan2024.html', format='jsviewer', overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221705d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate of code that I moved up to the top and then deprecated later on\n",
    "## here we are further formatting the coordinates columns\n",
    "## we'll be flagging RA2 and Dec2 as -99 (value not string) for cases where RA2 and Dec2 are duplicated from RA1 and Dec1\n",
    "#\n",
    "## we'll start by flagging groups of objects based on the paper they come from:\n",
    "#papers = ['Orosz+2013','Hwang+2020']\n",
    "#\n",
    "#for i in papers:\n",
    "#    for index, row in MAC[MAC['Paper(s)']==str(i)].iterrows():\n",
    "#        MAC.at[index, 'RA2'] = -99\n",
    "#        MAC.at[index, 'Dec2'] = -99\n",
    "#\n",
    "## and here we are formatting for the naming convention for Name2\n",
    "## if the entry for Name 2 is duplicated from Name1, it is reflagged as -99. Here I have gone through and manually \\\n",
    "## checked this\n",
    "#\n",
    "#papers = ['Kim+2020','Barrows+2013','Ge+2012','Lyu+2016 ; Yuan+2016','Lyu+2016','Yuan+2016','Wang+2009 ; Ge+2012',\\\n",
    "#         'Liu+2010a ; Ge+2012','Ge+2012 ; Orosz+2013','Smith+2010 ; Song+2020','Shi+2014',\\\n",
    "#         'Smith+2010 ; Smith+2012 ; Ge+2012 ; Song+2020','Smith+2010 ; Kim+2020 ; Song+2020',\\\n",
    "#         'Smith+2010 ; Smith+2012 ; Song+2020','Smith+2010 ; Ge+2012 ; Song+2020','Wang+2009 ; Tingay+2011 ; Ge+2012',\\\n",
    "#         'Wang+2009 ; Liu+2010a ; Ge+2012','Liu+2010a ; Yuan+2016','Yuan+2016 ; Yang+2019 ; Joshi+2019',\\\n",
    "#         'Kim+2020 ; Liu+2014','Liu+2010a ; Yuan+2016','Shi+2014 ; Lyu+2016','Smith+2010 ; Yuan+2016 ; Song+2020',\\\n",
    "#         'Smith+2010 ; Shi+2014 ; Song+2020','Smith+2010 ; Comerford+2018 ; Song+2020',\\\n",
    "#         'Liu+2010a ; Ge+2012 ; Yuan+2016','Liu+2010a ; Yuan+2016 ; Comerford+2018','Ge+2012 ; Yuan+2016',\\\n",
    "#         'Wang+2009 ; Shi+2014','Liu+2010a ; Ge+2012 ; Comerford+2018','Liu+2010a','Ge+2012 ; Kim+2020']\n",
    "##J143359.71+351020.5 (comerford2013)\n",
    "#for i in papers:\n",
    "#    for index, row in MAC[MAC['Paper(s)']==str(i)].iterrows():\n",
    "#        MAC.at[index, 'Name2'] = \"-99\"\n",
    "#\n",
    "## just added A and B designations to the Miller+2004 targets, since previously they were listed as the same thing\n",
    "#\n",
    "## and evidently the objects within the gimli table have already been taken care of, so we only need to be \\\n",
    "## concerned with the gandalf targets\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6021e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gandalfcheck = gandalf[(gandalf['RA1'].astype(str)==gandalf['RA2'].astype(str)) & (gandalf['Dec1'].astype(str)==gandalf['Dec2'].astype(str))]\n",
    "\n",
    "gandalfcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACcheck = MAC[(MAC['Name1']==MAC['Name2'])]#gandalf[(gandalf['RA2']=='-99')]\n",
    "print(len(MACcheck))\n",
    "MACcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3484c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gandalfcheck = gandalf[(gandalf['Name1']==gandalf['Name2'])]#gandalf[(gandalf['RA2']=='-99')]\n",
    "print(len(gandalfcheck))\n",
    "gandalfcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gandalfcheck = gandalf[(gandalf['Name1']==gandalf['Name2'])]#gandalf[(gandalf['RA2']=='-99')]\n",
    "print(len(gandalfcheck))\n",
    "gandalfcheck\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0162b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gimlicheck = gimli[(gimli['Name1']==gimli['Name2'])]#gandalf[(gandalf['RA2']=='-99')]\n",
    "print(len(gimlicheck))\n",
    "gimlicheck\n",
    "\n",
    "# did this check; no objects that have matching Name1 and Name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are further formatting the coordinates columns\n",
    "# we'll be flagging RA2 and Dec2 as -99 (value not string) for cases where RA2 and Dec2 are duplicated from RA1 and Dec1\n",
    "\n",
    "## we'll start by flagging groups of objects based on the paper they come from:\n",
    "#papers = ['Orosz+2013','Hwang+2020']\n",
    "#\n",
    "#for i in papers:\n",
    "#    for index, row in MAC[MAC['Paper(s)']==str(i)].iterrows():\n",
    "#        MAC.at[index, 'RA2'] = -99\n",
    "#        MAC.at[index, 'Dec2'] = -99\n",
    "#\n",
    "## and here we are formatting for the naming convention for Name2\n",
    "## if the entry for Name 2 is duplicated from Name1, it is reflagged as -99. Here I have gone through and manually \\\n",
    "## checked this\n",
    "#\n",
    "#papers = ['Kim+2020','Barrows+2013','Ge+2012','Lyu+2016 ; Yuan+2016','Lyu+2016','Yuan+2016','Wang+2009 ; Ge+2012',\\\n",
    "#         'Liu+2010a ; Ge+2012','Ge+2012 ; Orosz+2013','Smith+2010 ; Song+2020','Shi+2014',\\\n",
    "#         'Smith+2010 ; Smith+2012 ; Ge+2012 ; Song+2020','Smith+2010 ; Kim+2020 ; Song+2020',\\\n",
    "#         'Smith+2010 ; Smith+2012 ; Song+2020','Smith+2010 ; Ge+2012 ; Song+2020','Wang+2009 ; Tingay+2011 ; Ge+2012',\\\n",
    "#         'Wang+2009 ; Liu+2010a ; Ge+2012','Liu+2010a ; Yuan+2016','Yuan+2016 ; Yang+2019 ; Joshi+2019',\\\n",
    "#         'Kim+2020 ; Liu+2014','Liu+2010a ; Yuan+2016','Shi+2014 ; Lyu+2016','Smith+2010 ; Yuan+2016 ; Song+2020',\\\n",
    "#         'Smith+2010 ; Shi+2014 ; Song+2020','Smith+2010 ; Comerford+2018 ; Song+2020',\\\n",
    "#         'Liu+2010a ; Ge+2012 ; Yuan+2016','Liu+2010a ; Yuan+2016 ; Comerford+2018','Ge+2012 ; Yuan+2016',\\\n",
    "#         'Wang+2009 ; Shi+2014','Liu+2010a ; Ge+2012 ; Comerford+2018','Liu+2010a','Ge+2012 ; Kim+2020']\n",
    "##J143359.71+351020.5 (comerford2013)\n",
    "#for i in papers:\n",
    "#    for index, row in MAC[MAC['Paper(s)']==str(i)].iterrows():\n",
    "#        MAC.at[index, 'Name2'] = \"-99\"\n",
    "\n",
    "\n",
    "# and evidently the objects within the gimli table have already been taken care of, so we only need to be \\\n",
    "# concerned with the gandalf targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here we're going to fix up the duplicate Name1 and Name2s, duplicate coordinates between RA1 and RA2, etc...\n",
    "\n",
    "#for index, row in gandalf.iterrows():\n",
    "#    if row['Paper(s)'] == 'Hwang+2020':\n",
    "#        #gimli.at[index, 'Confidence Flag'] = -1\n",
    "#        gandalf.at[index, 'RA2'] = -99\n",
    "#        gandalf.at[index, 'Dec2'] = -99\n",
    "#        gandalf.at[index, 'Equinox2'] = -99\n",
    "#        gandalf.at[index, 'Coordinate_waveband2'] = -99\n",
    "#        gandalf.at[index, 'Coordinate_Source2'] = -99\n",
    "#    elif row['Paper(s)'] == 'Orosz+2013':\n",
    "#        gandalf.at[index, 'RA2'] = -99\n",
    "#        gandalf.at[index, 'Dec2'] = -99\n",
    "#        gandalf.at[index, 'Equinox2'] = -99\n",
    "#        gandalf.at[index, 'Coordinate_waveband2'] = -99\n",
    "#        gandalf.at[index, 'Coordinate_Source2'] = -99\n",
    "#    elif row['Paper(s)'] == 'Comerford+2013':\n",
    "#        gandalf.at[index, 'RA2'] = -99\n",
    "#        gandalf.at[index, 'Dec2'] = -99\n",
    "#        gandalf.at[index, 'Equinox2'] = -99\n",
    "#        gandalf.at[index, 'Coordinate_waveband2'] = -99\n",
    "#        gandalf.at[index, 'Coordinate_Source2'] = -99\n",
    "#    #elif row['Paper(s)'] == 'Gattano+2014':\n",
    "#    #    gandalf.at[index, 'RA2'] = -99\n",
    "#    #    gandalf.at[index, 'Dec2'] = -99\n",
    "#    #    gandalf.at[index, 'Equinox2'] = -99\n",
    "#    #    gandalf.at[index, 'Coordinate_waveband2'] = -99\n",
    "#    #    gandalf.at[index, 'Coordinate_Source2'] = -99\n",
    "\n",
    "# nmeed to check pindor+hiennawi\n",
    "\n",
    "\n",
    "# and below here, we'll start cleaning up the selection, analysis, and confirmation methdologies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4592c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check the condition\n",
    "#def check_value(value):\n",
    "#    if pd.isna(value) or (value != -99 and not value > 0):\n",
    "#        return True\n",
    "#    return False\n",
    "\n",
    "# Applying the check and creating a new DataFrame\n",
    "#filtered_df = gandalf[gandalf['z1'].apply(check_value)]\n",
    "\n",
    "#print(\"Original DataFrame:\")\n",
    "#print(df)\n",
    "#print(\"\\nFiltered DataFrame:\")\n",
    "#filtered_df\n",
    "\n",
    "# As of December 14/15th 2023, we have fixed all issues of NaN values in the redshift z1 and z2 column for duals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93bfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell deprecated 24 January 2024; I don't think this is needed anymore\n",
    "#for index, row in gimli.iterrows():\n",
    "#    if 'Single AGNs' in row['Processed System Type']:\n",
    "#        ##gimli.at[index, 'Confidence Flag'] = -1\n",
    "#        #gimli.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "#        print('True singles')\n",
    "#    elif 'Single AGN' in row['Processed System Type']:\n",
    "#        ##gimli.at[index, 'Confidence Flag'] = -1\n",
    "#        #gimli.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "#        print('True single')\n",
    "#    elif 'Likely Single AGN' in row['Processed System Type']:\n",
    "#        ##gimli.at[index, 'Confidence Flag'] = -1\n",
    "#        #gimli.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "#        print('True likely single')\n",
    "#    # deprecated 24 january 2024\n",
    "#    #elif \"J0045+41\" in row['Name1']:\n",
    "#    #    ##gimli.at[index, 'Confidence Flag'] = -1\n",
    "#    #    print('Adjusted')\n",
    "#    #    print('True')\n",
    "#    elif 'Offset AGN Candidate' in row['Processed System Type']:\n",
    "#        ##gimli.at[index, 'Confidence Flag'] = 0\n",
    "#        #gimli.at[index, 'Processed System Type'] = 'Dual SMBH Candidate'\n",
    "#        print('True off')\n",
    "#\n",
    "\n",
    "\n",
    "# correcting system types and adding some confidence flags here....\n",
    "# deprecated on 24 january 2024; I don't think this is needed anymore!\n",
    "#for index, row in gimli.iterrows():\n",
    "#    if 'Single AGNs' in row['Processed System Type']:\n",
    "#        #gimli.at[index, 'Confidence Flag'] = -1\n",
    "#        gimli.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "#    elif 'Single AGN' in row['Processed System Type']:\n",
    "#        #gimli.at[index, 'Confidence Flag'] = -1\n",
    "#        gimli.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "#    elif 'Likely Single AGN' in row['Processed System Type']:\n",
    "#        #gimli.at[index, 'Confidence Flag'] = -1\n",
    "#        gimli.at[index, 'Processed System Type'] = 'Dual AGN Candidate'\n",
    "#    elif \"J0045+41\" in row['Name1']:\n",
    "#        #gimli.at[index, 'Confidence Flag'] = -1\n",
    "#        print('Adjusted')\n",
    "#    elif 'Offset AGN Candidate' in row['Processed System Type']:\n",
    "#        #gimli.at[index, 'Confidence Flag'] = 0\n",
    "#        gimli.at[index, 'Processed System Type'] = 'Dual SMBH Candidate'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f232383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #if row['Paper(s)'] == 'Hwang+2020':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Orosz+2013':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Lyu+2016':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Yuan+2016':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Barrows+2013':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Ge+2012':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Lyu+2016 ; Yuan+2016':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Wang+2009 ; Liu+2010a ; Ge+2012':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Smith+2010 ; Song+2020':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0        \n",
    "    #elif row['Paper(s)'] == 'Shi+2014':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0        \n",
    "    #elif row['Paper(s)'] == 'Wang+2009 ; Ge+2012 ; Shi+2014':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0                    \n",
    "    #elif row['Paper(s)'] == 'Liu+2010a ; Ge+2012':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0        \n",
    "    #elif row['Paper(s)'] == 'Liu+2010a':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0        \n",
    "    #elif row['Paper(s)'] == 'Kim+2020':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0               \n",
    "    #elif row['Paper(s)'] == 'Spiniello+2018':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0        \n",
    "    #elif row['Paper(s)'] == 'Rusu+2019':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0 \n",
    "    #elif row['Paper(s)'] == 'Wang+2009 ; Ge+2012':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0 \n",
    "    #elif row['Paper(s)'] == 'Wang+2009':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Yuan+2016 ; Cheung+2007 ; Roberts+2018 ; Saripalli+2018 ; Saripalli+2018':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Liu+2010a ; Yuan+2016':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Liu+2010a ; Ge+2012 ; Yuan+2016':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Ge+2012 ; Orosz+2013':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Wang+2009 ; Shi+2014':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Ge+2012 ; Comerford+2013':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Smith+2010 ; Smith+2012 ; Song+2020':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Smith+2010 ; Ge+2012 ; Song+2020':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Smith+2010 ; Smith+2012 ; Ge+2012 ; Song+2020':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Smith+2010 ; Smith+2012 ; Ge+2012 ; Song+2020 ':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Smith+2010 ; Smith+2012 ; Song+2020 ':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Smith+2010 ; Ge+2012 ; Song+2020 ':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Yuan+2016 ; Yang+2019 ; Joshi+2019':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Kim+2020 ; Liu+2014':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Kim+2020 ; Kim+2016':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "    #elif row['Paper(s)'] == 'Spiniello+2018 ; Rusu+2019':\n",
    "    #    gandalf.at[index, 'Confidence Flag'] = 0\n",
    "#shi+2014 --> 0\n",
    "#Wang+2009 ; Ge+2012 ; Shi+2014\n",
    "#Liu+2010a ; Ge+2012\n",
    "#Liu+2010a\n",
    "#Kim+2020\n",
    "###Kim+2020 ; Song+2020 --> figure out why this exists without Smith+2010. it shouldn't I don't think\n",
    "### Kim+2020 ; Foord+2020 same as above\n",
    "#Findlay+2018\n",
    "#Spiniello+2018 0 \n",
    "#Rusu+2019 0 \n",
    "##Inada+2012 0\n",
    "##Inada+2008 0\n",
    "##Inada+2010 0\n",
    "#Lemon+2018 +0.5\n",
    "#Lemon+2019 +0.5\n",
    "#Lemon+2020 +0.5\n",
    "# Koss 2012 +1\n",
    "# Hennawi+2010 +1\n",
    "# Hennawi+2006 +1\n",
    "# Hennawi+2006 ; Eftekharzadeh+2017 +1\n",
    "# Hennawi+2006 ; Inada+2008 ; Eftekharzadeh+2017 +1\n",
    "# Hennawi+2006 ; Inada+2008 ; Lemon+2018 +1\n",
    "#Liu+2011b ; Ge+2012\n",
    "#Liu+2010a ; Yuan+2016\n",
    "#Liu+2010a ; Ge+2012 ; Yuan+2016\n",
    "#Ge+2012 ; Orosz+2013\n",
    "#Wang+2009 ; Shi+2014\n",
    "#Ge+2012 ; Comerford+2013\n",
    "#Comerford+2013\n",
    "#Smith+2010 ; Smith+2012 ; Song+2020\n",
    "#Smith+2010 ; Ge+2012 ; Song+2020\n",
    "#Yuan+2016 ; Yang+2019 ; Joshi+2019\n",
    "#Kim+2020 ; Liu+2014\n",
    "#Spiniello+2018 ; Rusu+2019\n",
    "#Yuan+2016 ; Cheung+2007 ; Roberts+2018 ; Saripalli+2018 ; Saripalli+2018\n",
    "#Grade A targets from Fu+2015. --> +0.5\n",
    "#Grade B targets from Fu+2015. --> 0\n",
    "#Fu+2018 --> +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde984aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a8d2df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## here we're beginning to clean up the tables and remove projected pairs or pairs that are not close enough to \\\n",
    "## be 'merger-induced' (like clustered quasars)\n",
    "#\n",
    "## first we're checking to see if the coordinates and redshifts for AGN 1 and 2 are identical under some conditions.\\\n",
    "## If they are, we'll be replacing the values with a no-value flag. This is in preparation for clipping on \\\n",
    "## separations and velocity differences\n",
    "#MAC.fillna(-99, inplace=True)\n",
    "#\n",
    "#MAC['z1'] = MAC['z1'].astype(float)\n",
    "#MAC['z2'] = MAC['z2'].astype(float)\n",
    "#\n",
    "#\n",
    "##for i,j in MAC.iterrows():\n",
    "##    if ('Double-Peak' in MAC.at[i, 'Selection Method']) and (MAC.at[i, 'z1']==MAC.at[i, 'z2']):\n",
    "##        print('True')\n",
    "#\n",
    "#for i, row in MAC.iterrows():\n",
    "#    # Check if z1 and z2 are not -99\n",
    "#    if row['z1'] != -99 and row['z2'] != -99:\n",
    "#        try:\n",
    "#            # Perform the calculation for the row\n",
    "#            MAC.at[i, 'dV'] = (2.99e+5) * ((1 + row['z1'])**2 - (1 + row['z2'])**2) / ((1 + row['z1'])**2 + (1 + row['z2'])**2)\n",
    "#        except TypeError as e:\n",
    "#            # If a TypeError occurs, print the row index and the error\n",
    "#            print(f\"Error at row {i}: {e}\")\n",
    "#            print(row)\n",
    "#\n",
    "#            \n",
    "#for i, row in MAC.iterrows():\n",
    "#    # Check if z1 and z2 are not -99\n",
    "#    if (row['Sep'] != -99) and (row['Sep'] != -99.0) and (row['z1']>0) and (row['Sep']>0):\n",
    "#        try:\n",
    "#            # Perform the calculation for the row\n",
    "#            row['Sep(kpc)'] = row['Sep']*cosmo.kpc_proper_per_arcmin(row['z1'])*(u.arcmin/u.kpc)*(1/60)\n",
    "#        except TypeError as e:\n",
    "#            # If a TypeError occurs, print the row index and the error\n",
    "#            print(f\"Error at row {i}: {e}\")\n",
    "#            print(row)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d8a15b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAC_bad1 = MAC[MAC['Sep(kpc)']>100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa4b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, row in MAC.iterrows():\n",
    "#    # Check if z1 and z2 are not -99\n",
    "#    try:\n",
    "#        # Perform the calculation for the row\n",
    "#        MAC_bad1 = MAC[MAC['Sep(kpc)']>100.0]\n",
    "#    except TypeError as e:\n",
    "#        # If a TypeError occurs, print the row index and the error\n",
    "#        print(f\"Error at row {i}: {e}\")\n",
    "#        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import pandas as pd\n",
    "#\n",
    "## Load your dataframe\n",
    "##df = pd.read_csv('your_file.csv')  # Replace with your file path\n",
    "#\n",
    "## Function to check if a value is a float\n",
    "#def is_float(value):\n",
    "#    try:\n",
    "#        float(value)\n",
    "#        return True\n",
    "#    except ValueError:\n",
    "#        return False\n",
    "#\n",
    "## Create a new dataframe for problem rows\n",
    "#problem_rows = pd.DataFrame()\n",
    "#\n",
    "## Iterate over the rows\n",
    "#for index, row in MAC.iterrows():\n",
    "#    value = row['Sep(kpc)']  # Replace 'your_column' with the name of your column\n",
    "#    if not is_float(value) or value == -99:\n",
    "#        problem_rows = problem_rows.append(row)\n",
    "#\n",
    "## Now, 'problem_rows' contains all the rows that you need to examine\n",
    "##print(problem_rows)\n",
    "#\n",
    "## Optionally, save the problem rows to a new CSV\n",
    "##problem_rows.to_csv('problem_rows.csv', index=False)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f027d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c57d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import pandas as pd\n",
    "#\n",
    "## Load your dataframe\n",
    "##df = pd.read_csv('your_file.csv')  # Replace with your file path\n",
    "#\n",
    "## Function to check if a value is a float\n",
    "#def is_float(value):\n",
    "#    try:\n",
    "#        float(value)\n",
    "#        return True\n",
    "#    except ValueError:\n",
    "#        return False\n",
    "#\n",
    "## Create a new dataframe for problem rows\n",
    "#good_rows = pd.DataFrame()\n",
    "#\n",
    "## Iterate over the rows\n",
    "#for index, row in MAC.iterrows():\n",
    "#    value = row['Sep(kpc)']  # Replace 'your_column' with the name of your column\n",
    "#    if is_float(value) or value != -99 or value!=-99.0:\n",
    "#        good_rows = good_rows.append(row)\n",
    "#\n",
    "## Now, 'problem_rows' contains all the rows that you need to examine\n",
    "##print(good_rows)\n",
    "#\n",
    "## Optionally, save the problem rows to a new CSV\n",
    "##problem_rows.to_csv('problem_rows.csv', index=False)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34ba9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC['Sep(kpc)'] = MAC['Sep(kpc)'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.max(MAC['Sep(kpc)'])\n",
    "#MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC_bad1 = MAC[MAC['Sep(kpc)']>100.0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC_bad1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736e18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(good_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5327290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC_bad1 = good_rows[good_rows['Sep(kpc)']>100.0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to check if a value in a column is a string\n",
    "#def is_string(value):\n",
    "#    return isinstance(value, str)\n",
    "#\n",
    "## Create a new dataframe for rows where the specified column contains a string\n",
    "#rows_with_string_in_column = pd.DataFrame()\n",
    "#\n",
    "## Name of the column to check\n",
    "#column_name = 'Sep(kpc)'  # Replace 'your_column' with the name of your column\n",
    "#\n",
    "## Iterate over the rows\n",
    "#for index, row in MAC.iterrows():\n",
    "#    if is_string(row[column_name]):\n",
    "#        rows_with_string_in_column = rows_with_string_in_column.append(row)\n",
    "#\n",
    "## 'rows_with_string_in_column' contains all the rows where the specified column has a string\n",
    "#print(rows_with_string_in_column)\n",
    "#\n",
    "## Optionally, save these rows to a new CSV\n",
    "##rows_with_string_in_column.to_csv('rows_with_string_in_column.csv', index=False)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ad7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(problem_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c20572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in MAC.iterrows():\n",
    "#    print(row['z1'].dtype,row['z2'].dtype)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fffd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosmo.kpc_proper_per_arcmin(3)*(u.arcmin/u.kpc)*(1/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we'll work to format the selection methodology cell\n",
    "#\n",
    "#types = MAC['Selection Method'].dropna().str.split(' / ')\n",
    "#\n",
    "## Step 2 and 3: Remove duplicates and alphabetize for each cell\n",
    "#def process_cell(cell):\n",
    "#    # Remove duplicates using set and then convert back to list\n",
    "#    unique_labels = list(set(cell))\n",
    "#    # Alphabetize the contents\n",
    "#    unique_labels.sort()\n",
    "#    return unique_labels\n",
    "#\n",
    "#processed_types = types.apply(process_cell)\n",
    "#\n",
    "## Step 4: Join the contents back into a single string\n",
    "#MAC['Processed Selection Method'] = processed_types.apply(' / '.join)\n",
    "#\n",
    "## Display the updated DataFrame\n",
    "##print(MAC[['Processed Selection Method']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75d1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00bd8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad10 = MAC[MAC['Processed Selection Method']=='1.487']\n",
    "#bad10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0d97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b77d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
